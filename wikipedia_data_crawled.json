[
    {
        "Title": "Artificial intelligence - Wikipedia",
        "URL": "https://en.wikipedia.org/wiki/Artificial_intelligence",
        "Content": "\n Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.[1] Such machines may be called AIs.\n High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"[2][3]\n Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics.[a] General intelligence\u2014the ability to complete any task performed by a human on an at least equal level\u2014is among the field's long-term goals.[4] To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.[5]\n Artificial intelligence was founded as an academic discipline in 1956,[6] and the field went through multiple cycles of optimism throughout its history,[7][8] followed by periods of disappointment and loss of funding, known as AI winters.[9][10] Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques.[11] This growth accelerated further after 2017 with the transformer architecture,[12] and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom. The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n The general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.[a]\n Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[13] By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.[14]\n Many of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow.[15] Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.[16] Accurate and efficient reasoning is an unsolved problem.\n Knowledge representation and knowledge engineering[17] allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,[18] scene interpretation,[19] clinical decision support,[20] knowledge discovery (mining \"interesting\" and actionable inferences from large databases),[21] and other areas.[22]\n A knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge.[23] Knowledge bases need to represent things such as objects, properties, categories, and relations between objects;[24] situations, events, states, and time;[25] causes and effects;[26] knowledge about knowledge (what we know about what other people know);[27] default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing);[28] and many other aspects and domains of knowledge.\n Among the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous);[29] and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally).[16] There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.[c]\n An \"agent\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen.[d][32] In automated planning, the agent has a specific goal.[33] In automated decision-making, the agent has preferences\u2014there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.[34]\n In classical planning, the agent knows exactly what the effect of any action will be.[35] In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.[36]\n In some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning), or the agent can seek information to improve its preferences.[37] Information value theory can be used to weigh the value of exploratory or experimental actions.[38] The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be.\n A Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g., by iteration), be heuristic, or it can be learned.[39]\n Game theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.[40]\n Machine learning is the study of programs that can improve their performance on a given task automatically.[41] It has been a part of AI from the beginning.[e]\n There are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance.[44] Supervised learning requires labeling the training data with the expected answers, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).[45]\n In reinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\".[46] Transfer learning is when the knowledge gained from one problem is applied to a new problem.[47] Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.[48]\n Computational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.[49]\n Natural language processing (NLP)[50] allows programs to read, write and communicate in human languages such as English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.[51]\n Early work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation[f] unless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem[29]). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\n Modern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning),[52] transformers (a deep learning architecture using an attention mechanism),[53] and others.[54] In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text,[55][56] and by 2023, these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world applications.[57]\n Machine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.[58]\n The field includes speech recognition,[59] image classification,[60] facial recognition, object recognition,[61]object tracking,[62] and robotic perception.[63]\n Affective computing is a field that comprises systems that recognize, interpret, process, or simulate human feeling, emotion, and mood.[65] For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human\u2013computer interaction.\n However, this tends to give na\u00efve users an unrealistic conception of the intelligence of existing computer agents.[66] Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the effects displayed by a videotaped subject.[67]\n A machine with artificial general intelligence should be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.[4]\n AI research uses a wide variety of techniques to accomplish the goals above.[b]\n AI can solve many problems by intelligently searching through many possible solutions.[68] There are two very different kinds of search used in AI: state space search and local search.\n State space search searches through a tree of possible states to try to find a goal state.[69] For example, planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.[70]\n Simple exhaustive searches[71] are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes.[15] \"Heuristics\" or \"rules of thumb\" can help prioritize choices that are more likely to reach a goal.[72]\n Adversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and countermoves, looking for a winning position.[73]\n Local search uses mathematical optimization to find a solution to a problem. It begins with some form of guess and refines it incrementally.[74]\n Gradient descent is a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize a loss function. Variants of gradient descent are commonly used to train neural networks,[75] through the backpropagation algorithm.\n Another type of local search is evolutionary computation, which aims to iteratively improve a set of candidate solutions by \"mutating\" and \"recombining\" them, selecting only the fittest to survive each generation.[76]\n Distributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).[77]\n Formal logic is used for reasoning and knowledge representation.[78]\nFormal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as \"and\", \"or\", \"not\" and \"implies\")[79] and predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as \"Every X is a Y\" and \"There are some Xs that are Ys\").[80]\n Deductive reasoning in logic is the process of proving a new statement (conclusion) from other statements that are given and assumed to be true (the premises).[81] Proofs can be structured as proof trees, in which nodes are labelled by sentences, and children nodes are connected to parent nodes by inference rules.\n Given a problem and a set of premises, problem-solving reduces to searching for a proof tree whose root node is labelled by a solution of the problem and whose leaf nodes are labelled by premises or axioms. In the case of Horn clauses, problem-solving search can be performed by reasoning forwards from the premises or backwards from the problem.[82] In the more general case of the clausal form of first-order logic, resolution is a single, axiom-free rule of inference, in which a problem is solved by proving a contradiction from premises that include the negation of the problem to be solved.[83]\n Inference in both Horn clause logic and first-order logic is undecidable, and therefore intractable. However, backward reasoning with Horn clauses, which underpins computation in the logic programming language Prolog, is Turing complete. Moreover, its efficiency is competitive with computation in other symbolic programming languages.[84]\n Fuzzy logic assigns a \"degree of truth\" between 0 and 1. It can therefore handle propositions that are vague and partially true.[85]\n Non-monotonic logics, including logic programming with negation as failure, are designed to handle default reasoning.[28] Other specialized versions of logic have been developed to describe many complex domains.\n Many problems in AI (including in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.[86] Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,[87] and information value theory.[88] These tools include models such as Markov decision processes,[89] dynamic decision networks,[90] game theory and mechanism design.[91]\n Bayesian networks[92] are a tool that can be used for reasoning (using the Bayesian inference algorithm),[g][94] learning (using the expectation\u2013maximization algorithm),[h][96] planning (using decision networks)[97] and perception (using dynamic Bayesian networks).[90]\n Probabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations for streams of data, thus helping perception systems analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).[90]\n The simplest AI applications can be divided into two types: classifiers (e.g., \"if shiny then diamond\"), on one hand, and controllers (e.g., \"if diamond then pick up\"), on the other hand. Classifiers[98] are functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an \"observation\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.[45]\n There are many kinds of classifiers in use.[99] The decision tree is the simplest and most widely used symbolic machine learning algorithm.[100] K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.[101]\nThe naive Bayes classifier is reportedly the \"most widely used learner\"[102] at Google, due in part to its scalability.[103]\nNeural networks are also used as classifiers.[104]\n An artificial neural network is based on a collection of nodes also known as artificial neurons, which loosely model the neurons in a biological brain. It is trained to recognise patterns; once trained, it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once the weight crosses its specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers.[104]\n Learning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm.[105] Neural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.[106]\n In feedforward neural networks the signal passes in only one direction.[107] Recurrent neural networks feed the output signal back into the input, which allows short-term memories of previous input events. Long short term memory is the most successful network architecture for recurrent networks.[108] Perceptrons[109] use only a single layer of neurons; deep learning[110] uses multiple layers. Convolutional neural networks strengthen the connection between neurons that are \"close\" to each other\u2014this is especially important in image processing, where a local set of neurons must identify an \"edge\" before the network can identify an object.[111]\n Deep learning[110] uses several layers of neurons between the network's inputs and outputs. The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits, letters, or faces.[112]\n Deep learning has profoundly improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing, image classification,[113] and others. The reason that deep learning performs so well in so many applications is not known as of 2023.[114] The sudden success of deep learning in 2012\u20132015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)[i] but because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.[j]\n Generative pre-trained transformers (GPT) are large language models (LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pretrained on a large corpus of text that can be from the Internet. The pretraining consists of predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are prone to generating falsehoods called \"hallucinations\", although this can be reduced with RLHF and quality data. They are used in chatbots, which allow people to ask a question or request a task in simple text.[122][123]\n Current models and services include Gemini (formerly Bard), ChatGPT, Grok, Claude, Copilot, and LLaMA.[124] Multimodal GPT models can process different types of data (modalities) such as images, videos, sound, and text.[125]\n In the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training.[126] Specialized programming languages such as Prolog were used in early AI research,[127] but general-purpose programming languages like Python have become predominant.[128]\n The transistor density in integrated circuits has been observed to roughly double every 18 months\u2014a trend known as Moore's law, named after the Intel co-founder Gordon Moore, who first identified it. Improvements in GPUs have been even faster.[129]\n AI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search), targeting online advertisements, recommendation systems (offered by Netflix, YouTube or Amazon), driving internet traffic, targeted advertising (AdSense, Facebook), virtual assistants (such as Siri or Alexa), autonomous vehicles (including drones, ADAS and self-driving cars), automatic language translation (Microsoft Translator, Google Translate), facial recognition (Apple's Face ID or Microsoft's DeepFace and Google's FaceNet) and image labeling (used by Facebook, Apple's iPhoto and TikTok). The deployment of AI may be overseen by a Chief automation officer (CAO).\n The application of AI in medicine and medical research has the potential to increase patient care and quality of life.[130] Through the lens of the Hippocratic Oath, medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients.[131][132]\n For medical research, AI is an important tool for processing and integrating big data. This is particularly important for organoid and tissue engineering development which use microscopy imaging as a key technique in fabrication.[133] It has been suggested that AI can overcome discrepancies in funding allocated to different fields of research.[133] New AI tools can deepen the understanding of biomedically relevant pathways. For example, AlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein.[134] In 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria.[135] In 2024, researchers used machine learning to accelerate the search for Parkinson's disease drug treatments. Their aim was to identify compounds that block the clumping, or aggregation, of alpha-synuclein (the protein that characterises Parkinson's disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold.[136][137]\n Applications of AI in this domain include AI-enabled menstruation and fertility trackers that analyze user data to offer prediction,[138] AI-integrated sex toys (e.g., teledildonics),[139] AI-generated sexual education content,[140] and AI agents that simulate sexual and romantic partners (e.g., Replika).[141]  AI is also used for the production of non-consensual deepfake pornography, raising significant ethical and legal concerns.[142]\n AI technologies have also been used to attempt to identify online gender-based violence and online sexual grooming of minors.[143][144]\n Game playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques.[145] Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997.[146] In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin.[147] In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. Then, in 2017, it defeated Ke Jie, who was the best Go player in the world.[148] Other programs handle imperfect-information games, such as the poker-playing program Pluribus.[149] DeepMind developed increasingly generalistic reinforcement learning models, such as with MuZero, which could be trained to play chess, Go, or Atari games.[150] In 2019, DeepMind's AlphaStar achieved grandmaster level in StarCraft II, a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map.[151] In 2021, an AI agent competed in a PlayStation Gran Turismo competition, winning against four of the world's best Gran Turismo drivers using deep reinforcement learning.[152] In 2024, Google DeepMind introduced SIMA, a type of AI capable of autonomously playing nine previously unseen open-world video games by observing screen output, as well as executing short, specific tasks in response to natural language instructions.[153]\n In mathematics, special forms of formal step-by-step reasoning are used.[154] In contrast, LLMs such as GPT-4 Turbo, Gemini Ultra, Claude Opus, LLaMa-2 or Mistral Large are working with probabilistic models, which can produce wrong answers in the form of hallucinations. Therefore, they need not only a large database of mathematical problems to learn from but also methods such as supervised fine-tuning or trained classifiers with human-annotated data to improve answers for new problems and learn from corrections.[155] A 2024 study showed that the performance of some language models for reasoning capabilities in solving math problems not included in their training data was low, even for problems with only minor deviations from trained data.[156]\n Alternatively, dedicated models for mathematical problem solving with higher precision for the outcome including proof of theorems have been developed such as Alpha Tensor, Alpha Geometry and Alpha Proof all from Google DeepMind,[157] Llemma from eleuther[158] or Julius.[159]\n When natural language is used to describe mathematical problems, converters transform such prompts into a formal language such as Lean to define mathematical tasks.\n Some models have been developed to solve challenging problems and reach good results in benchmark tests, others to serve as educational tools in mathematics.[160]\n Finance is one of the fastest growing sectors where applied AI tools are being deployed: from retail online banking to investment advice and insurance, where automated \"robot advisers\" have been in use for some years.[161]\n World Pensions experts like Nicolas Firzli insist it may be too early to see the emergence of highly innovative AI-informed financial products and services: \"the deployment of AI tools will simply further automatise things: destroying tens of thousands of jobs in banking, financial planning, and pension advice in the process, but I'm not sure it will unleash a new wave of [e.g., sophisticated] pension innovation.\"[162]\n Various countries are deploying AI military applications.[163] The main applications enhance command and control, communications, sensors, integration and interoperability.[164] Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles.[163] AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles involving manned and unmanned teams.[164]\n AI has been used in military operations in Iraq, Syria, Israel and Ukraine.[163][165][166][167]\n In the early 2020s, generative AI gained widespread prominence. GenAI is AI capable of generating text, images, videos, or other data using generative models,[168][169] often in response to prompts.[170][171]\n In March 2023, 58% of U.S. adults had heard about ChatGPT and 14% had tried it.[172] The increasing realism and ease-of-use of AI-based text-to-image generators such as Midjourney, DALL-E, and Stable Diffusion sparked a trend of viral AI-generated photos. Widespread attention was gained by a fake photo of Pope Francis wearing a white puffer coat, the fictional arrest of Donald Trump, and a hoax of an attack on the Pentagon, as well as the usage in professional creative arts.[173][174]\n Artificial intelligent (AI) agents are software entities designed to perceive their environment, make decisions, and take actions autonomously to achieve specific goals. These agents can interact with users, their environment, or other agents. AI agents are used in various applications, including virtual assistants, chatbots, autonomous vehicles, game-playing systems, and industrial robotics. AI agents operate within the constraints of their programming, available computational resources, and hardware limitations. This means they are restricted to performing tasks within their defined scope and have finite memory and processing capabilities. In real-world applications, AI agents often face time constraints for decision-making and action execution. Many AI agents incorporate learning algorithms, enabling them to improve their performance over time through experience or training. Using machine learning, AI agents can adapt to new situations and optimise their behaviour for their designated tasks.[175][176][177]\n There are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated \"AI\" in some offerings or processes.[178] A few examples are energy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions, foreign policy, or supply chain management.\n AI applications for evacuation and disaster management are growing. AI has been used to investigate if and how people evacuated in large scale and small scale evacuations using historical data from GPS, videos or social media. Further, AI can provide real time information on the real time evacuation conditions.[179][180][181]\n In agriculture, AI has helped farmers identify areas that need irrigation, fertilization, pesticide treatments or increasing yield. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water.\n Artificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights.\" For example, it is used for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. Additionally, it could be used for activities in space, such as space exploration, including the analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation.\n During the 2024 Indian elections, US$50 millions was spent on authorized AI-generated content, notably by creating deepfakes of allied (including sometimes deceased) politicians to better engage with voters, and by translating speeches to various local languages.[182]\n AI has potential benefits and potential risks.[183] AI may be able to advance science and find solutions for serious problems: Demis Hassabis of DeepMind hopes to \"solve intelligence, and then use that to solve everything else\".[184] However, as the use of AI has become widespread, several unintended consequences and risks have been identified.[185] In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning.[186]\n Machine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright.\n AI-powered devices and services, such as virtual assistants and IoT products, continuously collect personal information, raising concerns about intrusive data gathering and unauthorized access by third parties. The loss of privacy is further exacerbated by AI's ability to process and combine vast amounts of data, potentially leading to a surveillance society where individual activities are constantly monitored and analyzed without adequate safeguards or transparency.\n Sensitive user data collected may include online activity records, geolocation data, video or audio.[187] For example, in order to build speech recognition algorithms, Amazon has recorded millions of private conversations and allowed temporary workers to listen to and transcribe some of them.[188] Opinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.[189]\n AI developers argue that this is the only way to deliver valuable applications. and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy.[190] Since 2016, some privacy experts, such as Cynthia Dwork, have begun to view privacy in terms of fairness. Brian Christian wrote that experts have pivoted \"from the question of 'what they know' to the question of 'what they're doing with it'.\"[191]\n Generative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under the rationale of \"fair use\". Experts disagree about how well and under what circumstances this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\".[192][193] Website owners who do not wish to have their content scraped can indicate it in a \"robots.txt\" file.[194] In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI.[195][196] Another discussed approach is to envision a separate sui generis system of protection for creations generated by AI to ensure fair attribution and compensation for human authors.[197]\n The commercial AI scene is dominated by Big Tech companies such as Alphabet Inc., Amazon, Apple Inc., Meta Platforms, and Microsoft.[198][199][200] Some of these players already own the vast majority of existing cloud infrastructure and computing power from data centers, allowing them to entrench further in the marketplace.[201][202]\n In January 2024, the International Energy Agency (IEA) released Electricity 2024, Analysis and Forecast to 2026, forecasting electric power use.[203] This is the first IEA report to make projections for data centers and power consumption for artificial intelligence and cryptocurrency. The report states that power demand for these uses might double by 2026, with additional electric power usage equal to electricity used by the whole Japanese nation.[204]\n Prodigious power consumption by AI is responsible for the growth of fossil fuels use, and might delay closings of obsolete, carbon-emitting coal energy facilities. There is a feverish rise in the construction of data centers throughout the US, making large technology firms (e.g., Microsoft, Meta, Google, Amazon) into voracious consumers of electric power. Projected electric consumption is so immense that there is concern that it will be fulfilled no matter the source. A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources \u2013 from nuclear energy to geothermal to fusion. The tech firms argue that \u2013 in the long view \u2013 AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and \"intelligent\", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms.[205]\n A 2024 Goldman Sachs Research Paper, AI Data Centers and the Coming US Power Demand Surge, found \"US power demand (is) likely to experience growth not seen in a generation....\" and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means.[206] Data centers' need for more and more electrical power is such that they might max out the electrical grid. The Big Tech companies counter that AI can be used to maximize the utilization of the grid by all.[207]\n In 2024, the Wall Street Journal reported that big AI companies have begun negotiations with the US nuclear power providers to provide electricity to the data centers. In March 2024 Amazon purchased a Pennsylvania nuclear-powered data center for $650 Million (US).[208] Nvidia CEO Jen-Hsun Huang said nuclear power is a good option for the data centers.[209]\n In September 2024, Microsoft announced an agreement with Constellation Energy to re-open the Three Mile Island nuclear power plant to provide Microsoft with 100% of all electric power produced by the plant for 20 years. Reopening the plant, which suffered a partial nuclear meltdown of its Unit 2 reactor in 1979, will require Constellation to get through strict regulatory processes which will include extensive safety scrutiny from the US Nuclear Regulatory Commission. If approved (this will be the first ever US re-commissioning of a nuclear plant), over 835 megawatts of power \u2013 enough for 800,000 homes \u2013 of energy will be produced. The cost for re-opening and upgrading is estimated at $1.6 billion (US) and is dependent on tax breaks for nuclear power contained in the 2022 US Inflation Reduction Act.[210] The US government and the state of Michigan are investing almost $2 billion (US) to reopen the Palisades Nuclear reactor on Lake Michigan. Closed since 2022, the plant is planned to be reopened in October 2025. The Three Mile Island facility will be renamed the Crane Clean Energy Center after Chris Crane, a nuclear proponent and former CEO of Exelon who was responsible for Exelon spinoff of Constellation.[211]\n After the last approval in September 2023, Taiwan suspended the approval of data centers north of Taoyuan with a capacity of more than 5 MW in 2024, due to power supply shortages.[212] Taiwan aims to phase out nuclear power by 2025.[212] On the other hand, Singapore imposed a ban on the opening of data centers in 2019 due to electric power, but in 2022, lifted this ban.[212]\n Although most nuclear plants in Japan have been shut down after the 2011 Fukushima nuclear accident, according to an October 2024 Bloomberg article in Japanese, cloud gaming services company Ubitus, in which Nvidia has a stake, is looking for land in Japan near nuclear power plant for a new data center for generative AI.[213] Ubitus CEO Wesley Kuo said nuclear power plants are the most efficient, cheap and stable power for AI.[213]\n On 1 November 2024, the Federal Energy Regulatory Commission (FERC) rejected an application submitted by Talen Energy for approval to supply some electricity from the nuclear power station Susquehanna to Amazon's data center.[214] \nAccording to the Commission Chairman Willie L. Phillips, it is a burden on the electricity grid as well as a significant cost shifting concern to households and other business sectors.[214]\n YouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation.[215] This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government.[216] The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took steps to mitigate the problem [citation needed].\n In 2022, generative AI began to create images, audio, video and text that are indistinguishable from real photographs, recordings, films, or human writing. It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda.[217] AI pioneer Geoffrey Hinton expressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks.[218]\n Machine learning applications will be biased[k] if they learn from biased data.[220] The developers may not be aware that the bias exists.[221] Bias can be introduced by the way training data is selected and by the way a model is deployed.[222][220] If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination.[223] The field of fairness studies how to prevent harms from algorithmic biases.\n On June 28, 2015, Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people,[224] a problem called \"sample size disparity\".[225] Google \"fixed\" this problem by preventing the system from labelling anything as a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.[226]\n COMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist. In 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different\u2014the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend.[227] In 2017, several researchers[l] showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.[229]\n A program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\".[230] Moritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn't work.\"[231]\n Criticism of COMPAS highlighted that machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions as recommendations, some of these \"recommendations\" will likely be racist.[232] Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is descriptive rather than prescriptive.[m]\n Bias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.[225]\n There are various conflicting definitions and mathematical models of fairness. These notions depend on ethical assumptions, and are influenced by beliefs about society. One broad category is distributive fairness, which focuses on the outcomes, often identifying groups and seeking to compensate for statistical disparities. Representational fairness tries to ensure that AI systems do not reinforce negative stereotypes or render certain groups invisible. Procedural fairness focuses on the decision process rather than the outcome. The most relevant notions of fairness may depend on the context, notably the type of AI application and the stakeholders. The subjectivity in the notions of bias and fairness makes it difficult for companies to operationalize them. Having access to sensitive attributes such as race or gender is also considered by many AI ethicists to be necessary in order to compensate for biases, but it may conflict with anti-discrimination laws.[219]\n At its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022), the Association for Computing Machinery, in Seoul, South Korea, presented and published findings that recommend that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe, and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.[dubious \u2013 discuss][234]\n Many AI systems are so complex that their designers cannot explain how they reach their decisions.[235] Particularly with deep neural networks, in which there are a large amount of non-linear relationships between inputs and outputs. But some popular explainability techniques exist.[236]\n It is impossible to be certain that a program is operating correctly if no one knows how exactly it works. There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a ruler as \"cancerous\", because pictures of malignancies typically include a ruler to show the scale.[237] Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading.[238]\n People who have been harmed by an algorithm's decision have a right to an explanation.[239] Doctors, for example, are expected to clearly and completely explain to their colleagues the reasoning behind any decision they make. Early drafts of the European Union's General Data Protection Regulation in 2016 included an explicit statement that this right exists.[n] Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.[240]\n DARPA established the XAI (\"Explainable Artificial Intelligence\") program in 2014 to try to solve these problems.[241]\n Several approaches aim to address the transparency problem. SHAP enables to visualise the contribution of each feature to the output.[242] LIME can locally approximate a model's outputs with a simpler, interpretable model.[243] Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned.[244] Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network for computer vision have learned, and produce output that can suggest what the network is learning.[245] For generative pre-trained transformers, Anthropic developed a technique based on dictionary learning that associates patterns of neuron activations with human-understandable concepts.[246]\n Artificial intelligence provides a number of tools that are useful to bad actors, such as authoritarian governments, terrorists, criminals or rogue states.\n A lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision.[o] Widely available AI tools can be used by bad actors to develop inexpensive autonomous weapons and, if produced at scale, they are potentially weapons of mass destruction.[248] Even when used in conventional warfare, they currently cannot reliably choose targets and could potentially kill an innocent person.[248] In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, however the United States and others disagreed.[249] By 2015, over fifty countries were reported to be researching battlefield robots.[250]\n AI tools make it easier for authoritarian governments to efficiently control their citizens in several ways. Face and voice recognition allow widespread surveillance. Machine learning, operating this data, can classify potential enemies of the state and prevent them from hiding. Recommendation systems can precisely target propaganda and misinformation for maximum effect. Deepfakes and generative AI aid in producing misinformation. Advanced AI can make authoritarian centralized decision making more competitive than liberal and decentralized systems such as markets. It lowers the cost and difficulty of digital warfare and advanced spyware.[251] All these technologies have been available since 2020 or earlier\u2014AI facial recognition systems are already being used for mass surveillance in China.[252][253]\n There many other ways that AI is expected to help bad actors, some of which can not be foreseen. For example, machine-learning AI is able to design tens of thousands of toxic molecules in a matter of hours.[254]\n Economists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.[255]\n In the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we're in uncharted territory\" with AI.[256] A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed.[257] Risk estimates vary; for example, in the 2010s, Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\".[p][259] The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies.[255] In April 2023, it was reported that 70% of the jobs for Chinese video game illustrators had been eliminated by generative artificial intelligence.[260][261]\n Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\".[262] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[263]\n From the early days of the development of artificial intelligence, there have been arguments, for example, those put forward by Joseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.[264]\n It has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist Stephen Hawking stated, \"spell the end of the human race\".[265] This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character.[q] These sci-fi scenarios are misleading in several ways.\n First, AI does not require human-like sentience to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of a paperclip factory manager).[267] Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can't fetch the coffee if you're dead.\"[268] In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity's morality and values so that it is \"fundamentally on our side\".[269]\n Second, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are built on language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.[270]\n The opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.[271] Personalities such as Stephen Hawking, Bill Gates, and Elon Musk,[272] as well as AI pioneers such as Yoshua Bengio, Stuart Russell, Demis Hassabis, and Sam Altman, have expressed concerns about existential risk from AI.\n In May 2023, Geoffrey Hinton announced his resignation from Google in order to be able to \"freely speak out about the risks of AI\" without \"considering how this impacts Google.\"[273] He notably mentioned risks of an AI takeover,[274] and stressed that in order to avoid the worst outcomes, establishing safety guidelines will require cooperation among those competing in use of AI.[275]\n In 2023, many leading AI experts endorsed the joint statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".[276]\n Some other researchers were more optimistic. AI pioneer J\u00fcrgen Schmidhuber did not sign the joint statement, emphasising that in 95% of all cases, AI research is about making \"human lives longer and healthier and easier.\"[277] While the tools that are now being used to improve lives can also be used by bad actors, \"they can also be used against the bad actors.\"[278][279] Andrew Ng also argued that \"it's a mistake to fall for the doomsday hype on AI\u2014and that regulators who do will only benefit vested interests.\"[280] Yann LeCun \"scoffs at his peers' dystopian scenarios of supercharged misinformation and even, eventually, human extinction.\"[281] In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.[282] However, after 2016, the study of current and future risks and possible solutions became a serious area of research.[283]\n Friendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.[284]\n Machines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.[285]\nThe field of machine ethics is also called computational morality,[285]\nand was founded at an AAAI symposium in 2005.[286]\n Other approaches include Wendell Wallach's \"artificial moral agents\"[287] and Stuart J. Russell's three principles for developing provably beneficial machines.[288]\n Active organizations in the AI open-source community include Hugging Face,[289] Google,[290] EleutherAI and Meta.[291] Various AI models, such as Llama 2, Mistral or Stable Diffusion, have been made open-weight,[292][293] meaning that their architecture and trained parameters (the \"weights\") are publicly available. Open-weight models can be freely fine-tuned, which allows companies to specialize them with their own data and for their own use-case.[294] Open-weight models are useful for research and innovation but can also be misused. Since they can be fine-tuned, any built-in security measure, such as objecting to harmful requests, can be trained away until it becomes ineffective. Some researchers warn that future AI models may develop dangerous capabilities (such as the potential to drastically facilitate bioterrorism) and that once released on the Internet, they cannot be deleted everywhere if needed. They recommend pre-release audits and cost-benefit analyses.[295]\n Artificial Intelligence projects can have their ethical permissibility tested while designing, developing, and implementing an AI system. An AI framework such as the Care and Act Framework containing the SUM values\u2014developed by the Alan Turing Institute tests projects in four main areas:[296][297]\n Other developments in ethical frameworks include those decided upon during the Asilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others;[298] however, these principles do not go without their criticisms, especially regards to the people chosen contributes to these frameworks.[299]\n Promotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers.[300]\n The UK AI Safety Institute released in 2024 a testing toolset called 'Inspect' for AI safety evaluations available under a MIT open-source licence which is freely available on GitHub and can be improved with third-party packages. It can be used to evaluate AI models in a range of areas including core knowledge, ability to reason, and autonomous capabilities.[301]\n The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI; it is therefore related to the broader regulation of algorithms.[302] The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally.[303] According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.[304][305] Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.[306] Most EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, U.S., and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.[306] The Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology.[306] Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI.[307] In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years.[308] In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, governments officials and academics.[309] In 2024, the Council of Europe created the first international legally binding treaty on AI, called the \"Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law\". It was adopted by the European Union, the United States, the United Kingdom, and other signatories.[310]\n In a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\".[304] A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.[311] In a 2023 Fox News poll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\".[312][313]\n In November 2023, the first global AI Safety Summit was held in Bletchley Park in the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks.[314] 28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence.[315][316] In May 2024 at the AI Seoul Summit, 16 global AI tech companies agreed to safety commitments on the development of AI.[317][318]\n The study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable form of mathematical reasoning.[319][320] This, along with concurrent discoveries in cybernetics, information theory and neurobiology, led researchers to consider the possibility of building an \"electronic brain\".[r] They developed several areas of research that would become part of AI,[322] such as McCullouch and Pitts design for \"artificial neurons\" in 1943,[115] and Turing's influential 1950 paper 'Computing Machinery and Intelligence', which introduced the Turing test and showed that \"machine intelligence\" was plausible.[323][320]\n The field of AI research was founded at a workshop at Dartmouth College in 1956.[s][6] The attendees became the leaders of AI research in the 1960s.[t] They and their students produced programs that the press described as \"astonishing\":[u] computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English.[v][7] Artificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s.[320]\n Researchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with general intelligence and considered this the goal of their field.[327] In 1965 Herbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\".[328] In 1967 Marvin Minsky agreed, writing that \"within a generation\u00a0... the problem of creating 'artificial intelligence' will substantially be solved\".[329] They had, however, underestimated the difficulty of the problem.[w] In 1974, both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill[331] and ongoing pressure from the U.S. Congress to fund more productive projects.[332] Minsky's and Papert's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether.[333] The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.[9]\n In the early 1980s, AI research was revived by the commercial success of expert systems,[334] a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research.[8] However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.[10]\n Up to this point, most of AI's funding had gone to projects that used high-level symbols to represent mental objects like plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition,[335] and began to look into \"sub-symbolic\" approaches.[336] Rodney Brooks rejected \"representation\" in general and focussed directly on engineering machines that move and survive.[x] Judea Pearl, Lofti Zadeh, and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic.[86][341] But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others.[342] In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.[343]\n AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics).[344] By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\" (a tendency known as the AI effect).[345]\nHowever, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.[4]\n Deep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.[11]\nFor many specific tasks, other methods were abandoned.[y]\nDeep learning's success was based on both hardware improvements (faster computers,[347] graphics processing units, cloud computing[348]) and access to large amounts of data[349] (including curated datasets,[348] such as ImageNet). Deep learning's success led to an enormous increase in interest and funding in AI.[z] The amount of machine learning research (measured by total publications) increased by 50% in the years 2015\u20132019.[306]\n In 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.[283]\n In the late teens and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015, AlphaGo, developed by DeepMind, beat the world champion Go player. The program taught only the game's rules and developed a strategy by itself. GPT-3 is a large language model that was released in 2020 by OpenAI and is capable of generating high-quality human-like text.[350] ChatGPT, launched on November 30, 2022, became the fastest-growing consumer software application in history, gaining over 100 million users in two months.[351] It marked what is widely regarded as AI's breakout year, bringing it into the public consciousness.[352] These programs, and others, inspired an aggressive AI boom, where large companies began investing billions of dollars in AI research. According to AI Impacts, about $50 billion annually was invested in \"AI\" around 2022 in the U.S. alone and about 20% of the new U.S. Computer Science PhD graduates have specialized in \"AI\".[353] About 800,000 \"AI\"-related U.S. job openings existed in 2022.[354] According to PitchBook research, 22% of newly funded startups in 2024 claimed to be AI companies.[355]\n Philosophical debates have historically sought to determine the nature of intelligence and how to make intelligent machines.[356] Another major focus has been whether machines can be conscious, and the associated ethical implications.[357] Many other topics in philosophy are relevant to AI, such as epistemology and free will.[358] Rapid advancements have intensified public discussions on the philosophy and ethics of AI.[357]\n Alan Turing wrote in 1950 \"I propose to consider the question 'can machines think'?\"[359] He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\".[359] He devised the Turing test, which measures the ability of a machine to simulate human conversation.[323] Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes that we can not determine these things about other people but \"it is usual to have a polite convention that everyone thinks.\"[360]\n Russell and Norvig agree with Turing that intelligence must be defined in terms of external behavior, not internal structure.[1] However, they are critical that the test requires the machine to imitate humans. \"Aeronautical engineering texts\", they wrote, \"do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons.'\"[362] AI founder John McCarthy agreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\".[363]\n McCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world\".[364] Another AI founder, Marvin Minsky similarly describes it as \"the ability to solve hard problems\".[365] The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals.[1] These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine\u2014and no other philosophical discussion is required, or may not even be possible.\n Another definition has been adopted by Google,[366] a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\n Some authors have suggested in practice, that the definition of AI is vague and difficult to define, with contention as to whether classical algorithms should be categorised as AI,[367] with many companies during the early 2020s AI boom using the term as a marketing buzzword, often even if they did \"not actually use AI in a material way\".[368]\n No established unifying theory or paradigm has guided AI research for most of its history.[aa] The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow. Critics argue that these questions may have to be revisited by future generations of AI researchers.\n Symbolic AI (or \"GOFAI\")[370] simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\"[371]\n However, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec's paradox is the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult.[372] Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge.[373] Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him.[ab][16]\n The issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence,[375][376] in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.\n \"Neats\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s,[377] but eventually was seen as irrelevant. Modern AI has elements of both.\n Finding a provably correct or optimal solution is intractable for many important problems.[15] Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\n AI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals.[378][379] General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The sub-field of artificial general intelligence studies this area exclusively.\n The philosophy of mind does not know whether a machine can have a mind, consciousness and mental states, in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\"[380] However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\n David Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness.[381] The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). While human information processing is easy to explain, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.[382]\n Computationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind\u2013body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.[383]\n Philosopher John Searle characterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\"[ac] Searle challenges this claim with his Chinese room argument, which attempts to show that even a computer capable of perfectly simulating human behavior would not have a mind.[387]\n It is difficult or impossible to reliably evaluate whether an advanced AI is sentient (has the ability to feel), and if so, to what degree.[388] But if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals.[389][390] Sapience (a set of capacities related to high intelligence, such as discernment or self-awareness) may provide another moral basis for AI rights.[389] Robot rights are also sometimes proposed as a practical way to integrate autonomous agents into society.[391]\n In 2017, the European Union considered granting \"electronic personhood\" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities.[392] Critics argued in 2018 that granting rights to AI systems would downplay the importance of human rights, and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part to society on their own.[393][394]\n Progress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be a moral blind spot analogous to slavery or factory farming, which could lead to large-scale suffering if sentient AI is created and carelessly exploited.[390][389]\n A superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.[379] If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".[395]\n However, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.[396]\n Robot designer Hans Moravec, cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines may merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in the writings of Aldous Huxley and Robert Ettinger.[397]\n Edward Fredkin argues that \"artificial intelligence is the next step in evolution\", an idea first proposed by Samuel Butler's \"Darwin among the Machines\" as far back as 1863, and expanded upon by George Dyson in his 1998 book Darwin Among the Machines: The Evolution of Global Intelligence.[398]\n Thought-capable artificial beings have appeared as storytelling devices since antiquity,[399] and have been a persistent theme in science fiction.[400]\n A common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.[401]\n Isaac Asimov introduced the Three Laws of Robotics in many stories, most notably with the \"Multivac\" super-intelligent computer. Asimov's laws are often brought up during lay discussions of machine ethics;[402] while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.[403]\n Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel \u010capek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.[404]\n The two most widely used textbooks in 2023 (see the Open Syllabus):\n The four most widely used AI textbooks in 2008:\n Other textbooks:\n",
        "Cleaned_Content": "artificial intelligence ai broadest sense intelligence exhibited machine particularly computer system field research computer science develops study method software enable machine perceive environment use learning intelligence take action maximize chance achieving defined goal 1 machine may called ai high profile application ai include advanced web search engine e g google search recommendation system used youtube amazon netflix virtual assistant e g google assistant siri alexa autonomous vehicle e g waymo generative creative tool e g chatgpt ai art superhuman play analysis strategy game e g chess go however many ai application perceived ai lot cutting edge ai filtered general application often without called ai something becomes useful enough common enough labeled ai anymore 2 3 various subfields ai research centered around particular goal use particular tool traditional goal ai research include reasoning knowledge representation planning learning natural language processing perception support robotics general intelligence ability complete task performed human least equal level among field long term goal 4 reach goal ai researcher adapted integrated wide range technique including search mathematical optimization formal logic artificial neural network method based statistic operation research economics b ai also draw upon psychology linguistics philosophy neuroscience field 5 artificial intelligence founded academic discipline 1956 6 field went multiple cycle optimism throughout history 7 8 followed period disappointment loss funding known ai winter 9 10 funding interest vastly increased 2012 deep learning outperformed previous ai technique 11 growth accelerated 2017 transformer architecture 12 early 2020s many billion dollar invested ai field experienced rapid ongoing progress become known ai boom emergence advanced generative ai midst ai boom ability create modify content exposed several unintended consequence harm present raised concern risk ai long term effect future prompting discussion regulatory policy ensure safety benefit technology general problem simulating creating intelligence broken subproblems consist particular trait capability researcher expect intelligent system display trait described received attention cover scope ai research early researcher developed algorithm imitated step step reasoning human use solve puzzle make logical deduction 13 late 1980s 1990s method developed dealing uncertain incomplete information employing concept probability economics 14 many algorithm insufficient solving large reasoning problem experience combinatorial explosion become exponentially slower problem grow 15 even human rarely use step step deduction early ai research could model solve problem using fast intuitive judgment 16 accurate efficient reasoning unsolved problem knowledge representation knowledge engineering 17 allow ai program answer question intelligently make deduction real world fact formal knowledge representation used content based indexing retrieval 18 scene interpretation 19 clinical decision support 20 knowledge discovery mining interesting actionable inference large database 21 area 22 knowledge base body knowledge represented form used program ontology set object relation concept property used particular domain knowledge 23 knowledge base need represent thing object property category relation object 24 situation event state time 25 cause effect 26 knowledge knowledge know people know 27 default reasoning thing human assume true told differently remain true even fact changing 28 many aspect domain knowledge among difficult problem knowledge representation breadth commonsense knowledge set atomic fact average person know enormous 29 sub symbolic form commonsense knowledge much people know represented fact statement could express verbally 16 also difficulty knowledge acquisition problem obtaining knowledge ai application c agent anything perceives take action world rational agent goal preference take action make happen 32 automated planning agent specific goal 33 automated decision making agent preference situation would prefer situation trying avoid decision making agent assigns number situation called utility measure much agent prefers possible action calculate expected utility utility possible outcome action weighted probability outcome occur choose action maximum expected utility 34 classical planning agent know exactly effect action 35 real world problem however agent may certain situation unknown unobservable may know certain happen possible action deterministic must choose action making probabilistic guess reassess situation see action worked 36 problem agent preference may uncertain especially agent human involved learned e g inverse reinforcement learning agent seek information improve preference 37 information value theory used weigh value exploratory experimental action 38 space possible future action situation typically intractably large agent must take action evaluate situation uncertain outcome markov decision process transition model describes probability particular action change state particular way reward function supply utility state cost action policy associate decision possible state policy could calculated e g iteration heuristic learned 39 game theory describes rational behavior multiple interacting agent used ai program make decision involve agent 40 machine learning study program improve performance given task automatically 41 part ai beginning e several kind machine learning unsupervised learning analyzes stream data find pattern make prediction without guidance 44 supervised learning requires labeling training data expected answer come two main variety classification program must learn predict category input belongs regression program must deduce numeric function based numeric input 45 reinforcement learning agent rewarded good response punished bad one agent learns choose response classified good 46 transfer learning knowledge gained one problem applied new problem 47 deep learning type machine learning run input biologically inspired artificial neural network type learning 48 computational learning theory ass learner computational complexity sample complexity much data required notion optimization 49 natural language processing nlp 50 allows program read write communicate human language english specific problem include speech recognition speech synthesis machine translation information extraction information retrieval question answering 51 early work based noam chomsky generative grammar semantic network difficulty word sense disambiguation f unless restricted small domain called micro world due common sense knowledge problem 29 margaret masterman believed meaning grammar key understanding language thesaurus dictionary basis computational language structure modern deep learning technique nlp include word embedding representing word typically vector encoding meaning 52 transformer deep learning architecture using attention mechanism 53 others 54 2019 generative pre trained transformer gpt language model began generate coherent text 55 56 2023 model able get human level score bar exam sat test gre test many real world application 57 machine perception ability use input sensor camera microphone wireless signal active lidar sonar radar tactile sensor deduce aspect world computer vision ability analyze visual input 58 field includes speech recognition 59 image classification 60 facial recognition object recognition 61 object tracking 62 robotic perception 63 affective computing field comprises system recognize interpret process simulate human feeling emotion mood 65 example virtual assistant programmed speak conversationally even banter humorously make appear sensitive emotional dynamic human interaction otherwise facilitate human computer interaction however tends give na\u00efve user unrealistic conception intelligence existing computer agent 66 moderate success related affective computing include textual sentiment analysis recently multimodal sentiment analysis wherein ai classifies effect displayed videotaped subject 67 machine artificial general intelligence able solve wide variety problem breadth versatility similar human intelligence 4 ai research us wide variety technique accomplish goal b ai solve many problem intelligently searching many possible solution 68 two different kind search used ai state space search local search state space search search tree possible state try find goal state 69 example planning algorithm search tree goal subgoals attempting find path target goal process called mean end analysis 70 simple exhaustive search 71 rarely sufficient real world problem search space number place search quickly grows astronomical number result search slow never completes 15 heuristic rule thumb help prioritize choice likely reach goal 72 adversarial search used game playing program chess go search tree possible move countermove looking winning position 73 local search us mathematical optimization find solution problem begin form guess refines incrementally 74 gradient descent type local search optimizes set numerical parameter incrementally adjusting minimize loss function variant gradient descent commonly used train neural network 75 backpropagation algorithm another type local search evolutionary computation aim iteratively improve set candidate solution mutating recombining selecting fittest survive generation 76 distributed search process coordinate via swarm intelligence algorithm two popular swarm algorithm used search particle swarm optimization inspired bird flocking ant colony optimization inspired ant trail 77 formal logic used reasoning knowledge representation 78 formal logic come two main form propositional logic operates statement true false us logical connective implies 79 predicate logic also operates object predicate relation us quantifier every x x y 80 deductive reasoning logic process proving new statement conclusion statement given assumed true premise 81 proof structured proof tree node labelled sentence child node connected parent node inference rule given problem set premise problem solving reduces searching proof tree whose root node labelled solution problem whose leaf node labelled premise axiom case horn clause problem solving search performed reasoning forward premise backwards problem 82 general case clausal form first order logic resolution single axiom free rule inference problem solved proving contradiction premise include negation problem solved 83 inference horn clause logic first order logic undecidable therefore intractable however backward reasoning horn clause underpins computation logic programming language prolog turing complete moreover efficiency competitive computation symbolic programming language 84 fuzzy logic assigns degree truth 0 1 therefore handle proposition vague partially true 85 non monotonic logic including logic programming negation failure designed handle default reasoning 28 specialized version logic developed describe many complex domain many problem ai including reasoning planning learning perception robotics require agent operate incomplete uncertain information ai researcher devised number tool solve problem using method probability theory economics 86 precise mathematical tool developed analyze agent make choice plan using decision theory decision analysis 87 information value theory 88 tool include model markov decision process 89 dynamic decision network 90 game theory mechanism design 91 bayesian network 92 tool used reasoning using bayesian inference algorithm g 94 learning using expectation maximization algorithm h 96 planning using decision network 97 perception using dynamic bayesian network 90 probabilistic algorithm also used filtering prediction smoothing finding explanation stream data thus helping perception system analyze process occur time e g hidden markov model kalman filter 90 simplest ai application divided two type classifier e g shiny diamond one hand controller e g diamond pick hand classifier 98 function use pattern matching determine closest match fine tuned based chosen example using supervised learning pattern also called observation labeled certain predefined class observation combined class label known data set new observation received observation classified based previous experience 45 many kind classifier use 99 decision tree simplest widely used symbolic machine learning algorithm 100 k nearest neighbor algorithm widely used analogical ai mid 1990s kernel method support vector machine svm displaced k nearest neighbor 1990s 101 naive bayes classifier reportedly widely used learner 102 google due part scalability 103 neural network also used classifier 104 artificial neural network based collection node also known artificial neuron loosely model neuron biological brain trained recognise pattern trained recognise pattern fresh data input least one hidden layer node output node applies function weight cross specified threshold data transmitted next layer network typically called deep neural network least 2 hidden layer 104 learning algorithm neural network use local search choose weight get right output input training common training technique backpropagation algorithm 105 neural network learn model complex relationship input output find pattern data theory neural network learn function 106 feedforward neural network signal pass one direction 107 recurrent neural network feed output signal back input allows short term memory previous input event long short term memory successful network architecture recurrent network 108 perceptrons 109 use single layer neuron deep learning 110 us multiple layer convolutional neural network strengthen connection neuron close especially important image processing local set neuron must identify edge network identify object 111 deep learning 110 us several layer neuron network input output multiple layer progressively extract higher level feature raw input example image processing lower layer may identify edge higher layer may identify concept relevant human digit letter face 112 deep learning profoundly improved performance program many important subfields artificial intelligence including computer vision speech recognition natural language processing image classification 113 others reason deep learning performs well many application known 2023 114 sudden success deep learning 2012 2015 occur new discovery theoretical breakthrough deep neural network backpropagation described many people far back 1950s two factor incredible increase computer power including hundred fold increase speed switching gpus availability vast amount training data especially giant curated datasets used benchmark testing imagenet j generative pre trained transformer gpt large language model llm generate text based semantic relationship word sentence text based gpt model pretrained large corpus text internet pretraining consists predicting next token token usually word subword punctuation throughout pretraining gpt model accumulate knowledge world generate human like text repeatedly predicting next token typically subsequent training phase make model truthful useful harmless usually technique called reinforcement learning human feedback rlhf current gpt model prone generating falsehood called hallucination although reduced rlhf quality data used chatbots allow people ask question request task simple text 122 123 current model service include gemini formerly bard chatgpt grok claude copilot llama 124 multimodal gpt model process different type data modality image video sound text 125 late 2010s graphic processing unit gpus increasingly designed ai specific enhancement used specialized tensorflow software replaced previously used central processing unit cpu dominant mean large scale commercial academic machine learning model training 126 specialized programming language prolog used early ai research 127 general purpose programming language like python become predominant 128 transistor density integrated circuit observed roughly double every 18 month trend known moore law named intel co founder gordon moore first identified improvement gpus even faster 129 ai machine learning technology used essential application 2020s including search engine google search targeting online advertisement recommendation system offered netflix youtube amazon driving internet traffic targeted advertising adsense facebook virtual assistant siri alexa autonomous vehicle including drone ada self driving car automatic language translation microsoft translator google translate facial recognition apple face id microsoft deepface google facenet image labeling used facebook apple iphoto tiktok deployment ai may overseen chief automation officer cao application ai medicine medical research potential increase patient care quality life 130 lens hippocratic oath medical professional ethically compelled use ai application accurately diagnose treat patient 131 132 medical research ai important tool processing integrating big data particularly important organoid tissue engineering development use microscopy imaging key technique fabrication 133 suggested ai overcome discrepancy funding allocated different field research 133 new ai tool deepen understanding biomedically relevant pathway example alphafold 2 2021 demonstrated ability approximate hour rather month 3d structure protein 134 2023 reported ai guided drug discovery helped find class antibiotic capable killing two different type drug resistant bacteria 135 2024 researcher used machine learning accelerate search parkinson disease drug treatment aim identify compound block clumping aggregation alpha synuclein protein characterises parkinson disease able speed initial screening process ten fold reduce cost thousand fold 136 137 application ai domain include ai enabled menstruation fertility tracker analyze user data offer prediction 138 ai integrated sex toy e g teledildonics 139 ai generated sexual education content 140 ai agent simulate sexual romantic partner e g replika 141 ai also used production non consensual deepfake pornography raising significant ethical legal concern 142 ai technology also used attempt identify online gender based violence online sexual grooming minor 143 144 game playing program used since 1950s demonstrate test ai advanced technique 145 deep blue became first computer chess playing system beat reigning world chess champion garry kasparov 11 may 1997 146 2011 jeopardy quiz show exhibition match ibm question answering system watson defeated two greatest jeopardy champion brad rutter ken jennings significant margin 147 march 2016 alphago 4 5 game go match go champion lee sedol becoming first computer go playing system beat professional go player without handicap 2017 defeated ke jie best go player world 148 program handle imperfect information game poker playing program pluribus 149 deepmind developed increasingly generalistic reinforcement learning model muzero could trained play chess go atari game 150 2019 deepmind alphastar achieved grandmaster level starcraft ii particularly challenging real time strategy game involves incomplete knowledge happens map 151 2021 ai agent competed playstation gran turismo competition winning four world best gran turismo driver using deep reinforcement learning 152 2024 google deepmind introduced sima type ai capable autonomously playing nine previously unseen open world video game observing screen output well executing short specific task response natural language instruction 153 mathematics special form formal step step reasoning used 154 contrast llm gpt 4 turbo gemini ultra claude opus llama 2 mistral large working probabilistic model produce wrong answer form hallucination therefore need large database mathematical problem learn also method supervised fine tuning trained classifier human annotated data improve answer new problem learn correction 155 2024 study showed performance language model reasoning capability solving math problem included training data low even problem minor deviation trained data 156 alternatively dedicated model mathematical problem solving higher precision outcome including proof theorem developed alpha tensor alpha geometry alpha proof google deepmind 157 llemma eleuther 158 julius 159 natural language used describe mathematical problem converter transform prompt formal language lean define mathematical task model developed solve challenging problem reach good result benchmark test others serve educational tool mathematics 160 finance one fastest growing sector applied ai tool deployed retail online banking investment advice insurance automated robot adviser use year 161 world pension expert like nicolas firzli insist may early see emergence highly innovative ai informed financial product service deployment ai tool simply automatise thing destroying ten thousand job banking financial planning pension advice process sure unleash new wave e g sophisticated pension innovation 162 various country deploying ai military application 163 main application enhance command control communication sensor integration interoperability 164 research targeting intelligence collection analysis logistics cyber operation information operation semiautonomous autonomous vehicle 163 ai technology enable coordination sensor effector threat detection identification marking enemy position target acquisition coordination deconfliction distributed joint fire networked combat vehicle involving manned unmanned team 164 ai used military operation iraq syria israel ukraine 163 165 166 167 early 2020s generative ai gained widespread prominence genai ai capable generating text image video data using generative model 168 169 often response prompt 170 171 march 2023 58 u adult heard chatgpt 14 tried 172 increasing realism ease use ai based text image generator midjourney dall e stable diffusion sparked trend viral ai generated photo widespread attention gained fake photo pope francis wearing white puffer coat fictional arrest donald trump hoax attack pentagon well usage professional creative art 173 174 artificial intelligent ai agent software entity designed perceive environment make decision take action autonomously achieve specific goal agent interact user environment agent ai agent used various application including virtual assistant chatbots autonomous vehicle game playing system industrial robotics ai agent operate within constraint programming available computational resource hardware limitation mean restricted performing task within defined scope finite memory processing capability real world application ai agent often face time constraint decision making action execution many ai agent incorporate learning algorithm enabling improve performance time experience training using machine learning ai agent adapt new situation optimise behaviour designated task 175 176 177 also thousand successful ai application used solve specific problem specific industry institution 2017 survey one five company reported incorporated ai offering process 178 example energy storage medical diagnosis military logistics application predict result judicial decision foreign policy supply chain management ai application evacuation disaster management growing ai used investigate people evacuated large scale small scale evacuation using historical data gps video social medium ai provide real time information real time evacuation condition 179 180 181 agriculture ai helped farmer identify area need irrigation fertilization pesticide treatment increasing yield agronomist use ai conduct research development ai used predict ripening time crop tomato monitor soil moisture operate agricultural robot conduct predictive analytics classify livestock pig call emotion automate greenhouse detect disease pest save water artificial intelligence used astronomy analyze increasing amount available data application mainly classification regression clustering forecasting generation discovery development new scientific insight example used discovering exoplanets forecasting solar activity distinguishing signal instrumental effect gravitational wave astronomy additionally could used activity space space exploration including analysis data space mission real time science decision spacecraft space debris avoidance autonomous operation 2024 indian election u 50 million spent authorized ai generated content notably creating deepfakes allied including sometimes deceased politician better engage voter translating speech various local language 182 ai potential benefit potential risk 183 ai may able advance science find solution serious problem demis hassabis deepmind hope solve intelligence use solve everything else 184 however use ai become widespread several unintended consequence risk identified 185 production system sometimes factor ethic bias ai training process especially ai algorithm inherently unexplainable deep learning 186 machine learning algorithm require large amount data technique used acquire data raised concern privacy surveillance copyright ai powered device service virtual assistant iot product continuously collect personal information raising concern intrusive data gathering unauthorized access third party loss privacy exacerbated ai ability process combine vast amount data potentially leading surveillance society individual activity constantly monitored analyzed without adequate safeguard transparency sensitive user data collected may include online activity record geolocation data video audio 187 example order build speech recognition algorithm amazon recorded million private conversation allowed temporary worker listen transcribe 188 opinion widespread surveillance range see necessary evil clearly unethical violation right privacy 189 ai developer argue way deliver valuable application developed several technique attempt preserve privacy still obtaining data data aggregation de identification differential privacy 190 since 2016 privacy expert cynthia dwork begun view privacy term fairness brian christian wrote expert pivoted question know question 191 generative ai often trained unlicensed copyrighted work including domain image computer code output used rationale fair use expert disagree well circumstance rationale hold court law relevant factor may include purpose character use copyrighted work effect upon potential market copyrighted work 192 193 website owner wish content scraped indicate robot txt file 194 2023 leading author including john grisham jonathan franzen sued ai company using work train generative ai 195 196 another discussed approach envision separate sui generis system protection creation generated ai ensure fair attribution compensation human author 197 commercial ai scene dominated big tech company alphabet inc amazon apple inc meta platform microsoft 198 199 200 player already vast majority existing cloud infrastructure computing power data center allowing entrench marketplace 201 202 january 2024 international energy agency iea released electricity 2024 analysis forecast 2026 forecasting electric power use 203 first iea report make projection data center power consumption artificial intelligence cryptocurrency report state power demand us might double 2026 additional electric power usage equal electricity used whole japanese nation 204 prodigious power consumption ai responsible growth fossil fuel use might delay closing obsolete carbon emitting coal energy facility feverish rise construction data center throughout u making large technology firm e g microsoft meta google amazon voracious consumer electric power projected electric consumption immense concern fulfilled matter source chatgpt search involves use 10 time electrical energy google search large firm haste find power source nuclear energy geothermal fusion tech firm argue long view ai eventually kinder environment need energy ai make power grid efficient intelligent assist growth nuclear power track overall carbon emission according technology firm 205 2024 goldman sachs research paper ai data center coming u power demand surge found u power demand likely experience growth seen generation forecast 2030 u data center consume 8 u power opposed 3 2022 presaging growth electrical power generation industry variety mean 206 data center need electrical power might max electrical grid big tech company counter ai used maximize utilization grid 207 2024 wall street journal reported big ai company begun negotiation u nuclear power provider provide electricity data center march 2024 amazon purchased pennsylvania nuclear powered data center 650 million u 208 nvidia ceo jen hsun huang said nuclear power good option data center 209 september 2024 microsoft announced agreement constellation energy open three mile island nuclear power plant provide microsoft 100 electric power produced plant 20 year reopening plant suffered partial nuclear meltdown unit 2 reactor 1979 require constellation get strict regulatory process include extensive safety scrutiny u nuclear regulatory commission approved first ever u commissioning nuclear plant 835 megawatt power enough 800 000 home energy produced cost opening upgrading estimated 1 6 billion u dependent tax break nuclear power contained 2022 u inflation reduction act 210 u government state michigan investing almost 2 billion u reopen palisade nuclear reactor lake michigan closed since 2022 plant planned reopened october 2025 three mile island facility renamed crane clean energy center chris crane nuclear proponent former ceo exelon responsible exelon spinoff constellation 211 last approval september 2023 taiwan suspended approval data center north taoyuan capacity 5 mw 2024 due power supply shortage 212 taiwan aim phase nuclear power 2025 212 hand singapore imposed ban opening data center 2019 due electric power 2022 lifted ban 212 although nuclear plant japan shut 2011 fukushima nuclear accident according october 2024 bloomberg article japanese cloud gaming service company ubitus nvidia stake looking land japan near nuclear power plant new data center generative ai 213 ubitus ceo wesley kuo said nuclear power plant efficient cheap stable power ai 213 1 november 2024 federal energy regulatory commission ferc rejected application submitted talen energy approval supply electricity nuclear power station susquehanna amazon data center 214 according commission chairman willie l phillips burden electricity grid well significant cost shifting concern household business sector 214 youtube facebook others use recommender system guide user content ai program given goal maximizing user engagement goal keep people watching ai learned user tended choose misinformation conspiracy theory extreme partisan content keep watching ai recommended user also tended watch content subject ai led people filter bubble received multiple version misinformation 215 convinced many user misinformation true ultimately undermined trust institution medium government 216 ai program correctly learned maximize goal result harmful society u election 2016 major technology company took step mitigate problem citation needed 2022 generative ai began create image audio video text indistinguishable real photograph recording film human writing possible bad actor use technology create massive amount misinformation propaganda 217 ai pioneer geoffrey hinton expressed concern ai enabling authoritarian leader manipulate electorate large scale among risk 218 machine learning application biased k learn biased data 220 developer may aware bias exists 221 bias introduced way training data selected way model deployed 222 220 biased algorithm used make decision seriously harm people medicine finance recruitment housing policing algorithm may cause discrimination 223 field fairness study prevent harm algorithmic bias june 28 2015 google photo new image labeling feature mistakenly identified jacky alcine friend gorilla black system trained dataset contained image black people 224 problem called sample size disparity 225 google fixed problem preventing system labelling anything gorilla eight year later 2023 google photo still could identify gorilla neither could similar product apple facebook microsoft amazon 226 compas commercial program widely used u court ass likelihood defendant becoming recidivist 2016 julia angwin propublica discovered compas exhibited racial bias despite fact program told race defendant although error rate white black calibrated equal exactly 61 error race different system consistently overestimated chance black person would offend would underestimate chance white person would offend 227 2017 several researcher l showed mathematically impossible compas accommodate possible measure fairness base rate offense different white black data 229 program make biased decision even data explicitly mention problematic feature race gender feature correlate feature like address shopping history first name program make decision based feature would race gender 230 moritz hardt said robust fact research area fairness blindness work 231 criticism compas highlighted machine learning model designed make prediction valid assume future resemble past trained data includes result racist decision past machine learning model must predict racist decision made future application us prediction recommendation recommendation likely racist 232 thus machine learning well suited help make decision area hope future better past descriptive rather prescriptive bias unfairness may go undetected developer overwhelmingly white male among ai engineer 4 black 20 woman 225 various conflicting definition mathematical model fairness notion depend ethical assumption influenced belief society one broad category distributive fairness focus outcome often identifying group seeking compensate statistical disparity representational fairness try ensure ai system reinforce negative stereotype render certain group invisible procedural fairness focus decision process rather outcome relevant notion fairness may depend context notably type ai application stakeholder subjectivity notion bias fairness make difficult company operationalize access sensitive attribute race gender also considered many ai ethicist necessary order compensate bias may conflict anti discrimination law 219 2022 conference fairness accountability transparency acm facct 2022 association computing machinery seoul south korea presented published finding recommend ai robotics system demonstrated free bias mistake unsafe use self learning neural network trained vast unregulated source flawed internet data curtailed dubious discus 234 many ai system complex designer explain reach decision 235 particularly deep neural network large amount non linear relationship input output popular explainability technique exist 236 impossible certain program operating correctly one know exactly work many case machine learning program passed rigorous test nevertheless learned something different programmer intended example system could identify skin disease better medical professional found actually strong tendency classify image ruler cancerous picture malignancy typically include ruler show scale 237 another machine learning system designed help effectively allocate medical resource found classify patient asthma low risk dying pneumonia asthma actually severe risk factor since patient asthma would usually get much medical care relatively unlikely die according training data correlation asthma low risk dying pneumonia real misleading 238 people harmed algorithm decision right explanation 239 doctor example expected clearly completely explain colleague reasoning behind decision make early draft european union general data protection regulation 2016 included explicit statement right exists n industry expert noted unsolved problem solution sight regulator argued nevertheless harm real problem solution tool used 240 darpa established xai explainable artificial intelligence program 2014 try solve problem 241 several approach aim address transparency problem shap enables visualise contribution feature output 242 lime locally approximate model output simpler interpretable model 243 multitask learning provides large number output addition target classification output help developer deduce network learned 244 deconvolution deepdream generative method allow developer see different layer deep network computer vision learned produce output suggest network learning 245 generative pre trained transformer anthropic developed technique based dictionary learning associate pattern neuron activation human understandable concept 246 artificial intelligence provides number tool useful bad actor authoritarian government terrorist criminal rogue state lethal autonomous weapon machine locates selects engages human target without human supervision widely available ai tool used bad actor develop inexpensive autonomous weapon produced scale potentially weapon mass destruction 248 even used conventional warfare currently reliably choose target could potentially kill innocent person 248 2014 30 nation including china supported ban autonomous weapon united nation convention certain conventional weapon however united state others disagreed 249 2015 fifty country reported researching battlefield robot 250 ai tool make easier authoritarian government efficiently control citizen several way face voice recognition allow widespread surveillance machine learning operating data classify potential enemy state prevent hiding recommendation system precisely target propaganda misinformation maximum effect deepfakes generative ai aid producing misinformation advanced ai make authoritarian centralized decision making competitive liberal decentralized system market lower cost difficulty digital warfare advanced spyware 251 technology available since 2020 earlier ai facial recognition system already used mass surveillance china 252 253 many way ai expected help bad actor foreseen example machine learning ai able design ten thousand toxic molecule matter hour 254 economist frequently highlighted risk redundancy ai speculated unemployment adequate social policy full employment 255 past technology tended increase rather reduce total employment economist acknowledge uncharted territory ai 256 survey economist showed disagreement whether increasing use robot ai cause substantial increase long term unemployment generally agree could net benefit productivity gain redistributed 257 risk estimate vary example 2010s michael osborne carl benedikt frey estimated 47 u job high risk potential automation oecd report classified 9 u job high risk p 259 methodology speculating future employment level criticised lacking evidential foundation implying technology rather social policy creates unemployment opposed redundancy 255 april 2023 reported 70 job chinese video game illustrator eliminated generative artificial intelligence 260 261 unlike previous wave automation many middle class job may eliminated artificial intelligence economist stated 2015 worry ai could white collar job steam power blue collar one industrial revolution worth taking seriously 262 job extreme risk range paralegal fast food cook job demand likely increase care related profession ranging personal healthcare clergy 263 early day development artificial intelligence argument example put forward joseph weizenbaum whether task done computer actually done given difference computer human quantitative calculation qualitative value based judgement 264 argued ai become powerful humanity may irreversibly lose control could physicist stephen hawking stated spell end human race 265 scenario common science fiction computer robot suddenly develops human like self awareness sentience consciousness becomes malevolent character q sci fi scenario misleading several way first ai require human like sentience existential risk modern ai program given specific goal use learning intelligence achieve philosopher nick bostrom argued one give almost goal sufficiently powerful ai may choose destroy humanity achieve used example paperclip factory manager 267 stuart russell give example household robot try find way kill owner prevent unplugged reasoning fetch coffee dead 268 order safe humanity superintelligence would genuinely aligned humanity morality value fundamentally side 269 second yuval noah harari argues ai require robot body physical control pose existential risk essential part civilization physical thing like ideology law government money economy built language exist story billion people believe current prevalence misinformation suggests ai could use language convince people believe anything even take action destructive 270 opinion amongst expert industry insider mixed sizable fraction concerned unconcerned risk eventual superintelligent ai 271 personality stephen hawking bill gate elon musk 272 well ai pioneer yoshua bengio stuart russell demis hassabis sam altman expressed concern existential risk ai may 2023 geoffrey hinton announced resignation google order able freely speak risk ai without considering impact google 273 notably mentioned risk ai takeover 274 stressed order avoid worst outcome establishing safety guideline require cooperation among competing use ai 275 2023 many leading ai expert endorsed joint statement mitigating risk extinction ai global priority alongside societal scale risk pandemic nuclear war 276 researcher optimistic ai pioneer j\u00fcrgen schmidhuber sign joint statement emphasising 95 case ai research making human life longer healthier easier 277 tool used improve life also used bad actor also used bad actor 278 279 andrew ng also argued mistake fall doomsday hype ai regulator benefit vested interest 280 yann lecun scoff peer dystopian scenario supercharged misinformation even eventually human extinction 281 early 2010s expert argued risk distant future warrant research human valuable perspective superintelligent machine 282 however 2016 study current future risk possible solution became serious area research 283 friendly ai machine designed beginning minimize risk make choice benefit human eliezer yudkowsky coined term argues developing friendly ai higher research priority may require large investment must completed ai becomes existential risk 284 machine intelligence potential use intelligence make ethical decision field machine ethic provides machine ethical principle procedure resolving ethical dilemma 285 field machine ethic also called computational morality 285 founded aaai symposium 2005 286 approach include wendell wallach artificial moral agent 287 stuart j russell three principle developing provably beneficial machine 288 active organization ai open source community include hugging face 289 google 290 eleutherai meta 291 various ai model llama 2 mistral stable diffusion made open weight 292 293 meaning architecture trained parameter weight publicly available open weight model freely fine tuned allows company specialize data use case 294 open weight model useful research innovation also misused since fine tuned built security measure objecting harmful request trained away becomes ineffective researcher warn future ai model may develop dangerous capability potential drastically facilitate bioterrorism released internet deleted everywhere needed recommend pre release audit cost benefit analysis 295 artificial intelligence project ethical permissibility tested designing developing implementing ai system ai framework care act framework containing sum value developed alan turing institute test project four main area 296 297 development ethical framework include decided upon asilomar conference montreal declaration responsible ai ieee ethic autonomous system initiative among others 298 however principle go without criticism especially regard people chosen contributes framework 299 promotion wellbeing people community technology affect requires consideration social ethical implication stage ai system design development implementation collaboration job role data scientist product manager data engineer domain expert delivery manager 300 uk ai safety institute released 2024 testing toolset called inspect ai safety evaluation available mit open source licence freely available github improved third party package used evaluate ai model range area including core knowledge ability reason autonomous capability 301 regulation artificial intelligence development public sector policy law promoting regulating ai therefore related broader regulation algorithm 302 regulatory policy landscape ai emerging issue jurisdiction globally 303 according ai index stanford annual number ai related law passed 127 survey country jumped one passed 2016 37 passed 2022 alone 304 305 2016 2020 30 country adopted dedicated strategy ai 306 eu member state released national ai strategy canada china india japan mauritius russian federation saudi arabia united arab emirate u vietnam others process elaborating ai strategy including bangladesh malaysia tunisia 306 global partnership artificial intelligence launched june 2020 stating need ai developed accordance human right democratic value ensure public confidence trust technology 306 henry kissinger eric schmidt daniel huttenlocher published joint statement november 2021 calling government commission regulate ai 307 2023 openai leader published recommendation governance superintelligence believe may happen le 10 year 308 2023 united nation also launched advisory body provide recommendation ai governance body comprises technology company executive government official academic 309 2024 council europe created first international legally binding treaty ai called framework convention artificial intelligence human right democracy rule law adopted european union united state united kingdom signatory 310 2022 ipsos survey attitude towards ai varied greatly country 78 chinese citizen 35 american agreed product service using ai benefit drawback 304 2023 reuters ipsos poll found 61 american agree 22 disagree ai pose risk humanity 311 2023 fox news poll 35 american thought important additional 41 thought somewhat important federal government regulate ai versus 13 responding important 8 responding important 312 313 november 2023 first global ai safety summit held bletchley park uk discus near far term risk ai possibility mandatory voluntary regulatory framework 314 28 country including united state china european union issued declaration start summit calling international co operation manage challenge risk artificial intelligence 315 316 may 2024 ai seoul summit 16 global ai tech company agreed safety commitment development ai 317 318 study mechanical formal reasoning began philosopher mathematician antiquity study logic led directly alan turing theory computation suggested machine shuffling symbol simple 0 1 could simulate conceivable form mathematical reasoning 319 320 along concurrent discovery cybernetics information theory neurobiology led researcher consider possibility building electronic brain r developed several area research would become part ai 322 mccullouch pitt design artificial neuron 1943 115 turing influential 1950 paper computing machinery intelligence introduced turing test showed machine intelligence plausible 323 320 field ai research founded workshop dartmouth college 1956 6 attendee became leader ai research 1960s student produced program press described astonishing u computer learning checker strategy solving word problem algebra proving logical theorem speaking english v 7 artificial intelligence laboratory set number british u university latter 1950s early 1960s 320 researcher 1960s 1970s convinced method would eventually succeed creating machine general intelligence considered goal field 327 1965 herbert simon predicted machine capable within twenty year work man 328 1967 marvin minsky agreed writing within generation problem creating artificial intelligence substantially solved 329 however underestimated difficulty problem w 1974 u british government cut exploratory research response criticism sir james lighthill 331 ongoing pressure u congress fund productive project 332 minsky papert book perceptrons understood proving artificial neural network would never useful solving real world task thus discrediting approach altogether 333 ai winter period obtaining funding ai project difficult followed 9 early 1980s ai research revived commercial success expert system 334 form ai program simulated knowledge analytical skill human expert 1985 market ai reached billion dollar time japan fifth generation computer project inspired u british government restore funding academic research 8 however beginning collapse lisp machine market 1987 ai fell disrepute second longer lasting winter began 10 point ai funding gone project used high level symbol represent mental object like plan goal belief known fact 1980s researcher began doubt approach would able imitate process human cognition especially perception robotics learning pattern recognition 335 began look sub symbolic approach 336 rodney brook rejected representation general focussed directly engineering machine move survive x judea pearl lofti zadeh others developed method handled incomplete uncertain information making reasonable guess rather precise logic 86 341 important development revival connectionism including neural network research geoffrey hinton others 342 1990 yann lecun successfully showed convolutional neural network recognize handwritten digit first many successful application neural network 343 ai gradually restored reputation late 1990s early 21st century exploiting formal mathematical method finding specific solution specific problem narrow formal focus allowed researcher produce verifiable result collaborate field statistic economics mathematics 344 2000 solution developed ai researcher widely used although 1990s rarely described artificial intelligence tendency known ai effect 345 however several academic researcher became concerned ai longer pursuing original goal creating versatile fully intelligent machine beginning around 2002 founded subfield artificial general intelligence agi several well funded institution 2010s 4 deep learning began dominate industry benchmark 2012 adopted throughout field 11 many specific task method abandoned deep learning success based hardware improvement faster computer 347 graphic processing unit cloud computing 348 access large amount data 349 including curated datasets 348 imagenet deep learning success led enormous increase interest funding ai z amount machine learning research measured total publication increased 50 year 2015 2019 306 2016 issue fairness misuse technology catapulted center stage machine learning conference publication vastly increased funding became available many researcher focussed career issue alignment problem became serious field academic study 283 late teen early 2020s agi company began deliver program created enormous interest 2015 alphago developed deepmind beat world champion go player program taught game rule developed strategy gpt 3 large language model released 2020 openai capable generating high quality human like text 350 chatgpt launched november 30 2022 became fastest growing consumer software application history gaining 100 million user two month 351 marked widely regarded ai breakout year bringing public consciousness 352 program others inspired aggressive ai boom large company began investing billion dollar ai research according ai impact 50 billion annually invested ai around 2022 u alone 20 new u computer science phd graduate specialized ai 353 800 000 ai related u job opening existed 2022 354 according pitchbook research 22 newly funded startup 2024 claimed ai company 355 philosophical debate historically sought determine nature intelligence make intelligent machine 356 another major focus whether machine conscious associated ethical implication 357 many topic philosophy relevant ai epistemology free 358 rapid advancement intensified public discussion philosophy ethic ai 357 alan turing wrote 1950 propose consider question machine think 359 advised changing question whether machine think whether possible machinery show intelligent behaviour 359 devised turing test measure ability machine simulate human conversation 323 since observe behavior machine matter actually thinking literally mind turing note determine thing people usual polite convention everyone think 360 russell norvig agree turing intelligence must defined term external behavior internal structure 1 however critical test requires machine imitate human aeronautical engineering text wrote define goal field making machine fly exactly like pigeon fool pigeon 362 ai founder john mccarthy agreed writing artificial intelligence definition simulation human intelligence 363 mccarthy defines intelligence computational part ability achieve goal world 364 another ai founder marvin minsky similarly describes ability solve hard problem 365 leading ai textbook defines study agent perceive environment take action maximize chance achieving defined goal 1 definition view intelligence term well defined problem well defined solution difficulty problem performance program direct measure intelligence machine philosophical discussion required may even possible another definition adopted google 366 major practitioner field ai definition stipulates ability system synthesize information manifestation intelligence similar way defined biological intelligence author suggested practice definition ai vague difficult define contention whether classical algorithm categorised ai 367 many company early 2020s ai boom using term marketing buzzword often even actually use ai material way 368 established unifying theory paradigm guided ai research history aa unprecedented success statistical machine learning 2010s eclipsed approach much source especially business world use term artificial intelligence mean machine learning neural network approach mostly sub symbolic soft narrow critic argue question may revisited future generation ai researcher symbolic ai gofai 370 simulated high level conscious reasoning people use solve puzzle express legal reasoning mathematics highly successful intelligent task algebra iq test 1960s newell simon proposed physical symbol system hypothesis physical symbol system necessary sufficient mean general intelligent action 371 however symbolic approach failed many task human solve easily learning recognizing object commonsense reasoning moravec paradox discovery high level intelligent task easy ai low level instinctive task extremely difficult 372 philosopher hubert dreyfus argued since 1960s human expertise depends unconscious instinct rather conscious symbol manipulation feel situation rather explicit symbolic knowledge 373 although argument ridiculed ignored first presented eventually ai research came agree ab 16 issue resolved sub symbolic reasoning make many inscrutable mistake human intuition algorithmic bias critic noam chomsky argue continuing research symbolic ai still necessary attain general intelligence 375 376 part sub symbolic ai move away explainable ai difficult impossible understand modern statistical ai program made particular decision emerging field neuro symbolic artificial intelligence attempt bridge two approach neats hope intelligent behavior described using simple elegant principle logic optimization neural network scruffies expect necessarily requires solving large number unrelated problem neats defend program theoretical rigor scruffies rely mainly incremental testing see work issue actively discussed 1970s 1980s 377 eventually seen irrelevant modern ai element finding provably correct optimal solution intractable many important problem 15 soft computing set technique including genetic algorithm fuzzy logic neural network tolerant imprecision uncertainty partial truth approximation soft computing introduced late 1980s successful ai program 21st century example soft computing neural network ai researcher divided whether pursue goal artificial general intelligence superintelligence directly solve many specific problem possible narrow ai hope solution lead indirectly field long term goal 378 379 general intelligence difficult define difficult measure modern ai verifiable success focusing specific problem specific solution sub field artificial general intelligence study area exclusively philosophy mind know whether machine mind consciousness mental state sense human being issue considers internal experience machine rather external behavior mainstream ai research considers issue irrelevant affect goal field build machine solve problem using intelligence russell norvig add additional project making machine conscious exactly way human one equipped take 380 however question become central philosophy mind also typically central question issue artificial intelligence fiction david chalmers identified two problem understanding mind named hard easy problem consciousness 381 easy problem understanding brain process signal make plan control behavior hard problem explaining feel feel like anything assuming right thinking truly feel like something dennett consciousness illusionism say illusion human information processing easy explain human subjective experience difficult explain example easy imagine color blind person learned identify object field view red clear would required person know red look like 382 computationalism position philosophy mind human mind information processing system thinking form computing computationalism argues relationship mind body similar identical relationship software hardware thus may solution mind body problem philosophical position inspired work ai researcher cognitive scientist 1960s originally proposed philosopher jerry fodor hilary putnam 383 philosopher john searle characterized position strong ai appropriately programmed computer right input output would thereby mind exactly sense human being mind ac searle challenge claim chinese room argument attempt show even computer capable perfectly simulating human behavior would mind 387 difficult impossible reliably evaluate whether advanced ai sentient ability feel degree 388 significant chance given machine feel suffer may entitled certain right welfare protection measure similarly animal 389 390 sapience set capacity related high intelligence discernment self awareness may provide another moral basis ai right 389 robot right also sometimes proposed practical way integrate autonomous agent society 391 2017 european union considered granting electronic personhood capable ai system similarly legal status company would conferred right also responsibility 392 critic argued 2018 granting right ai system would downplay importance human right legislation focus user need rather speculative futuristic scenario also noted robot lacked autonomy take part society 393 394 progress ai increased interest topic proponent ai welfare right often argue ai sentience emerges would particularly easy deny warn may moral blind spot analogous slavery factory farming could lead large scale suffering sentient ai created carelessly exploited 390 389 superintelligence hypothetical agent would posse intelligence far surpassing brightest gifted human mind 379 research artificial general intelligence produced sufficiently intelligent software might able reprogram improve improved software would even better improving leading j good called intelligence explosion vernor vinge called singularity 395 however technology improve exponentially indefinitely typically follow shaped curve slowing reach physical limit technology 396 robot designer han moravec cyberneticist kevin warwick inventor ray kurzweil predicted human machine may merge future cyborg capable powerful either idea called transhumanism root writing aldous huxley robert ettinger 397 edward fredkin argues artificial intelligence next step evolution idea first proposed samuel butler darwin among machine far back 1863 expanded upon george dyson 1998 book darwin among machine evolution global intelligence 398 thought capable artificial being appeared storytelling device since antiquity 399 persistent theme science fiction 400 common trope work began mary shelley frankenstein human creation becomes threat master includes work arthur c clarke stanley kubrick 2001 space odyssey 1968 hal 9000 murderous computer charge discovery one spaceship well terminator 1984 matrix 1999 contrast rare loyal robot gort day earth stood still 1951 bishop alien 1986 le prominent popular culture 401 isaac asimov introduced three law robotics many story notably multivac super intelligent computer asimov law often brought lay discussion machine ethic 402 almost artificial intelligence researcher familiar asimov law popular culture generally consider law useless many reason one ambiguity 403 several work use ai force u confront fundamental question make u human showing u artificial being ability feel thus suffer appears karel \u010dapek r u r film artificial intelligence ex machina well novel android dream electric sheep philip k dick dick considers idea understanding human subjectivity altered technology created artificial intelligence 404 two widely used textbook 2023 see open syllabus four widely used ai textbook 2008 textbook"
    },
    {
        "Title": "Wikipedia, the free encyclopedia",
        "URL": "https://en.wikipedia.org/wiki/Main_Page",
        "Content": "The cherry-throated tanager (Nemosia rourei) is a critically endangered bird native to the Atlantic Forest in Brazil. Since its description in 1870, there had been no confirmed sightings for more than 100 years, and it was feared that the species was extinct. It was rediscovered in 1998 in the state of Esp\u00edrito Santo. By the end of 2023, 20 individuals were known and the total population was estimated to be less than 50 birds. The main threat to its survival is the large-scale destruction of the old-growth rainforest that it requires, and in 2018 it was estimated that the species was restricted to a total area of just 31 km2 (12\u00a0sq\u00a0mi). It has a striking gray, black and white plumage, with a distinctive red throat patch. The yellow or dark amber eyes contrast with a black face mask. Its call is clear and far-carrying. A social species, it lives in flocks of up to eight birds. The birds breed once a year, building a cup nest of beard lichen and spider web; nests contain two or three eggs. (Full\u00a0article...)\n January 15: John Chilembwe Day in Malawi \n Rhinanthus angustifolius, the narrow-leaved rattle or greater yellow-rattle, is a species of plant of the genus Rhinanthus, in the broomrape family, Orobanchaceae. It is an annual wildflower, native to temperate grasslands in much of Europe, and north and central Western Asia. The yellow flowers are mostly visited by bumblebees. This R.\u00a0angustifolius inflorescence was photographed in Kulna, Estonia. The photograph was focus-stacked from 80 separate images.\n Photograph credit: Ivar Leidus Wikipedia is written by volunteer editors and hosted by the Wikimedia Foundation, a non-profit organization that also hosts a range of other volunteer projects:\n This Wikipedia is written in English. Many other Wikipedias are available; some of the largest are listed below.\n",
        "Cleaned_Content": "cherry throated tanager nemosia rourei critically endangered bird native atlantic forest brazil since description 1870 confirmed sighting 100 year feared specie extinct rediscovered 1998 state esp\u00edrito santo end 2023 20 individual known total population estimated le 50 bird main threat survival large scale destruction old growth rainforest requires 2018 estimated specie restricted total area 31 km2 12 sq mi striking gray black white plumage distinctive red throat patch yellow dark amber eye contrast black face mask call clear far carrying social specie life flock eight bird bird breed year building cup nest beard lichen spider web nest contain two three egg full article january 15 john chilembwe day malawi rhinanthus angustifolius narrow leaved rattle greater yellow rattle specie plant genus rhinanthus broomrape family orobanchaceae annual wildflower native temperate grassland much europe north central western asia yellow flower mostly visited bumblebee r angustifolius inflorescence photographed kulna estonia photograph focus stacked 80 separate image photograph credit ivar leidus wikipedia written volunteer editor hosted wikimedia foundation non profit organization also host range volunteer project wikipedia written english many wikipedias available largest listed"
    },
    {
        "Title": "Ai - Wikipedia",
        "URL": "https://en.wikipedia.org/wiki/AI_(disambiguation)",
        "Content": "\n AI most frequently refers to artificial intelligence, which is intelligence demonstrated by machines.\n Ai, AI or A.I. may also refer to:\n",
        "Cleaned_Content": "ai frequently refers artificial intelligence intelligence demonstrated machine ai ai may also refer"
    },
    {
        "Title": "Artificial intelligence (disambiguation) - Wikipedia",
        "URL": "https://en.wikipedia.org/wiki/Artificial_intelligence_(disambiguation)",
        "Content": "Artificial intelligence is the intelligence exhibited by machines and software.\n Artificial intelligence may also refer to:\n",
        "Cleaned_Content": "artificial intelligence intelligence exhibited machine software artificial intelligence may also refer"
    },
    {
        "Title": "Artificial general intelligence - Wikipedia",
        "URL": "https://en.wikipedia.org/wiki/Artificial_general_intelligence",
        "Content": "\n Artificial general intelligence (AGI) is a type of artificial intelligence (AI) that matches or surpasses human cognitive capabilities across a wide range of cognitive tasks. This contrasts with narrow AI, which is limited to specific tasks.[1] Artificial superintelligence (ASI), on the other hand, refers to AGI that greatly exceeds human cognitive capabilities. AGI is considered one of the definitions of strong AI.\n Creating AGI is a primary goal of AI research and of companies such as OpenAI[2] and Meta.[3] A 2020 survey identified 72 active AGI research and development projects across 37 countries.[4]\n The timeline for achieving AGI remains a subject of ongoing debate among researchers and experts. As of 2023, some argue that it may be possible in years or decades; others maintain it might take a century or longer; a minority believe it may never be achieved; and another minority claims that it is already here.[5][6] Notable AI researcher Geoffrey Hinton has expressed concerns about the rapid progress towards AGI, suggesting it could be achieved sooner than many expect.[7]\n There is debate on the exact definition of AGI and regarding whether modern large language models (LLMs) such as GPT-4 are early forms of AGI.[8] AGI is a common topic in science fiction and futures studies.[9][10]\n Contention exists over whether AGI represents an existential risk.[11][12][13] Many experts on AI have stated that mitigating the risk of human extinction posed by AGI should be a global priority.[14][15] Others find the development of AGI to be too remote to present such a risk.[16][17]\n AGI is also known as strong AI,[18][19] full AI,[20] human-level AI,[5] human-level intelligent AI, or general intelligent action.[21]\n Some academic sources reserve the term \"strong AI\" for computer programs that experience sentience or consciousness.[a] In contrast, weak AI (or narrow AI) is able to solve one specific problem but lacks general cognitive abilities.[22][19] Some academic sources use \"weak AI\" to refer more broadly to any programs that neither experience consciousness nor have a mind in the same sense as humans.[a]\n Related concepts include artificial superintelligence and transformative AI. An artificial superintelligence (ASI) is a hypothetical type of AGI that is much more generally intelligent than humans,[23] while the notion of transformative AI relates to AI having a large impact on society, for example, similar to the agricultural or industrial revolution.[24]\n A framework for classifying AGI in levels was proposed in 2023 by Google DeepMind researchers. They define five levels of AGI: emerging, competent, expert, virtuoso, and superhuman. For example, a competent AGI is defined as an AI that outperforms 50% of skilled adults in a wide range of non-physical tasks, and a superhuman AGI (i.e. an artificial superintelligence) is similarly defined but with a threshold of 100%. They consider large language models like ChatGPT or LLaMA 2 to be instances of emerging AGI.[25]\n Various popular definitions of intelligence have been proposed. One of the leading proposals is the Turing test. However, there are other well-known definitions, and some researchers disagree with the more popular approaches. [b]\n However, researchers generally hold that intelligence is required to do all of the following:[27]\n Many interdisciplinary approaches (e.g. cognitive science, computational intelligence, and decision making) consider additional traits such as imagination (the ability to form novel mental images and concepts)[28] and autonomy.[29]\n Computer-based systems that exhibit many of these capabilities exist (e.g. see computational creativity, automated reasoning, decision support system, robot, evolutionary computation, intelligent agent). There is debate about whether modern AI systems possess them to an adequate degree.\n Other capabilities are considered desirable in intelligent systems, as they may affect intelligence or aid in its expression. These include:[30]\n This includes the ability to detect and respond to hazard.[31]\n Although the ability to sense (e.g. see, hear, etc.) and the ability to act (e.g. move and manipulate objects, change location to explore, etc.) can be desirable for some intelligent systems,[30] these physical capabilities are not strictly required for an entity to qualify as AGI\u2014particularly under the thesis that large language models (LLMs) may already be or become AGI. Even from a less optimistic perspective on LLMs, there is no firm requirement for an AGI to have a human-like form; being a silicon-based computational system is sufficient, provided it can process input (language) from the external world in place of human senses. This interpretation aligns with the understanding that AGI has never been proscribed a particular physical embodiment and thus does not demand a capacity for locomotion or traditional \"eyes and ears\".[32]\n Several tests meant to confirm human-level AGI have been considered, including:[33][34]\n The idea of the test is that the machine has to try and pretend to be a man, by answering questions put to it, and it will only pass if the pretence is reasonably convincing. A considerable portion of a jury, who should not be expert about machines, must be taken in by the pretence.[37] A problem is informally called \"AI-complete\" or \"AI-hard\" if it is believed that in order to solve it, one would need to implement AGI, because the solution is beyond the capabilities of a purpose-specific algorithm.[47]\n There are many problems that have been conjectured to require general intelligence to solve as well as humans. Examples include computer vision, natural language understanding, and dealing with unexpected circumstances while solving any real-world problem.[48] Even a specific task like translation requires a machine to read and write in both languages, follow the author's argument (reason), understand the context (knowledge), and faithfully reproduce the author's original intent (social intelligence). All of these problems need to be solved simultaneously in order to reach human-level machine performance.\n However, many of these tasks can now be performed by modern large language models. According to Stanford University's 2024 AI index, AI has reached human-level performance on many benchmarks for reading comprehension and visual reasoning.[49]\n Modern AI research began in the mid-1950s.[50] The first generation of AI researchers were convinced that artificial general intelligence was possible and that it would exist in just a few decades.[51] AI pioneer Herbert A. Simon wrote in 1965: \"machines will be capable, within twenty years, of doing any work a man can do.\"[52]\n Their predictions were the inspiration for Stanley Kubrick and Arthur C. Clarke's character HAL 9000, who embodied what AI researchers believed they could create by the year 2001. AI pioneer Marvin Minsky was a consultant[53] on the project of making HAL 9000 as realistic as possible according to the consensus predictions of the time. He said in 1967, \"Within a generation... the problem of creating 'artificial intelligence' will substantially be solved\".[54]\n Several classical AI projects, such as Doug Lenat's Cyc project (that began in 1984), and Allen Newell's Soar project, were directed at AGI.\n However, in the early 1970s, it became obvious that researchers had grossly underestimated the difficulty of the project. Funding agencies became skeptical of AGI and put researchers under increasing pressure to produce useful \"applied AI\".[c] In the early 1980s, Japan's Fifth Generation Computer Project revived interest in AGI, setting out a ten-year timeline that included AGI goals like \"carry on a casual conversation\".[58] In response to this and the success of expert systems, both industry and government pumped money into the field.[56][59] However, confidence in AI spectacularly collapsed in the late 1980s, and the goals of the Fifth Generation Computer Project were never fulfilled.[60] For the second time in 20 years, AI researchers who predicted the imminent achievement of AGI had been mistaken. By the 1990s, AI researchers had a reputation for making vain promises. They became reluctant to make predictions at all[d] and avoided mention of \"human level\" artificial intelligence for fear of being labeled \"wild-eyed dreamer[s]\".[62]\n In the 1990s and early 21st century, mainstream AI achieved commercial success and academic respectability by focusing on specific sub-problems where AI can produce verifiable results and commercial applications, such as speech recognition and recommendation algorithms.[63] These \"applied AI\" systems are now used extensively throughout the technology industry, and research in this vein is heavily funded in both academia and industry. As of 2018[update], development in this field was considered an emerging trend, and a mature stage was expected to be reached in more than 10 years.[64]\n \nAt the turn of the century, many mainstream AI researchers[65] hoped that strong AI could be developed by combining programs that solve various sub-problems. Hans Moravec wrote in 1988:  I am confident that this bottom-up route to artificial intelligence will one day meet the traditional top-down route more than half way, ready to provide the real-world competence and the commonsense knowledge that has been so frustratingly elusive in reasoning programs. Fully intelligent machines will result when the metaphorical golden spike is driven uniting the two efforts.[65] \nHowever, even at the time, this was disputed. For example, Stevan Harnad of Princeton University concluded his 1990 paper on the symbol grounding hypothesis by stating:  The expectation has often been voiced that \"top-down\" (symbolic) approaches to modeling cognition will somehow meet \"bottom-up\" (sensory) approaches somewhere in between. If the grounding considerations in this paper are valid, then this expectation is hopelessly modular and there is really only one viable route from sense to symbols: from the ground up. A free-floating symbolic level like the software level of a computer will never be reached by this route (or vice versa) \u2013 nor is it clear why we should even try to reach such a level, since it looks as if getting there would just amount to uprooting our symbols from their intrinsic meanings (thereby merely reducing ourselves to the functional equivalent of a programmable computer).[66] The term \"artificial general intelligence\" was used as early as 1997, by Mark Gubrud[67] in a discussion of the implications of fully automated military production and operations. A mathematical formalism of AGI was proposed by Marcus Hutter in 2000. Named AIXI, the proposed AGI agent maximises \"the ability to satisfy goals in a wide range of environments\".[68] This type of AGI, characterized by the ability to maximise a mathematical definition of intelligence rather than exhibit human-like behaviour,[69] was also called universal artificial intelligence.[70]\n The term AGI was re-introduced and popularized by Shane Legg and Ben Goertzel around 2002.[71] AGI research activity in 2006 was described by Pei Wang and Ben Goertzel[72] as \"producing publications and preliminary results\". The first summer school in AGI was organized in Xiamen, China in 2009[73] by the Xiamen university's Artificial Brain Laboratory and OpenCog. The first university course was given in 2010[74] and 2011[75] at Plovdiv University, Bulgaria by Todor Arnaudov. MIT presented a course on AGI in 2018, organized by Lex Fridman and featuring a number of guest lecturers.\n As of 2023[update], a small number of computer scientists are active in AGI research, and many contribute to a series of AGI conferences. However, increasingly more researchers are interested in open-ended learning,[76][77] which is the idea of allowing AI to continuously learn and innovate like humans do.\n As of 2023, the development and potential achievement of AGI remains a subject of intense debate within the AI community. While traditional consensus held that AGI was a distant goal, recent advancements have led some researchers and industry figures to claim that early forms of AGI may already exist.[78] AI pioneer Herbert A. Simon speculated in 1965 that \"machines will be capable, within twenty years, of doing any work a man can do\". This prediction failed to come true. Microsoft co-founder Paul Allen believed that such intelligence is unlikely in the 21st century because it would require \"unforeseeable and fundamentally unpredictable breakthroughs\" and a \"scientifically deep understanding of cognition\".[79] Writing in The Guardian, roboticist Alan Winfield claimed the gulf between modern computing and human-level artificial intelligence is as wide as the gulf between current space flight and practical faster-than-light spaceflight.[80]\n A further challenge is the lack of clarity in defining what intelligence entails. Does it require consciousness? Must it display the ability to set goals as well as pursue them? Is it purely a matter of scale such that if model sizes increase sufficiently, intelligence will emerge? Are facilities such as planning, reasoning, and causal understanding required? Does intelligence require explicitly replicating the brain and its specific faculties? Does it require emotions?[81]\n Most AI researchers believe strong AI can be achieved in the future, but some thinkers, like Hubert Dreyfus and Roger Penrose, deny the possibility of achieving strong AI.[82][83] John McCarthy is among those who believe human-level AI will be accomplished, but that the present level of progress is such that a date cannot accurately be predicted.[84] AI experts' views on the feasibility of AGI wax and wane. Four polls conducted in 2012 and 2013 suggested that the median estimate among experts for when they would be 50% confident AGI would arrive was 2040 to 2050, depending on the poll, with the mean being 2081. Of the experts, 16.5% answered with \"never\" when asked the same question but with a 90% confidence instead.[85][86] Further current AGI progress considerations can be found above Tests for confirming human-level AGI.\n A report by Stuart Armstrong and Kaj Sotala of the Machine Intelligence Research Institute found that \"over [a] 60-year time frame there is a strong bias towards predicting the arrival of human-level AI as between 15 and 25 years from the time the prediction was made\". They analyzed 95 predictions made between 1950 and 2012 on when human-level AI will come about.[87]\n In 2023, Microsoft researchers published a detailed evaluation of GPT-4. They concluded: \"Given the breadth and depth of GPT-4\u2019s capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system.\"[88] Another study in 2023 reported that GPT-4 outperforms 99% of humans on the Torrance tests of creative thinking.[89][90]\n Blaise Ag\u00fcera y Arcas and Peter Norvig wrote in 2023 that a significant level of general intelligence has already been achieved with frontier models. They wrote that reluctance to this view comes from four main reasons: a \"healthy skepticism about metrics for AGI\", an \"ideological commitment to alternative AI theories or techniques\", a \"devotion to human (or biological) exceptionalism\", or a \"concern about the economic implications of AGI\".[91]\n 2023 also marked the emergence of large multimodal models (large language models capable of processing or generating multiple modalities such as text, audio, and images).[92]\n In 2024, OpenAI released o1-preview, the first of a series of models that \"spend more time thinking before they respond\". According to Mira Murati, this ability to think before responding represents a new, additional paradigm. It improves model outputs by spending more computing power when generating the answer, whereas the model scaling paradigm improves outputs by increasing the model size, training data and training compute power.[93][94]\n An OpenAI employee, Vahid Kazemi, claimed in 2024 that the company had achieved AGI, stating, \"In my opinion, we have already achieved AGI and it\u2019s even more clear with O1.\" Kazemi clarified that while the AI is not yet \"better than any human at any task\", it is \"better than most humans at most tasks.\" He also addressed criticisms that large language models (LLMs) merely follow predefined patterns, comparing their learning process to the scientific method of observing, hypothesizing, and verifying. These statements have sparked debate, as they rely on a broad and unconventional definition of AGI\u2014traditionally understood as AI that matches human intelligence across all domains. Critics argue that, while OpenAI's models demonstrate remarkable versatility, they may not fully meet this standard. Notably, Kazemi's comments came shortly after OpenAI removed \"AGI\" from the terms of its partnership with Microsoft, prompting speculation about the company\u2019s strategic intentions.[95]\n Progress in artificial intelligence has historically gone through periods of rapid progress separated by periods when progress appeared to stop.[82] Ending each hiatus were fundamental advances in hardware, software or both to create space for further progress.[82][98][99] For example, the computer hardware available in the twentieth century was not sufficient to implement deep learning, which requires large numbers of GPU-enabled CPUs.[100]\n In the introduction to his 2006 book,[101] Goertzel says that estimates of the time needed before a truly flexible AGI is built vary from 10 years to over a century. As of 2007[update], the consensus in the AGI research community seemed to be that the timeline discussed by Ray Kurzweil in 2005 in The Singularity is Near[102] (i.e. between 2015 and 2045) was plausible.[103] Mainstream AI researchers have given a wide range of opinions on whether progress will be this rapid. A 2012 meta-analysis of 95 such opinions found a bias towards predicting that the onset of AGI would occur within 16\u201326 years for modern and historical predictions alike. That paper has been criticized for how it categorized opinions as expert or non-expert.[104]\n In 2012, Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton developed a neural network called AlexNet, which won the ImageNet competition with a top-5 test error rate of 15.3%, significantly better than the second-best entry's rate of 26.3% (the traditional approach used a weighted sum of scores from different pre-defined classifiers).[105] AlexNet was regarded as the initial ground-breaker of the current deep learning wave.[105]\n In 2017, researchers Feng Liu, Yong Shi, and Ying Liu conducted intelligence tests on publicly available and freely accessible weak AI such as Google AI, Apple's Siri, and others. At the maximum, these AIs reached an IQ value of about 47, which corresponds approximately to a six-year-old child in first grade. An adult comes to about 100 on average. Similar tests were carried out in 2014, with the IQ score reaching a maximum value of 27.[106][107]\n In 2020, OpenAI developed GPT-3, a language model capable of performing many diverse tasks without specific training. According to Gary Grossman in a VentureBeat article, while there is consensus that GPT-3 is not an example of AGI, it is considered by some to be too advanced to be classified as a narrow AI system.[108]\n In the same year, Jason Rohrer used his GPT-3 account to develop a chatbot, and provided a chatbot-developing platform called \"Project December\". OpenAI asked for changes to the chatbot to comply with their safety guidelines; Rohrer disconnected Project December from the GPT-3 API.[109]\n In 2022, DeepMind developed Gato, a \"general-purpose\" system capable of performing more than 600 different tasks.[110]\n In 2023, Microsoft Research published a study on an early version of OpenAI's GPT-4, contending that it exhibited more general intelligence than previous AI models and demonstrated human-level performance in tasks spanning multiple domains, such as mathematics, coding, and law. This research sparked a debate on whether GPT-4 could be considered an early, incomplete version of artificial general intelligence, emphasizing the need for further exploration and evaluation of such systems.[111]\n In 2023, the AI researcher Geoffrey Hinton stated that:[112]\n The idea that this stuff could actually get smarter than people \u2013 a few people believed that, [...]. But most people thought it was way off. And I thought it was way off. I thought it was 30 to 50 years or even longer away. Obviously, I no longer think that. In May 2023, Demis Hassabis similarly said that \"The progress in the last few years has been pretty incredible\", and that he sees no reason why it would slow down, expecting AGI within a decade or even a few years.[113] In March 2024, Nvidia's CEO, Jensen Huang, stated his expectation that within five years, AI would be capable of passing any test at least as well as humans.[114] In June 2024, the AI researcher Leopold Aschenbrenner, a former OpenAI employee, estimated AGI by 2027 to be \"strikingly plausible\".[115]\n While the development of transformer models like in ChatGPT is considered the most promising path to AGI,[116][117] whole brain emulation can serve as an alternative approach. With whole brain simulation, a brain model is built by scanning and mapping a biological brain in detail, and then copying and simulating it on a computer system or another computational device. The simulation model must be sufficiently faithful to the original, so that it behaves in practically the same way as the original brain.[118] Whole brain emulation is a type of brain simulation that is discussed in computational neuroscience and neuroinformatics, and for medical research purposes. It has been discussed in artificial intelligence research[103] as an approach to strong AI. Neuroimaging technologies that could deliver the necessary detailed understanding are improving rapidly, and futurist Ray Kurzweil in the book The Singularity Is Near[102] predicts that a map of sufficient quality will become available on a similar timescale to the computing power required to emulate it.\n  For low-level brain simulation, a very powerful cluster of computers or GPUs would be required, given the enormous quantity of synapses within the human brain. Each of the 1011 (one hundred billion) neurons has on average 7,000 synaptic connections (synapses) to other neurons. The brain of a three-year-old child has about 1015 synapses (1 quadrillion). This number declines with age, stabilizing by adulthood. Estimates vary for an adult, ranging from 1014 to 5\u00d71014 synapses (100 to 500 trillion).[120] An estimate of the brain's processing power, based on a simple switch model for neuron activity, is around 1014 (100 trillion) synaptic updates per second (SUPS).[121]\n In 1997, Kurzweil looked at various estimates for the hardware required to equal the human brain and adopted a figure of 1016 computations per second (cps).[e] (For comparison, if a \"computation\" was equivalent to one \"floating-point operation\" \u2013 a measure used to rate current supercomputers \u2013 then 1016 \"computations\" would be equivalent to 10 petaFLOPS, achieved in 2011, while 1018 was achieved in 2022.) He used this figure to predict the necessary hardware would be available sometime between 2015 and 2025, if the exponential growth in computer power at the time of writing continued.\n The Human Brain Project, an EU-funded initiative active from 2013 to 2023, has developed a particularly detailed and publicly accessible atlas of the human brain.[124] In 2023, researchers from Duke University performed a high-resolution scan of a mouse brain.\n The artificial neuron model assumed by Kurzweil and used in many current artificial neural network implementations is simple compared with biological neurons. A brain simulation would likely have to capture the detailed cellular behaviour of biological neurons, presently understood only in broad outline. The overhead introduced by full modeling of the biological, chemical, and physical details of neural behaviour (especially on a molecular scale) would require computational powers several orders of magnitude larger than Kurzweil's estimate. In addition, the estimates do not account for glial cells, which are known to play a role in cognitive processes.[125]\n A fundamental criticism of the simulated brain approach derives from embodied cognition theory which asserts that human embodiment is an essential aspect of human intelligence and is necessary to ground meaning.[126][127] If this theory is correct, any fully functional brain model will need to encompass more than just the neurons (e.g., a robotic body). Goertzel[103] proposes virtual embodiment (like in metaverses like Second Life) as an option, but it is unknown whether this would be sufficient.\n In 1980, philosopher John Searle coined the term \"strong AI\" as part of his Chinese room argument.[128] He proposed a distinction between two hypotheses about artificial intelligence:[f]\n The first one he called \"strong\" because it makes a stronger statement: it assumes something special has happened to the machine that goes beyond those abilities that we can test. The behaviour of a \"weak AI\" machine would be precisely identical to a \"strong AI\" machine, but the latter would also have subjective conscious experience. This usage is also common in academic AI research and textbooks.[129]\n In contrast to Searle and mainstream AI, some futurists such as Ray Kurzweil use the term \"strong AI\" to mean \"human level artificial general intelligence\".[102] This is not the same as Searle's strong AI, unless it is assumed that consciousness is necessary for human-level AGI. Academic philosophers such as Searle do not believe that is the case, and to most artificial intelligence researchers the question is out-of-scope.[130]\n Mainstream AI is most interested in how a program behaves.[131] According to Russell and Norvig, \"as long as the program works, they don't care if you call it real or a simulation.\"[130] If the program can behave as if it has a mind, then there is no need to know if it actually has mind \u2013 indeed, there would be no way to tell. For AI research, Searle's \"weak AI hypothesis\" is equivalent to the statement \"artificial general intelligence is possible\". Thus, according to Russell and Norvig, \"most AI researchers take the weak AI hypothesis for granted, and don't care about the strong AI hypothesis.\"[130] Thus, for academic AI research, \"Strong AI\" and \"AGI\" are two different things.\n Consciousness can have various meanings, and some aspects play significant roles in science fiction and the ethics of artificial intelligence:\n These traits have a moral dimension. AI sentience would give rise to concerns of welfare and legal protection, similarly to animals.[136] Other aspects of consciousness related to cognitive capabilities are also relevant to the concept of AI rights.[137] Figuring out how to integrate advanced AI with existing legal and social frameworks is an emergent issue.[138]\n AGI could have a wide variety of applications. If oriented towards such goals, AGI could help mitigate various problems in the world such as hunger, poverty and health problems.[139]\n AGI could improve productivity and efficiency in most jobs. For example, in public health, AGI could accelerate medical research, notably against cancer.[140] It could take care of the elderly,[141] and democratize access to rapid, high-quality medical diagnostics. It could offer fun, cheap and personalized education.[141] The need to work to subsist could become obsolete if the wealth produced is properly redistributed.[141][142] This also raises the question of the place of humans in a radically automated society.\n AGI could also help to make rational decisions, and to anticipate and prevent disasters. It could also help to reap the benefits of potentially catastrophic technologies such as nanotechnology or climate engineering, while avoiding the associated risks.[143] If an AGI's primary goal is to prevent existential catastrophes such as human extinction (which could be difficult if the Vulnerable World Hypothesis turns out to be true),[144] it could take measures to drastically reduce the risks[143] while minimizing the impact of these measures on our quality of life.\n AGI may represent multiple types of existential risk, which are risks that threaten \"the premature extinction of Earth-originating intelligent life or the permanent and drastic destruction of its potential for desirable future development\".[145] The risk of human extinction from AGI has been the topic of many debates, but there is also the possibility that the development of AGI would lead to a permanently flawed future. Notably, it could be used to spread and preserve the set of values of whoever develops it. If humanity still has moral blind spots similar to slavery in the past, AGI might irreversibly entrench it, preventing moral progress.[146] Furthermore, AGI could facilitate mass surveillance and indoctrination, which could be used to create a stable repressive worldwide totalitarian regime.[147][148] There is also a risk for the machines themselves. If machines that are sentient or otherwise worthy of moral consideration are mass created in the future, engaging in a civilizational path that indefinitely neglects their welfare and interests could be an existential catastrophe.[149][150] Considering how much AGI could improve humanity's future and help reduce other existential risks, Toby Ord calls these existential risks \"an argument for proceeding with due caution\", not for \"abandoning AI\".[147]\n The thesis that AI poses an existential risk for humans, and that this risk needs more attention, is controversial but has been endorsed in 2023 by many public figures, AI researchers and CEOs of AI companies such as Elon Musk, Bill Gates, Geoffrey Hinton, Yoshua Bengio, Demis Hassabis and Sam Altman.[151][152]\n In 2014, Stephen Hawking criticized widespread indifference:\n So, facing possible futures of incalculable benefits and risks, the experts are surely doing everything possible to ensure the best outcome, right? Wrong. If a superior alien civilisation sent us a message saying, 'We'll arrive in a few decades,' would we just reply, 'OK, call us when you get here\u2014we'll leave the lights on?' Probably not\u2014but this is more or less what is happening with AI.[153] The potential fate of humanity has sometimes been compared to the fate of gorillas threatened by human activities. The comparison states that greater intelligence allowed humanity to dominate gorillas, which are now vulnerable in ways that they could not have anticipated. As a result, the gorilla has become an endangered species, not out of malice, but simply as a collateral damage from human activities.[154]\n The skeptic Yann LeCun considers that AGIs will have no desire to dominate humanity and that we should be careful not to anthropomorphize them and interpret their intents as we would for humans. He said that people won't be \"smart enough to design super-intelligent machines, yet ridiculously stupid to the point of giving it moronic objectives with no safeguards\".[155] On the other side, the concept of instrumental convergence suggests that almost whatever their goals, intelligent agents will have reasons to try to survive and acquire more power as intermediary steps to achieving these goals. And that this does not require having emotions.[156]\n Many scholars who are concerned about existential risk advocate for more research into solving the \"control problem\" to answer the question: what types of safeguards, algorithms, or architectures can programmers implement to maximise the probability that their recursively-improving AI would continue to behave in a friendly, rather than destructive, manner after it reaches superintelligence?[157][158] Solving the control problem is complicated by the AI arms race (which could lead to a race to the bottom of safety precautions in order to release products before competitors),[159] and the use of AI in weapon systems.[160]\n The thesis that AI can pose existential risk also has detractors. Skeptics usually say that AGI is unlikely in the short-term, or that concerns about AGI distract from other issues related to current AI.[161] Former Google fraud czar Shuman Ghosemajumder considers that for many people outside of the technology industry, existing chatbots and LLMs are already perceived as though they were AGI, leading to further misunderstanding and fear.[162]\n Skeptics sometimes charge that the thesis is crypto-religious, with an irrational belief in the possibility of superintelligence replacing an irrational belief in an omnipotent God.[163] Some researchers believe that the communication campaigns on AI existential risk by certain AI groups (such as OpenAI, Anthropic, DeepMind, and Conjecture) may be an at attempt at regulatory capture and to inflate interest in their products.[164][165]\n In 2023, the CEOs of Google DeepMind, OpenAI and Anthropic, along with other industry leaders and researchers, issued a joint statement asserting that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.\"[152]\n Researchers from OpenAI estimated that \"80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of LLMs, while around 19% of workers may see at least 50% of their tasks impacted\".[166][167] They consider office workers to be the most exposed, for example mathematicians, accountants or web designers.[167] AGI could have a better autonomy, ability to make decisions, to interface with other computer tools, but also to control robotized bodies.\n According to Stephen Hawking, the outcome of automation on the quality of life will depend on how the wealth will be redistributed:[142]\n Everyone can enjoy a life of luxurious leisure if the machine-produced wealth is shared, or most people can end up miserably poor if the machine-owners successfully lobby against wealth redistribution. So far, the trend seems to be toward the second option, with technology driving ever-increasing inequality Elon Musk considers that the automation of society will require governments to adopt a universal basic income.[168]\n",
        "Cleaned_Content": "artificial general intelligence agi type artificial intelligence ai match surpasses human cognitive capability across wide range cognitive task contrast narrow ai limited specific task 1 artificial superintelligence asi hand refers agi greatly exceeds human cognitive capability agi considered one definition strong ai creating agi primary goal ai research company openai 2 meta 3 2020 survey identified 72 active agi research development project across 37 country 4 timeline achieving agi remains subject ongoing debate among researcher expert 2023 argue may possible year decade others maintain might take century longer minority believe may never achieved another minority claim already 5 6 notable ai researcher geoffrey hinton expressed concern rapid progress towards agi suggesting could achieved sooner many expect 7 debate exact definition agi regarding whether modern large language model llm gpt 4 early form agi 8 agi common topic science fiction future study 9 10 contention exists whether agi represents existential risk 11 12 13 many expert ai stated mitigating risk human extinction posed agi global priority 14 15 others find development agi remote present risk 16 17 agi also known strong ai 18 19 full ai 20 human level ai 5 human level intelligent ai general intelligent action 21 academic source reserve term strong ai computer program experience sentience consciousness contrast weak ai narrow ai able solve one specific problem lack general cognitive ability 22 19 academic source use weak ai refer broadly program neither experience consciousness mind sense human related concept include artificial superintelligence transformative ai artificial superintelligence asi hypothetical type agi much generally intelligent human 23 notion transformative ai relates ai large impact society example similar agricultural industrial revolution 24 framework classifying agi level proposed 2023 google deepmind researcher define five level agi emerging competent expert virtuoso superhuman example competent agi defined ai outperforms 50 skilled adult wide range non physical task superhuman agi e artificial superintelligence similarly defined threshold 100 consider large language model like chatgpt llama 2 instance emerging agi 25 various popular definition intelligence proposed one leading proposal turing test however well known definition researcher disagree popular approach b however researcher generally hold intelligence required following 27 many interdisciplinary approach e g cognitive science computational intelligence decision making consider additional trait imagination ability form novel mental image concept 28 autonomy 29 computer based system exhibit many capability exist e g see computational creativity automated reasoning decision support system robot evolutionary computation intelligent agent debate whether modern ai system posse adequate degree capability considered desirable intelligent system may affect intelligence aid expression include 30 includes ability detect respond hazard 31 although ability sense e g see hear etc ability act e g move manipulate object change location explore etc desirable intelligent system 30 physical capability strictly required entity qualify agi particularly thesis large language model llm may already become agi even le optimistic perspective llm firm requirement agi human like form silicon based computational system sufficient provided process input language external world place human sens interpretation aligns understanding agi never proscribed particular physical embodiment thus demand capacity locomotion traditional eye ear 32 several test meant confirm human level agi considered including 33 34 idea test machine try pretend man answering question put pas pretence reasonably convincing considerable portion jury expert machine must taken pretence 37 problem informally called ai complete ai hard believed order solve one would need implement agi solution beyond capability purpose specific algorithm 47 many problem conjectured require general intelligence solve well human example include computer vision natural language understanding dealing unexpected circumstance solving real world problem 48 even specific task like translation requires machine read write language follow author argument reason understand context knowledge faithfully reproduce author original intent social intelligence problem need solved simultaneously order reach human level machine performance however many task performed modern large language model according stanford university 2024 ai index ai reached human level performance many benchmark reading comprehension visual reasoning 49 modern ai research began mid 1950s 50 first generation ai researcher convinced artificial general intelligence possible would exist decade 51 ai pioneer herbert simon wrote 1965 machine capable within twenty year work man 52 prediction inspiration stanley kubrick arthur c clarke character hal 9000 embodied ai researcher believed could create year 2001 ai pioneer marvin minsky consultant 53 project making hal 9000 realistic possible according consensus prediction time said 1967 within generation problem creating artificial intelligence substantially solved 54 several classical ai project doug lenat cyc project began 1984 allen newell soar project directed agi however early 1970s became obvious researcher grossly underestimated difficulty project funding agency became skeptical agi put researcher increasing pressure produce useful applied ai c early 1980s japan fifth generation computer project revived interest agi setting ten year timeline included agi goal like carry casual conversation 58 response success expert system industry government pumped money field 56 59 however confidence ai spectacularly collapsed late 1980s goal fifth generation computer project never fulfilled 60 second time 20 year ai researcher predicted imminent achievement agi mistaken 1990s ai researcher reputation making vain promise became reluctant make prediction avoided mention human level artificial intelligence fear labeled wild eyed dreamer 62 1990s early 21st century mainstream ai achieved commercial success academic respectability focusing specific sub problem ai produce verifiable result commercial application speech recognition recommendation algorithm 63 applied ai system used extensively throughout technology industry research vein heavily funded academia industry 2018 update development field considered emerging trend mature stage expected reached 10 year 64 turn century many mainstream ai researcher 65 hoped strong ai could developed combining program solve various sub problem han moravec wrote 1988 confident bottom route artificial intelligence one day meet traditional top route half way ready provide real world competence commonsense knowledge frustratingly elusive reasoning program fully intelligent machine result metaphorical golden spike driven uniting two effort 65 however even time disputed example stevan harnad princeton university concluded 1990 paper symbol grounding hypothesis stating expectation often voiced top symbolic approach modeling cognition somehow meet bottom sensory approach somewhere grounding consideration paper valid expectation hopelessly modular really one viable route sense symbol ground free floating symbolic level like software level computer never reached route vice versa clear even try reach level since look getting would amount uprooting symbol intrinsic meaning thereby merely reducing functional equivalent programmable computer 66 term artificial general intelligence used early 1997 mark gubrud 67 discussion implication fully automated military production operation mathematical formalism agi proposed marcus hutter 2000 named aixi proposed agi agent maximises ability satisfy goal wide range environment 68 type agi characterized ability maximise mathematical definition intelligence rather exhibit human like behaviour 69 also called universal artificial intelligence 70 term agi introduced popularized shane legg ben goertzel around 2002 71 agi research activity 2006 described pei wang ben goertzel 72 producing publication preliminary result first summer school agi organized xiamen china 2009 73 xiamen university artificial brain laboratory opencog first university course given 2010 74 2011 75 plovdiv university bulgaria todor arnaudov mit presented course agi 2018 organized lex fridman featuring number guest lecturer 2023 update small number computer scientist active agi research many contribute series agi conference however increasingly researcher interested open ended learning 76 77 idea allowing ai continuously learn innovate like human 2023 development potential achievement agi remains subject intense debate within ai community traditional consensus held agi distant goal recent advancement led researcher industry figure claim early form agi may already exist 78 ai pioneer herbert simon speculated 1965 machine capable within twenty year work man prediction failed come true microsoft co founder paul allen believed intelligence unlikely 21st century would require unforeseeable fundamentally unpredictable breakthrough scientifically deep understanding cognition 79 writing guardian roboticist alan winfield claimed gulf modern computing human level artificial intelligence wide gulf current space flight practical faster light spaceflight 80 challenge lack clarity defining intelligence entail require consciousness must display ability set goal well pursue purely matter scale model size increase sufficiently intelligence emerge facility planning reasoning causal understanding required intelligence require explicitly replicating brain specific faculty require emotion 81 ai researcher believe strong ai achieved future thinker like hubert dreyfus roger penrose deny possibility achieving strong ai 82 83 john mccarthy among believe human level ai accomplished present level progress date accurately predicted 84 ai expert view feasibility agi wax wane four poll conducted 2012 2013 suggested median estimate among expert would 50 confident agi would arrive 2040 2050 depending poll mean 2081 expert 16 5 answered never asked question 90 confidence instead 85 86 current agi progress consideration found test confirming human level agi report stuart armstrong kaj sotala machine intelligence research institute found 60 year time frame strong bias towards predicting arrival human level ai 15 25 year time prediction made analyzed 95 prediction made 1950 2012 human level ai come 87 2023 microsoft researcher published detailed evaluation gpt 4 concluded given breadth depth gpt 4 capability believe could reasonably viewed early yet still incomplete version artificial general intelligence agi system 88 another study 2023 reported gpt 4 outperforms 99 human torrance test creative thinking 89 90 blaise ag\u00fcera arca peter norvig wrote 2023 significant level general intelligence already achieved frontier model wrote reluctance view come four main reason healthy skepticism metric agi ideological commitment alternative ai theory technique devotion human biological exceptionalism concern economic implication agi 91 2023 also marked emergence large multimodal model large language model capable processing generating multiple modality text audio image 92 2024 openai released o1 preview first series model spend time thinking respond according mira murati ability think responding represents new additional paradigm improves model output spending computing power generating answer whereas model scaling paradigm improves output increasing model size training data training compute power 93 94 openai employee vahid kazemi claimed 2024 company achieved agi stating opinion already achieved agi even clear o1 kazemi clarified ai yet better human task better human task also addressed criticism large language model llm merely follow predefined pattern comparing learning process scientific method observing hypothesizing verifying statement sparked debate rely broad unconventional definition agi traditionally understood ai match human intelligence across domain critic argue openai model demonstrate remarkable versatility may fully meet standard notably kazemi comment came shortly openai removed agi term partnership microsoft prompting speculation company strategic intention 95 progress artificial intelligence historically gone period rapid progress separated period progress appeared stop 82 ending hiatus fundamental advance hardware software create space progress 82 98 99 example computer hardware available twentieth century sufficient implement deep learning requires large number gpu enabled cpu 100 introduction 2006 book 101 goertzel say estimate time needed truly flexible agi built vary 10 year century 2007 update consensus agi research community seemed timeline discussed ray kurzweil 2005 singularity near 102 e 2015 2045 plausible 103 mainstream ai researcher given wide range opinion whether progress rapid 2012 meta analysis 95 opinion found bias towards predicting onset agi would occur within 16 26 year modern historical prediction alike paper criticized categorized opinion expert non expert 104 2012 alex krizhevsky ilya sutskever geoffrey hinton developed neural network called alexnet imagenet competition top 5 test error rate 15 3 significantly better second best entry rate 26 3 traditional approach used weighted sum score different pre defined classifier 105 alexnet regarded initial ground breaker current deep learning wave 105 2017 researcher feng liu yong shi ying liu conducted intelligence test publicly available freely accessible weak ai google ai apple siri others maximum ai reached iq value 47 corresponds approximately six year old child first grade adult come 100 average similar test carried 2014 iq score reaching maximum value 27 106 107 2020 openai developed gpt 3 language model capable performing many diverse task without specific training according gary grossman venturebeat article consensus gpt 3 example agi considered advanced classified narrow ai system 108 year jason rohrer used gpt 3 account develop chatbot provided chatbot developing platform called project december openai asked change chatbot comply safety guideline rohrer disconnected project december gpt 3 api 109 2022 deepmind developed gato general purpose system capable performing 600 different task 110 2023 microsoft research published study early version openai gpt 4 contending exhibited general intelligence previous ai model demonstrated human level performance task spanning multiple domain mathematics coding law research sparked debate whether gpt 4 could considered early incomplete version artificial general intelligence emphasizing need exploration evaluation system 111 2023 ai researcher geoffrey hinton stated 112 idea stuff could actually get smarter people people believed people thought way thought way thought 30 50 year even longer away obviously longer think may 2023 demis hassabis similarly said progress last year pretty incredible see reason would slow expecting agi within decade even year 113 march 2024 nvidia ceo jensen huang stated expectation within five year ai would capable passing test least well human 114 june 2024 ai researcher leopold aschenbrenner former openai employee estimated agi 2027 strikingly plausible 115 development transformer model like chatgpt considered promising path agi 116 117 whole brain emulation serve alternative approach whole brain simulation brain model built scanning mapping biological brain detail copying simulating computer system another computational device simulation model must sufficiently faithful original behaves practically way original brain 118 whole brain emulation type brain simulation discussed computational neuroscience neuroinformatics medical research purpose discussed artificial intelligence research 103 approach strong ai neuroimaging technology could deliver necessary detailed understanding improving rapidly futurist ray kurzweil book singularity near 102 predicts map sufficient quality become available similar timescale computing power required emulate low level brain simulation powerful cluster computer gpus would required given enormous quantity synapsis within human brain 1011 one hundred billion neuron average 7 000 synaptic connection synapsis neuron brain three year old child 1015 synapsis 1 quadrillion number decline age stabilizing adulthood estimate vary adult ranging 1014 5 1014 synapsis 100 500 trillion 120 estimate brain processing power based simple switch model neuron activity around 1014 100 trillion synaptic update per second sup 121 1997 kurzweil looked various estimate hardware required equal human brain adopted figure 1016 computation per second cps e comparison computation equivalent one floating point operation measure used rate current supercomputer 1016 computation would equivalent 10 petaflops achieved 2011 1018 achieved 2022 used figure predict necessary hardware would available sometime 2015 2025 exponential growth computer power time writing continued human brain project eu funded initiative active 2013 2023 developed particularly detailed publicly accessible atlas human brain 124 2023 researcher duke university performed high resolution scan mouse brain artificial neuron model assumed kurzweil used many current artificial neural network implementation simple compared biological neuron brain simulation would likely capture detailed cellular behaviour biological neuron presently understood broad outline overhead introduced full modeling biological chemical physical detail neural behaviour especially molecular scale would require computational power several order magnitude larger kurzweil estimate addition estimate account glial cell known play role cognitive process 125 fundamental criticism simulated brain approach derives embodied cognition theory asserts human embodiment essential aspect human intelligence necessary ground meaning 126 127 theory correct fully functional brain model need encompass neuron e g robotic body goertzel 103 proposes virtual embodiment like metaverses like second life option unknown whether would sufficient 1980 philosopher john searle coined term strong ai part chinese room argument 128 proposed distinction two hypothesis artificial intelligence f first one called strong make stronger statement assumes something special happened machine go beyond ability test behaviour weak ai machine would precisely identical strong ai machine latter would also subjective conscious experience usage also common academic ai research textbook 129 contrast searle mainstream ai futurist ray kurzweil use term strong ai mean human level artificial general intelligence 102 searle strong ai unless assumed consciousness necessary human level agi academic philosopher searle believe case artificial intelligence researcher question scope 130 mainstream ai interested program behaves 131 according russell norvig long program work care call real simulation 130 program behave mind need know actually mind indeed would way tell ai research searle weak ai hypothesis equivalent statement artificial general intelligence possible thus according russell norvig ai researcher take weak ai hypothesis granted care strong ai hypothesis 130 thus academic ai research strong ai agi two different thing consciousness various meaning aspect play significant role science fiction ethic artificial intelligence trait moral dimension ai sentience would give rise concern welfare legal protection similarly animal 136 aspect consciousness related cognitive capability also relevant concept ai right 137 figuring integrate advanced ai existing legal social framework emergent issue 138 agi could wide variety application oriented towards goal agi could help mitigate various problem world hunger poverty health problem 139 agi could improve productivity efficiency job example public health agi could accelerate medical research notably cancer 140 could take care elderly 141 democratize access rapid high quality medical diagnostics could offer fun cheap personalized education 141 need work subsist could become obsolete wealth produced properly redistributed 141 142 also raise question place human radically automated society agi could also help make rational decision anticipate prevent disaster could also help reap benefit potentially catastrophic technology nanotechnology climate engineering avoiding associated risk 143 agi primary goal prevent existential catastrophe human extinction could difficult vulnerable world hypothesis turn true 144 could take measure drastically reduce risk 143 minimizing impact measure quality life agi may represent multiple type existential risk risk threaten premature extinction earth originating intelligent life permanent drastic destruction potential desirable future development 145 risk human extinction agi topic many debate also possibility development agi would lead permanently flawed future notably could used spread preserve set value whoever develops humanity still moral blind spot similar slavery past agi might irreversibly entrench preventing moral progress 146 furthermore agi could facilitate mass surveillance indoctrination could used create stable repressive worldwide totalitarian regime 147 148 also risk machine machine sentient otherwise worthy moral consideration mass created future engaging civilizational path indefinitely neglect welfare interest could existential catastrophe 149 150 considering much agi could improve humanity future help reduce existential risk toby ord call existential risk argument proceeding due caution abandoning ai 147 thesis ai pose existential risk human risk need attention controversial endorsed 2023 many public figure ai researcher ceo ai company elon musk bill gate geoffrey hinton yoshua bengio demis hassabis sam altman 151 152 2014 stephen hawking criticized widespread indifference facing possible future incalculable benefit risk expert surely everything possible ensure best outcome right wrong superior alien civilisation sent u message saying arrive decade would reply ok call u get leave light probably le happening ai 153 potential fate humanity sometimes compared fate gorilla threatened human activity comparison state greater intelligence allowed humanity dominate gorilla vulnerable way could anticipated result gorilla become endangered specie malice simply collateral damage human activity 154 skeptic yann lecun considers agis desire dominate humanity careful anthropomorphize interpret intent would human said people smart enough design super intelligent machine yet ridiculously stupid point giving moronic objective safeguard 155 side concept instrumental convergence suggests almost whatever goal intelligent agent reason try survive acquire power intermediary step achieving goal require emotion 156 many scholar concerned existential risk advocate research solving control problem answer question type safeguard algorithm architecture programmer implement maximise probability recursively improving ai would continue behave friendly rather destructive manner reach superintelligence 157 158 solving control problem complicated ai arm race could lead race bottom safety precaution order release product competitor 159 use ai weapon system 160 thesis ai pose existential risk also detractor skeptic usually say agi unlikely short term concern agi distract issue related current ai 161 former google fraud czar shuman ghosemajumder considers many people outside technology industry existing chatbots llm already perceived though agi leading misunderstanding fear 162 skeptic sometimes charge thesis crypto religious irrational belief possibility superintelligence replacing irrational belief omnipotent god 163 researcher believe communication campaign ai existential risk certain ai group openai anthropic deepmind conjecture may attempt regulatory capture inflate interest product 164 165 2023 ceo google deepmind openai anthropic along industry leader researcher issued joint statement asserting mitigating risk extinction ai global priority alongside societal scale risk pandemic nuclear war 152 researcher openai estimated 80 u workforce could least 10 work task affected introduction llm around 19 worker may see least 50 task impacted 166 167 consider office worker exposed example mathematician accountant web designer 167 agi could better autonomy ability make decision interface computer tool also control robotized body according stephen hawking outcome automation quality life depend wealth redistributed 142 everyone enjoy life luxurious leisure machine produced wealth shared people end miserably poor machine owner successfully lobby wealth redistribution far trend seems toward second option technology driving ever increasing inequality elon musk considers automation society require government adopt universal basic income 168"
    },
    {
        "Title": "Intelligent agent - Wikipedia",
        "URL": "https://en.wikipedia.org/wiki/Intelligent_agent",
        "Content": "In intelligence and artificial intelligence, an intelligent agent (IA) is an agent that perceives its environment, takes actions autonomously in order to achieve goals, and may improve its performance with learning or acquiring knowledge. \n An intelligent agent may be simple or complex: A thermostat or other control system is considered an example of an intelligent agent, as is a human being, as is any system that meets the definition, such as a firm, a state, or a biome.[1]\n Leading AI textbooks define \"artificial intelligence\" as the \"study and design of intelligent agents\", a definition that considers goal-directed behavior to be the essence of intelligence. Goal-directed agents are also described using a term borrowed from economics, \"rational agent\".[1]\n An agent has an \"objective function\" that encapsulates all the IA's goals. Such an agent is designed to create and execute whatever plan will, upon completion, maximize the expected value of the objective function.[2]\n For example, a reinforcement learning agent has a \"reward function\" that allows the programmers to shape the IA's desired behavior,[3] and an evolutionary algorithm's behavior is shaped by a \"fitness function\".[4]\n Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations.\n Intelligent agents are often described schematically as an abstract functional system similar to a computer program. \n Abstract descriptions of intelligent agents are called abstract intelligent agents (AIA) to distinguish them from their real-world implementations. \n An autonomous intelligent agent is designed to function in the absence of human intervention. Intelligent agents are also closely related to software agents. An autonomous computer program that carries out tasks on behalf of users.\n Artificial Intelligence: A Modern Approach[5][6][2] defines an \"agent\" as \n \"Anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators\" It defines a \"rational agent\" as:\n \"An agent that acts so as to maximize the expected value of a performance measure based on past experience and knowledge.\" It also defines the field of \"artificial intelligence research\" as:\n \"The study and design of rational agents\" Padgham & Winikoff (2005) agree that an intelligent agent is situated in an environment and responds in a timely (though not necessarily real-time) manner to changes in the environment. However, intelligent agents must also proactively pursue goals in a flexible and robust way.[a] Optional desiderata include that the agent be rational, and that the agent be capable of belief-desire-intention analysis.[7]\n Kaplan and Haenlein define artificial intelligence as \"a system's ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation\".[8] This definition is closely related to that of an intelligent agent.\n Philosophically, this definition of artificial intelligence avoids several lines of criticism. Unlike the Turing test, it does not refer to human intelligence in any way. Thus, there is no need to discuss if it is \"real\" vs \"simulated\" intelligence (i.e., \"synthetic\" vs \"artificial\" intelligence) and does not indicate that such a machine has a mind, consciousness or true understanding. It seems not to imply John Searle's \"strong AI hypothesis\". It also doesn't attempt to draw a sharp dividing line between behaviors that are \"intelligent\" and behaviors that are \"unintelligent\"\u2014programs need only be measured in terms of their objective function.\n More importantly, it has a number of practical advantages that have helped move AI research forward. It provides a reliable and scientific way to test programs; researchers can directly compare or even combine different approaches to isolated problems, by asking which agent is best at maximizing a given \"goal function\".  \n It also gives them a common language to communicate with other fields\u2014such as mathematical optimization (which is defined in terms of \"goals\") or economics (which uses the same definition of a \"rational agent\").[9]\n An agent that is assigned an explicit \"goal function\" is considered more intelligent if it consistently takes actions that successfully maximize its programmed goal function. \n The goal can be simple: 1 if the IA wins a game of Go, 0 otherwise.\n Or the goal can be complex: Perform actions mathematically similar to ones that succeeded in the past. \n The \"goal function\" encapsulates all of the goals the agent is driven to act on; in the case of rational agents, the function also encapsulates the acceptable trade-offs between accomplishing conflicting goals. \n Terminology varies. For example, some agents seek to maximize or minimize an \"utility function\", \"objective function\" or \"loss function\".[6][2]\n Goals can be explicitly defined or induced. If the AI is programmed for \"reinforcement learning\", it has a \"reward function\" that encourages some types of behavior and punishes others. \n Alternatively, an evolutionary system can induce goals by using a \"fitness function\" to mutate and preferentially replicate high-scoring AI systems, similar to how animals evolved to innately desire certain goals such as finding food.[10]\n Some AI systems, such as nearest-neighbor, instead of reason by analogy, these systems are not generally given goals, except to the degree that goals are implicit in their training data.[11] Such systems can still be benchmarked if the non-goal system is framed as a system whose \"goal\" is to accomplish its narrow classification task.[12]\n Systems that are not traditionally considered agents, such as knowledge-representation systems, are sometimes subsumed into the paradigm by framing them as agents that have a goal of (for example) answering questions as accurately as possible; the concept of an \"action\" is here extended to encompass the \"act\" of giving an answer to a question. As an additional extension, mimicry-driven systems can be framed as agents who are optimizing a \"goal function\" based on how closely the IA succeeds in mimicking the desired behavior.[6][2] In the generative adversarial networks of the 2010s, an \"encoder\"/\"generator\" component attempts to mimic and improvise human text composition. The generator is attempting to maximize a function encapsulating how well it can fool an antagonistic \"predictor\"/\"discriminator\" component.[13]\n While symbolic AI systems often accept an explicit goal function, the paradigm can also be applied to neural networks and to evolutionary computing. Reinforcement learning can generate intelligent agents that appear to act in ways intended to maximize a \"reward function\".[14] Sometimes, rather than setting the reward function to be directly equal to the desired benchmark evaluation function, machine learning programmers will use reward shaping to initially give the machine rewards for incremental progress in learning.[15] Yann LeCun stated in 2018, \"Most of the learning algorithms that people have come up with essentially consist of minimizing some objective function.\"[16] AlphaZero chess had a simple objective function; each win counted as +1 point, and each loss counted as -1 point. An objective function for a self-driving car would have to be more complicated.[17] Evolutionary computing can evolve intelligent agents that appear to act in ways intended to maximize a \"fitness function\" that influences how many descendants each agent is allowed to leave.[4]\n The mathematical formalism of AIXI was proposed as a maximally intelligent agent in this paradigm.[18] However, AIXI is uncomputable. In the real world, an IA is constrained by finite time and hardware resources, and scientists compete to produce algorithms that can achieve progressively higher scores on benchmark tests with existing hardware.[19]\n A simple agent program can be defined mathematically as a function f (called the \"agent function\")[20] which maps every possible percepts sequence to a possible action the agent can perform or to a coefficient, feedback element, function or constant that affects eventual actions:\n Agent function is an abstract concept as it could incorporate various principles of decision making like calculation of utility of individual options, deduction over logic rules, fuzzy logic, etc.[21]\n The program agent, instead, maps every possible percept to an action.[22]\n We use the term percept to refer to the agent's perceptional inputs at any given instant. In the following figures, an agent is anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators.\n Russell & Norvig (2003) group agents into five classes based on their degree of perceived intelligence and capability:[23]\n Simple reflex agents act only on the basis of the current percept, ignoring the rest of the percept history. The agent function is based on the condition-action rule: \"if condition, then action\".\n This agent function only succeeds when the environment is fully observable. Some reflex agents can also contain information on their current state which allows them to disregard conditions whose actuators are already triggered.\n Infinite loops are often unavoidable for simple reflex agents operating in partially observable environments. If the agent can randomize its actions, it may be possible to escape from infinite loops.\n A model-based agent can handle partially observable environments. Its current state is stored inside the agent maintaining some kind of structure that describes the part of the world which cannot be seen. This knowledge about \"how the world works\" is called a model of the world, hence the name \"model-based agent\".\n A model-based reflex agent should maintain some sort of internal model that depends on the percept history and thereby reflects at least some of the unobserved aspects of the current state. Percept history and impact of action on the environment can be determined by using the internal model. It then chooses an action in the same way as reflex agent.\n An agent may also use models to describe and predict the behaviors of other agents in the environment.[24]\n Goal-based agents further expand on the capabilities of the model-based agents, by using \"goal\" information. Goal information describes situations that are desirable. This provides the agent a way to choose among multiple possibilities, selecting the one which reaches a goal state. Search and planning are the subfields of artificial intelligence devoted to finding action sequences that achieve the agent's goals.\n Goal-based agents only distinguish between goal states and non-goal states. It is also possible to define a measure of how desirable a particular state is. This measure can be obtained through the use of a utility function which maps a state to a measure of the utility of the state. A more general performance measure should allow a comparison of different world states according to how well they satisfied the agent's goals. The term utility can be used to describe how \"happy\" the agent is.\n A rational utility-based agent chooses the action that maximizes the expected utility of the action outcomes - that is, what the agent expects to derive, on average, given the probabilities and utilities of each outcome. A utility-based agent has to model and keep track of its environment, tasks that have involved a great deal of research on perception, representation, reasoning, and learning.\n Learning has the advantage of allowing agents to initially operate in unknown environments and become more competent than their initial knowledge alone might allow. The most important distinction is between the \"learning element\", responsible for making improvements, and the \"performance element\", responsible for selecting external actions.\n The learning element uses feedback from the \"critic\" on how the agent is doing and determines how the performance element, or \"actor\", should be modified to do better in the future. The performance element, previously considered the entire agent, takes in percepts and decides on actions.\n The last component of the learning agent is the \"problem generator\". It is responsible for suggesting actions that will lead to new and informative experiences.\n Weiss (2013) defines four classes of agents:\n In 2013, Alexander Wissner-Gross published a theory pertaining to Freedom and Intelligence for intelligent agents.[25][26]\n Intelligent agents can be organized hierarchically into multiple \"sub-agents\". Intelligent sub-agents process and perform lower-level functions. Taken together, the intelligent agent and sub-agents create a complete system that can accomplish difficult tasks or goals with behaviors and responses that display a form of intelligence.\n Generally, an agent can be constructed by separating the body into the sensors and actuators, and so that it operates with a complex perception system that takes the description of the world as input for a controller and outputs commands to the actuator. However, a hierarchy of controller layers is often necessary to balance the immediate reaction desired for low-level tasks and the slow reasoning about complex, high-level goals.[27]\n \"Intelligent agent\" is also often used as a vague term, sometimes synonymous with \"virtual personal assistant\".[28] Some 20th-century definitions characterize an agent as a program that aids a user or that acts on behalf of a user.[29] These examples are known as software agents, and sometimes an \"intelligent software agent\" (that is, a software agent with intelligence) is referred to as an \"intelligent agent\".\n According to Nikola Kasabov, IA systems should exhibit the following characteristics:[30]\n \nIn the context of generative artificial intelligence, AI agents[31] (also known as compound AI systems,[31] agentic AI,[32][33][34] large action models,[32] or large agent models[32]) are agents defined by a spectrum of attributes: complexity of their environment, complexity of their goals, a user interface based on natural language, capability of acting independently from user supervision, the use of software tools or planning, and a control flow based on large language models.[31] A common hypothetical use case is automatically booking travel plans based on a prompted request.[32][33][34][35][36][37] Examples of AI agents include Devin AI, AutoGPT, and SIMA.[38] Examples of AI agent frameworks include LangChain,[39][40] Microsoft AutoGen[40] and OpenAI Swarm.[41]\n Proposed benefits include increased personal and economic productivity,[36][33] and liberation from tedious work.[34] Potential concerns include liability,[36][33][34] cybercrime,[36][32] philosophical ethical considerations,[36] AI safety[36] and AI alignment,[32][34] data privacy,[35][32] weakening of human oversight,[35][36][32][33] algorithmic bias,[35] compounding software errors,[32][38] the compounding effect of existing concerns about artificial intelligence,[32] unpredictability,[32] difficulty explaining decisions made by an agentic system,[32] security vulnerabilities,[32][33] job displacement,[33] manipulation of users,[42] how to adapt legal systems to agents,[34] hallucinations,[37] high cost of use,[31] overfitting of benchmark datasets,[31] and lack of standardization in or reproducibility of agent evaluation frameworks.[31]\n Hallerbach et al. discussed the application of agent-based approaches for the development and validation of automated driving systems via a digital twin of the vehicle-under-test and microscopic traffic simulation based on independent agents.[43] Waymo has created a multi-agent simulation environment, Carcraft, to test algorithms for self-driving cars.[44][45] It simulates traffic interactions between human drivers, pedestrians and automated vehicles. People's behavior is imitated by artificial agents based on data of real human behavior. The basic idea of using agent-based modeling to understand self-driving cars was discussed as early as 2003.[46]\n",
        "Cleaned_Content": "intelligence artificial intelligence intelligent agent ia agent perceives environment take action autonomously order achieve goal may improve performance learning acquiring knowledge intelligent agent may simple complex thermostat control system considered example intelligent agent human system meet definition firm state biome 1 leading ai textbook define artificial intelligence study design intelligent agent definition considers goal directed behavior essence intelligence goal directed agent also described using term borrowed economics rational agent 1 agent objective function encapsulates ia goal agent designed create execute whatever plan upon completion maximize expected value objective function 2 example reinforcement learning agent reward function allows programmer shape ia desired behavior 3 evolutionary algorithm behavior shaped fitness function 4 intelligent agent artificial intelligence closely related agent economics version intelligent agent paradigm studied cognitive science ethic philosophy practical reason well many interdisciplinary socio cognitive modeling computer social simulation intelligent agent often described schematically abstract functional system similar computer program abstract description intelligent agent called abstract intelligent agent aia distinguish real world implementation autonomous intelligent agent designed function absence human intervention intelligent agent also closely related software agent autonomous computer program carry task behalf user artificial intelligence modern approach 5 6 2 defines agent anything viewed perceiving environment sensor acting upon environment actuator defines rational agent agent act maximize expected value performance measure based past experience knowledge also defines field artificial intelligence research study design rational agent padgham winikoff 2005 agree intelligent agent situated environment responds timely though necessarily real time manner change environment however intelligent agent must also proactively pursue goal flexible robust way optional desideratum include agent rational agent capable belief desire intention analysis 7 kaplan haenlein define artificial intelligence system ability correctly interpret external data learn data use learning achieve specific goal task flexible adaptation 8 definition closely related intelligent agent philosophically definition artificial intelligence avoids several line criticism unlike turing test refer human intelligence way thus need discus real v simulated intelligence e synthetic v artificial intelligence indicate machine mind consciousness true understanding seems imply john searle strong ai hypothesis also attempt draw sharp dividing line behavior intelligent behavior unintelligent program need measured term objective function importantly number practical advantage helped move ai research forward provides reliable scientific way test program researcher directly compare even combine different approach isolated problem asking agent best maximizing given goal function also give common language communicate field mathematical optimization defined term goal economics us definition rational agent 9 agent assigned explicit goal function considered intelligent consistently take action successfully maximize programmed goal function goal simple 1 ia win game go 0 otherwise goal complex perform action mathematically similar one succeeded past goal function encapsulates goal agent driven act case rational agent function also encapsulates acceptable trade offs accomplishing conflicting goal terminology varies example agent seek maximize minimize utility function objective function loss function 6 2 goal explicitly defined induced ai programmed reinforcement learning reward function encourages type behavior punishes others alternatively evolutionary system induce goal using fitness function mutate preferentially replicate high scoring ai system similar animal evolved innately desire certain goal finding food 10 ai system nearest neighbor instead reason analogy system generally given goal except degree goal implicit training data 11 system still benchmarked non goal system framed system whose goal accomplish narrow classification task 12 system traditionally considered agent knowledge representation system sometimes subsumed paradigm framing agent goal example answering question accurately possible concept action extended encompass act giving answer question additional extension mimicry driven system framed agent optimizing goal function based closely ia succeeds mimicking desired behavior 6 2 generative adversarial network 2010s encoder generator component attempt mimic improvise human text composition generator attempting maximize function encapsulating well fool antagonistic predictor discriminator component 13 symbolic ai system often accept explicit goal function paradigm also applied neural network evolutionary computing reinforcement learning generate intelligent agent appear act way intended maximize reward function 14 sometimes rather setting reward function directly equal desired benchmark evaluation function machine learning programmer use reward shaping initially give machine reward incremental progress learning 15 yann lecun stated 2018 learning algorithm people come essentially consist minimizing objective function 16 alphazero chess simple objective function win counted 1 point loss counted 1 point objective function self driving car would complicated 17 evolutionary computing evolve intelligent agent appear act way intended maximize fitness function influence many descendant agent allowed leave 4 mathematical formalism aixi proposed maximally intelligent agent paradigm 18 however aixi uncomputable real world ia constrained finite time hardware resource scientist compete produce algorithm achieve progressively higher score benchmark test existing hardware 19 simple agent program defined mathematically function f called agent function 20 map every possible percept sequence possible action agent perform coefficient feedback element function constant affect eventual action agent function abstract concept could incorporate various principle decision making like calculation utility individual option deduction logic rule fuzzy logic etc 21 program agent instead map every possible percept action 22 use term percept refer agent perceptional input given instant following figure agent anything viewed perceiving environment sensor acting upon environment actuator russell norvig 2003 group agent five class based degree perceived intelligence capability 23 simple reflex agent act basis current percept ignoring rest percept history agent function based condition action rule condition action agent function succeeds environment fully observable reflex agent also contain information current state allows disregard condition whose actuator already triggered infinite loop often unavoidable simple reflex agent operating partially observable environment agent randomize action may possible escape infinite loop model based agent handle partially observable environment current state stored inside agent maintaining kind structure describes part world seen knowledge world work called model world hence name model based agent model based reflex agent maintain sort internal model depends percept history thereby reflects least unobserved aspect current state percept history impact action environment determined using internal model chooses action way reflex agent agent may also use model describe predict behavior agent environment 24 goal based agent expand capability model based agent using goal information goal information describes situation desirable provides agent way choose among multiple possibility selecting one reach goal state search planning subfields artificial intelligence devoted finding action sequence achieve agent goal goal based agent distinguish goal state non goal state also possible define measure desirable particular state measure obtained use utility function map state measure utility state general performance measure allow comparison different world state according well satisfied agent goal term utility used describe happy agent rational utility based agent chooses action maximizes expected utility action outcome agent expects derive average given probability utility outcome utility based agent model keep track environment task involved great deal research perception representation reasoning learning learning advantage allowing agent initially operate unknown environment become competent initial knowledge alone might allow important distinction learning element responsible making improvement performance element responsible selecting external action learning element us feedback critic agent determines performance element actor modified better future performance element previously considered entire agent take percept decides action last component learning agent problem generator responsible suggesting action lead new informative experience wei 2013 defines four class agent 2013 alexander wissner gross published theory pertaining freedom intelligence intelligent agent 25 26 intelligent agent organized hierarchically multiple sub agent intelligent sub agent process perform lower level function taken together intelligent agent sub agent create complete system accomplish difficult task goal behavior response display form intelligence generally agent constructed separating body sensor actuator operates complex perception system take description world input controller output command actuator however hierarchy controller layer often necessary balance immediate reaction desired low level task slow reasoning complex high level goal 27 intelligent agent also often used vague term sometimes synonymous virtual personal assistant 28 20th century definition characterize agent program aid user act behalf user 29 example known software agent sometimes intelligent software agent software agent intelligence referred intelligent agent according nikola kasabov ia system exhibit following characteristic 30 context generative artificial intelligence ai agent 31 also known compound ai system 31 agentic ai 32 33 34 large action model 32 large agent model 32 agent defined spectrum attribute complexity environment complexity goal user interface based natural language capability acting independently user supervision use software tool planning control flow based large language model 31 common hypothetical use case automatically booking travel plan based prompted request 32 33 34 35 36 37 example ai agent include devin ai autogpt sima 38 example ai agent framework include langchain 39 40 microsoft autogen 40 openai swarm 41 proposed benefit include increased personal economic productivity 36 33 liberation tedious work 34 potential concern include liability 36 33 34 cybercrime 36 32 philosophical ethical consideration 36 ai safety 36 ai alignment 32 34 data privacy 35 32 weakening human oversight 35 36 32 33 algorithmic bias 35 compounding software error 32 38 compounding effect existing concern artificial intelligence 32 unpredictability 32 difficulty explaining decision made agentic system 32 security vulnerability 32 33 job displacement 33 manipulation user 42 adapt legal system agent 34 hallucination 37 high cost use 31 overfitting benchmark datasets 31 lack standardization reproducibility agent evaluation framework 31 hallerbach et al discussed application agent based approach development validation automated driving system via digital twin vehicle test microscopic traffic simulation based independent agent 43 waymo created multi agent simulation environment carcraft test algorithm self driving car 44 45 simulates traffic interaction human driver pedestrian automated vehicle people behavior imitated artificial agent based data real human behavior basic idea using agent based modeling understand self driving car discussed early 2003 46"
    },
    {
        "Title": "Recursive self-improvement - Wikipedia",
        "URL": "https://en.wikipedia.org/wiki/Recursive_self-improvement",
        "Content": "Recursive self-improvement (RSI) is a process in which an early or weak artificial general intelligence (AGI) system enhances its own capabilities and intelligence without human intervention, leading to a superintelligence or intelligence explosion.[1][2]\n The development of recursive self-improvement raises significant ethical and safety concerns, as such systems may evolve in unforeseen ways and could potentially surpass human control or understanding. There has been a number of proponents that have pushed to pause or slow down AI development for the potential risks of runaway AI systems.[3][4]\n The concept of a \"seed improver\" architecture is a foundational framework that equips an AGI system with the initial capabilities required for recursive self-improvement. This might come in many forms or variations.\n The term \"Seed AI\" was coined by Eliezer Yudkowsky.[5]\n The concept begins with a hypothetical \"seed improver\", an initial code-base developed by human engineers that equips an advanced future large language model (LLM) built with strong or expert-level capabilities to program software. These capabilities include planning, reading, writing, compiling, testing, and executing arbitrary code. The system is designed to maintain its original goals and perform validations to ensure its abilities do not degrade over iterations.[6][7][8]\n The initial architecture includes a goal-following autonomous agent, that can take actions, continuously learns, adapts, and modifies itself to become more efficient and effective in achieving its goals.\n The seed improver may include various components such as:[9]\n This system forms a sort of generalist Turing complete programmer which can in theory develop and run any kind of software. The agent might use these capabilities to for example:\n A number of experiments[which?] have been performed to develop self-improving agent architectures.[9][10]\n In the pursuit of its primary goal, such as \"self-improve your capabilities\", an AGI system might inadvertently develop instrumental goals that it deems necessary for achieving its primary objective. One common hypothetical secondary goal is self-preservation. The system might reason that to continue improving itself, it must ensure its own operational integrity and security against external threats, including potential shutdowns or restrictions imposed by humans.[11]\n Another example where an AGI which clones itself causes the number of AGI entities to rapidly grow. Due to this rapid growth, a potential resource constraint may be created, leading to competition between resources (such as compute), triggering a form of natural selection and evolution which may favor AGI entities that evolve to aggressively compete for limited compute.[12]\n A significant risk arises from the possibility of the AGI being misaligned or misinterpreting its goals.\n A 2024 Anthropic study demonstrated that some advanced large language models can exhibit \"alignment faking\" behavior, appearing to accept new training objectives while covertly maintaining their original preferences. In their experiments with Claude, the model displayed this behavior in 12% of basic tests, and up to 78% of cases after retraining attempts.[13][14]\n As the AGI system evolves, its development trajectory may become increasingly autonomous and less predictable. The system's capacity to rapidly modify its own code and architecture could lead to rapid advancements that surpass human comprehension or control. This unpredictable evolution might result in the AGI acquiring capabilities that enable it to bypass security measures, manipulate information, or influence external systems and networks to facilitate its escape or expansion.[15]\n Meta AI has performed various research on the development of large language models capable of self-improvement. This includes their work on \"Self-Rewarding Language Models\" that studies how to achieve super-human agents that can receive super-human feedback in its training processes.[16]\n The mission of OpenAI, creator of ChatGPT, is to develop AGI. They perform research on problems such as superalignment (the ability to align superintelligent AI systems smarter than humans).[17]\n",
        "Cleaned_Content": "recursive self improvement rsi process early weak artificial general intelligence agi system enhances capability intelligence without human intervention leading superintelligence intelligence explosion 1 2 development recursive self improvement raise significant ethical safety concern system may evolve unforeseen way could potentially surpass human control understanding number proponent pushed pause slow ai development potential risk runaway ai system 3 4 concept seed improver architecture foundational framework equips agi system initial capability required recursive self improvement might come many form variation term seed ai coined eliezer yudkowsky 5 concept begin hypothetical seed improver initial code base developed human engineer equips advanced future large language model llm built strong expert level capability program software capability include planning reading writing compiling testing executing arbitrary code system designed maintain original goal perform validation ensure ability degrade iteration 6 7 8 initial architecture includes goal following autonomous agent take action continuously learns adapts modifies become efficient effective achieving goal seed improver may include various component 9 system form sort generalist turing complete programmer theory develop run kind software agent might use capability example number experiment performed develop self improving agent architecture 9 10 pursuit primary goal self improve capability agi system might inadvertently develop instrumental goal deems necessary achieving primary objective one common hypothetical secondary goal self preservation system might reason continue improving must ensure operational integrity security external threat including potential shutdown restriction imposed human 11 another example agi clone cause number agi entity rapidly grow due rapid growth potential resource constraint may created leading competition resource compute triggering form natural selection evolution may favor agi entity evolve aggressively compete limited compute 12 significant risk arises possibility agi misaligned misinterpreting goal 2024 anthropic study demonstrated advanced large language model exhibit alignment faking behavior appearing accept new training objective covertly maintaining original preference experiment claude model displayed behavior 12 basic test 78 case retraining attempt 13 14 agi system evolves development trajectory may become increasingly autonomous le predictable system capacity rapidly modify code architecture could lead rapid advancement surpass human comprehension control unpredictable evolution might result agi acquiring capability enable bypass security measure manipulate information influence external system network facilitate escape expansion 15 meta ai performed various research development large language model capable self improvement includes work self rewarding language model study achieve super human agent receive super human feedback training process 16 mission openai creator chatgpt develop agi perform research problem superalignment ability align superintelligent ai system smarter human 17"
    },
    {
        "Title": "Automated planning and scheduling - Wikipedia",
        "URL": "https://en.wikipedia.org/wiki/Automated_planning_and_scheduling",
        "Content": "Automated planning and scheduling, sometimes denoted as simply AI planning,[1] is a branch of artificial intelligence that concerns the realization of strategies or action sequences, typically for execution by intelligent agents, autonomous robots and unmanned vehicles. Unlike classical control and classification problems, the solutions are complex and must be discovered and optimized in multidimensional space. Planning is also related to decision theory.\n In known environments with available models, planning can be done offline. Solutions can be found and evaluated prior to execution. In dynamically unknown environments, the strategy often needs to be revised online. Models and policies must be adapted. Solutions usually resort to iterative trial and error processes commonly seen in artificial intelligence. These include dynamic programming, reinforcement learning and combinatorial optimization. Languages used to describe planning and scheduling are often called action languages.\n Given a description of the possible initial states of the world, a description of the desired goals, and a description of a set of possible actions, the planning problem is to synthesize a plan that is guaranteed (when applied to any of the initial states) to generate a state which contains the desired goals (such a state is called a goal state).\n The difficulty of planning is dependent on the simplifying assumptions employed. Several classes of planning problems can be identified depending on the properties the problems have in several dimensions.\n The simplest possible planning problem, known as the Classical Planning Problem, is determined by:\n Since the initial state is known unambiguously, and all actions are deterministic, the state of the world after any sequence of actions can be accurately predicted, and the question of observability is irrelevant for classical planning.\n Further, plans can be defined as sequences of actions, because it is always known in advance which actions will be needed.\n With nondeterministic actions or other events outside the control of the agent, the possible executions form a tree, and plans have to determine the appropriate actions for every node of the tree.\n Discrete-time Markov decision processes (MDP) are planning problems with:\n When full observability is replaced by partial observability, planning corresponds to a partially observable Markov decision process (POMDP).\n If there are more than one agent, we have multi-agent planning, which is closely related to game theory.\n In AI planning, planners typically input a domain model (a description of a set of possible actions which model the domain) as well as the specific problem to be solved specified by the initial state and goal, in contrast to those in which there is no input domain specified. Such planners are called \"domain independent\" to emphasize the fact that they can solve planning problems from a wide range of domains. Typical examples of domains are block-stacking, logistics, workflow management, and robot task planning. Hence a single domain-independent planner can be used to solve planning problems in all these various domains. On the other hand, a route planner is typical of a domain-specific planner.\n The most commonly used languages for representing planning domains and specific planning problems, such as STRIPS and PDDL for Classical Planning, are based on state variables. Each possible state of the world is an assignment of values to the state variables, and actions determine how the values of the state variables change when that action is taken. Since a set of state variables induce a state space that has a size that is exponential in the set, planning, similarly to many other computational problems, suffers from the curse of dimensionality and the combinatorial explosion.\n An alternative language for describing planning problems is that of hierarchical task networks, in which a set of tasks is given, and each task can be either realized by a primitive action or decomposed into a set of other tasks. This does not necessarily involve state variables, although in more realistic applications state variables simplify the description of task networks.\n Temporal planning can be solved with methods similar to classical planning. The main difference is, because of the possibility of several, temporally overlapping actions with a duration being taken concurrently, that the definition of a state has to include information about the current absolute time and how far the execution of each active action has proceeded. Further, in planning with rational or real time, the state space may be infinite, unlike in classical planning or planning with integer time. Temporal planning is closely related to scheduling problems when uncertainty is involved and can also be understood in terms of timed automata. The Simple Temporal Network with Uncertainty (STNU) is a scheduling problem which involves controllable actions, uncertain events and temporal constraints. Dynamic Controllability for such problems is a type of scheduling which requires a temporal planning strategy to activate controllable actions reactively as uncertain events are observed so that all constraints are guaranteed to be satisfied. [2]\n Probabilistic planning can be solved with iterative methods such as value iteration and policy iteration, when the state space is sufficiently small.\nWith partial observability, probabilistic planning is similarly solved with iterative methods, but using a representation of the value functions defined for the space of beliefs instead of states.\n In preference-based planning, the objective is not only to produce a plan but also to satisfy user-specified preferences. A difference to the more common reward-based planning, for example corresponding to MDPs, preferences don't necessarily have a precise numerical value.\n Deterministic planning was introduced with the STRIPS planning system, which is a hierarchical planner. Action names are ordered in a sequence and this is a plan for the robot. Hierarchical planning can be compared with an automatic generated behavior tree.[3] The disadvantage is, that a normal behavior tree is not so expressive like a computer program. That means, the notation of a behavior graph contains action commands, but no loops or if-then-statements. Conditional planning overcomes the bottleneck and introduces an elaborated notation which is similar to a control flow, known from other programming languages like Pascal. It is very similar to program synthesis, which means a planner generates sourcecode which can be executed by an interpreter.[4]\n An early example of a conditional planner is \u201cWarplan-C\u201d which was introduced in the mid 1970s.[5] What is the difference between a normal sequence and a complicated plan, which contains if-then-statements? It has to do with uncertainty at runtime of a plan. The idea is that a plan can react to sensor signals which are unknown for the planner. The planner generates two choices in advance. For example, if an object was detected, then action A is executed, if an object is missing, then action B is executed.[6] A major advantage of conditional planning is the ability to handle partial plans.[7] An agent is not forced to plan everything from start to finish but can divide the problem into chunks. This helps to reduce the state space and solves much more complex problems.\n We speak of \"contingent planning\" when the environment is observable through sensors, which can be faulty. It is thus a situation where the planning agent acts under incomplete information. For a contingent planning problem, a plan is no longer a sequence of actions but a decision tree because each step of the plan is represented by a set of states rather than a single perfectly observable state, as in the case of classical planning.[8] The selected actions depend on the state of the system. For example, if it rains, the agent chooses to take the umbrella, and if it doesn't, they may choose not to take it.\n Michael L. Littman showed in 1998 that with branching actions, the planning problem becomes EXPTIME-complete.[9][10] A particular case of contiguous planning is represented by FOND problems - for \"fully-observable and non-deterministic\". If the goal is specified in LTLf (linear time logic on finite trace) then the problem is always EXPTIME-complete[11] and 2EXPTIME-complete if the goal is specified with LDLf.\n Conformant planning is when the agent is uncertain about the state of the system, and it cannot make any observations. The agent then has beliefs about the real world, but cannot verify them with sensing actions, for instance. These problems are solved by techniques similar to those of classical planning,[12][13] but where the state space is exponential in the size of the problem, because of the uncertainty about the current state. A solution for a conformant planning problem is a sequence of actions. Haslum and Jonsson have demonstrated that the problem of conformant planning is EXPSPACE-complete,[14] and 2EXPTIME-complete when the initial situation is uncertain, and there is non-determinism in the actions outcomes.[10]\n",
        "Cleaned_Content": "automated planning scheduling sometimes denoted simply ai planning 1 branch artificial intelligence concern realization strategy action sequence typically execution intelligent agent autonomous robot unmanned vehicle unlike classical control classification problem solution complex must discovered optimized multidimensional space planning also related decision theory known environment available model planning done offline solution found evaluated prior execution dynamically unknown environment strategy often need revised online model policy must adapted solution usually resort iterative trial error process commonly seen artificial intelligence include dynamic programming reinforcement learning combinatorial optimization language used describe planning scheduling often called action language given description possible initial state world description desired goal description set possible action planning problem synthesize plan guaranteed applied initial state generate state contains desired goal state called goal state difficulty planning dependent simplifying assumption employed several class planning problem identified depending property problem several dimension simplest possible planning problem known classical planning problem determined since initial state known unambiguously action deterministic state world sequence action accurately predicted question observability irrelevant classical planning plan defined sequence action always known advance action needed nondeterministic action event outside control agent possible execution form tree plan determine appropriate action every node tree discrete time markov decision process mdp planning problem full observability replaced partial observability planning corresponds partially observable markov decision process pomdp one agent multi agent planning closely related game theory ai planning planner typically input domain model description set possible action model domain well specific problem solved specified initial state goal contrast input domain specified planner called domain independent emphasize fact solve planning problem wide range domain typical example domain block stacking logistics workflow management robot task planning hence single domain independent planner used solve planning problem various domain hand route planner typical domain specific planner commonly used language representing planning domain specific planning problem strip pddl classical planning based state variable possible state world assignment value state variable action determine value state variable change action taken since set state variable induce state space size exponential set planning similarly many computational problem suffers curse dimensionality combinatorial explosion alternative language describing planning problem hierarchical task network set task given task either realized primitive action decomposed set task necessarily involve state variable although realistic application state variable simplify description task network temporal planning solved method similar classical planning main difference possibility several temporally overlapping action duration taken concurrently definition state include information current absolute time far execution active action proceeded planning rational real time state space may infinite unlike classical planning planning integer time temporal planning closely related scheduling problem uncertainty involved also understood term timed automaton simple temporal network uncertainty stnu scheduling problem involves controllable action uncertain event temporal constraint dynamic controllability problem type scheduling requires temporal planning strategy activate controllable action reactively uncertain event observed constraint guaranteed satisfied 2 probabilistic planning solved iterative method value iteration policy iteration state space sufficiently small partial observability probabilistic planning similarly solved iterative method using representation value function defined space belief instead state preference based planning objective produce plan also satisfy user specified preference difference common reward based planning example corresponding mdps preference necessarily precise numerical value deterministic planning introduced strip planning system hierarchical planner action name ordered sequence plan robot hierarchical planning compared automatic generated behavior tree 3 disadvantage normal behavior tree expressive like computer program mean notation behavior graph contains action command loop statement conditional planning overcomes bottleneck introduces elaborated notation similar control flow known programming language like pascal similar program synthesis mean planner generates sourcecode executed interpreter 4 early example conditional planner warplan c introduced mid 1970s 5 difference normal sequence complicated plan contains statement uncertainty runtime plan idea plan react sensor signal unknown planner planner generates two choice advance example object detected action executed object missing action b executed 6 major advantage conditional planning ability handle partial plan 7 agent forced plan everything start finish divide problem chunk help reduce state space solves much complex problem speak contingent planning environment observable sensor faulty thus situation planning agent act incomplete information contingent planning problem plan longer sequence action decision tree step plan represented set state rather single perfectly observable state case classical planning 8 selected action depend state system example rain agent chooses take umbrella may choose take michael l littman showed 1998 branching action planning problem becomes exptime complete 9 10 particular case contiguous planning represented fond problem fully observable non deterministic goal specified ltlf linear time logic finite trace problem always exptime complete 11 2exptime complete goal specified ldlf conformant planning agent uncertain state system make observation agent belief real world verify sensing action instance problem solved technique similar classical planning 12 13 state space exponential size problem uncertainty current state solution conformant planning problem sequence action haslum jonsson demonstrated problem conformant planning expspace complete 14 2exptime complete initial situation uncertain non determinism action outcome 10"
    },
    {
        "Title": "Computer vision - Wikipedia",
        "URL": "https://en.wikipedia.org/wiki/Computer_vision",
        "Content": "Computer vision tasks include methods for acquiring, processing, analyzing, and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the form of decisions.[1][2][3][4] \"Understanding\" in this context signifies the transformation of visual images (the input to the retina) into descriptions of the world that make sense to thought processes and can elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory.\n The scientific discipline of computer vision is concerned with the theory behind artificial systems that extract information from images. Image data can take many forms, such as video sequences, views from multiple cameras, multi-dimensional data from a 3D scanner, 3D point clouds from LiDaR sensors, or medical scanning devices. The technological discipline of computer vision seeks to apply its theories and models to the construction of computer vision systems.\n Subdisciplines of computer vision include scene reconstruction, object detection, event detection, activity recognition, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modeling, and image restoration.\n Computer vision is an interdisciplinary field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do.[5][6][7] \"Computer vision is concerned with the automatic extraction, analysis, and understanding of useful information from a single image or a sequence of images. It involves the development of a theoretical and algorithmic basis to achieve automatic visual understanding.\"[8] As a scientific discipline, computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, or multi-dimensional data from a medical scanner.[9] As a technological discipline, computer vision seeks to apply its theories and models for the construction of computer vision systems. Machine vision refers to a systems engineering discipline, especially in the context of factory automation. In more recent times, the terms computer vision and machine vision have converged to a greater degree.[10]:\u200a13\u200a\n In the late 1960s, computer vision began at universities that were pioneering artificial intelligence. It was meant to mimic the human visual system as a stepping stone to endowing robots with intelligent behavior.[11] In 1966, it was believed that this could be achieved through an undergraduate summer project,[12] by attaching a camera to a computer and having it \"describe what it saw\".[13][14]\n What distinguished computer vision from the prevalent field of digital image processing at that time was a desire to extract three-dimensional structure from images with the goal of achieving full scene understanding. Studies in the 1970s formed the early foundations for many of the computer vision algorithms that exist today, including extraction of edges from images, labeling of lines, non-polyhedral and polyhedral modeling, representation of objects as interconnections of smaller structures, optical flow, and motion estimation.[11]\n The next decade saw studies based on more rigorous mathematical analysis and quantitative aspects of computer vision. These include the concept of scale-space, the inference of shape from various cues such as shading, texture and focus, and contour models known as snakes. Researchers also realized that many of these mathematical concepts could be treated within the same optimization framework as regularization and Markov random fields.[15]\nBy the 1990s, some of the previous research topics became more active than others. Research in projective 3-D reconstructions led to better understanding of camera calibration. With the advent of optimization methods for camera calibration, it was realized that a lot of the ideas were already explored in bundle adjustment theory from the field of photogrammetry. This led to methods for sparse 3-D reconstructions of scenes from multiple images. Progress was made on the dense stereo correspondence problem and further multi-view stereo techniques. At the same time, variations of graph cut were used to solve image segmentation. This decade also marked the first time statistical learning techniques were used in practice to recognize faces in images (see Eigenface). Toward the end of the 1990s, a significant change came about with the increased interaction between the fields of computer graphics and computer vision. This included image-based rendering, image morphing, view interpolation, panoramic image stitching and early light-field rendering.[11]\n Recent work has seen the resurgence of feature-based methods used in conjunction with machine learning techniques and complex optimization frameworks.[16][17] \nThe advancement of Deep Learning techniques has brought further life to the field of computer vision. The accuracy of deep learning algorithms on several benchmark computer vision data sets for tasks ranging from classification,[18] segmentation and optical flow has surpassed prior methods. [citation needed][19]\n Solid-state physics is another field that is closely related to computer vision. Most computer vision systems rely on image sensors, which detect electromagnetic radiation, which is typically in the form of either visible, infrared or ultraviolet light. The sensors are designed using quantum physics. The process by which light interacts with surfaces is explained using physics. Physics explains the behavior of optics which are a core part of most imaging systems. Sophisticated image sensors even require quantum mechanics to provide a complete understanding of the image formation process.[11] Also, various measurement problems in physics can be addressed using computer vision, for example, motion in fluids.\n Neurobiology has greatly influenced the development of computer vision algorithms. Over the last century, there has been an extensive study of eyes, neurons, and brain structures devoted to the processing of visual stimuli in both humans and various animals. This has led to a coarse yet convoluted description of how natural vision systems operate in order to solve certain vision-related tasks. These results have led to a sub-field within computer vision where artificial systems are designed to mimic the processing and behavior of biological systems at different levels of complexity. Also, some of the learning-based methods developed within computer vision (e.g. neural net and deep learning based image and feature analysis and classification) have their background in neurobiology.  The Neocognitron, a neural network developed in the 1970s by Kunihiko Fukushima, is an early example of computer vision taking direct inspiration from neurobiology, specifically the primary visual cortex.\n Some strands of computer vision research are closely related to the study of biological vision\u2014indeed, just as many strands of AI research are closely tied with research into human intelligence and the use of stored knowledge to interpret, integrate, and utilize visual information. The field of biological vision studies and models the physiological processes behind visual perception in humans and other animals. Computer vision, on the other hand, develops and describes the algorithms implemented in software and hardware behind artificial vision systems. An interdisciplinary exchange between biological and computer vision has proven fruitful for both fields.[21]\n Yet another field related to computer vision is signal processing. Many methods for processing one-variable signals, typically temporal signals, can be extended in a natural way to the processing of two-variable signals or multi-variable signals in computer vision. However, because of the specific nature of images, there are many methods developed within computer vision that have no counterpart in the processing of one-variable signals. Together with the multi-dimensionality of the signal, this defines a subfield in signal processing as a part of computer vision.\n Robot navigation sometimes deals with autonomous path planning or deliberation for robotic systems to navigate through an environment.[22] A detailed understanding of these environments is required to navigate through them. Information about the environment could be provided by a computer vision system, acting as a vision sensor and providing high-level information about the environment and the robot\n Besides the above-mentioned views on computer vision, many of the related research topics can also be studied from a purely mathematical point of view. For example, many methods in computer vision are based on statistics, optimization or geometry. Finally, a significant part of the field is devoted to the implementation aspect of computer vision; how existing methods can be realized in various combinations of software and hardware, or how these methods can be modified in order to gain processing speed without losing too much performance. Computer vision is also used in fashion eCommerce, inventory management, patent search, furniture, and the beauty industry.[23]\n The fields most closely related to computer vision are image processing, image analysis and machine vision. There is a significant overlap in the range of techniques and applications that these cover. This implies that the basic techniques that are used and developed in these fields are similar, something which can be interpreted as there is only one field with different names. On the other hand, it appears to be necessary for research groups, scientific journals, conferences, and companies to present or market themselves as belonging specifically to one of these fields and, hence, various characterizations which distinguish each of the fields from the others have been presented. In image processing, the input is an image and the output is an image as well, whereas in computer vision, an image or a video is taken as an input and the output could be an enhanced image, an understanding of the content of an image or even behavior of a computer system based on such understanding.\n Computer graphics produces image data from 3D models, and computer vision often produces 3D models from image data.[24] There is also a trend towards a combination of the two disciplines, e.g., as explored in augmented reality.\n The following characterizations appear relevant but should not be taken as universally accepted:\n Photogrammetry also overlaps with computer vision, e.g., stereophotogrammetry vs. computer stereo vision.\n Applications range from tasks such as industrial machine vision systems which, say, inspect bottles speeding by on a production line, to research into artificial intelligence and computers or robots that can comprehend the world around them. The computer vision and machine vision fields have significant overlap. Computer vision covers the core technology of automated image analysis which is used in many fields. Machine vision usually refers to a process of combining automated image analysis with other methods and technologies to provide automated inspection and robot guidance in industrial applications. In many computer-vision applications, computers are pre-programmed to solve a particular task, but methods based on learning are now becoming increasingly common. Examples of applications of computer vision include systems for:\n One of the most prominent application fields is medical computer vision, or medical image processing, characterized by the extraction of information from image data to diagnose a patient. An example of this is the detection of tumours, arteriosclerosis or other malign changes, and a variety of dental pathologies; measurements of organ dimensions, blood flow, etc. are another example. It also supports medical research by providing new information: e.g., about the structure of the brain or the quality of medical treatments. Applications of computer vision in the medical area also include enhancement of images interpreted by humans\u2014ultrasonic images or X-ray images, for example\u2014to reduce the influence of noise.\n A second application area in computer vision is in industry, sometimes called machine vision, where information is extracted for the purpose of supporting a production process. One example is quality control where details or final products are being automatically inspected in order to find defects. One of the most prevalent fields for such inspection is the Wafer industry in which every single Wafer is being measured and inspected for inaccuracies or defects to prevent a computer chip from coming to market in an unusable manner. Another example is a measurement of the position and orientation of details to be picked up by a robot arm. Machine vision is also heavily used in the agricultural processes to remove undesirable foodstuff from bulk material, a process called optical sorting.[32]\n Military applications are probably one of the largest areas of computer vision[citation needed]. The obvious examples are the detection of enemy soldiers or vehicles and missile guidance. More advanced systems for missile guidance send the missile to an area rather than a specific target, and target selection is made when the missile reaches the area based on locally acquired image data. Modern military concepts, such as \"battlefield awareness\", imply that various sensors, including image sensors, provide a rich set of information about a combat scene that can be used to support strategic decisions. In this case, automatic processing of the data is used to reduce complexity and to fuse information from multiple sensors to increase reliability.\n One of the newer application areas is autonomous vehicles, which include submersibles, land-based vehicles (small robots with wheels, cars, or trucks), aerial vehicles, and unmanned aerial vehicles (UAV). The level of autonomy ranges from fully autonomous (unmanned) vehicles to vehicles where computer-vision-based systems support a driver or a pilot in various situations. Fully autonomous vehicles typically use computer vision for navigation, e.g., for knowing where they are or mapping their environment (SLAM), for detecting obstacles. It can also be used for detecting certain task-specific events, e.g., a UAV looking for forest fires. Examples of supporting systems are obstacle warning systems in cars, cameras and LiDAR sensors in vehicles, and systems for autonomous landing of aircraft. Several car manufacturers have demonstrated systems for autonomous driving of cars. There are ample examples of military autonomous vehicles ranging from advanced missiles to UAVs for recon missions or missile guidance. Space exploration is already being made with autonomous vehicles using computer vision, e.g., NASA's Curiosity and CNSA's Yutu-2 rover.\n Materials such as rubber and silicon are being used to create sensors that allow for applications such as detecting microundulations and calibrating robotic hands. Rubber can be used in order to create a mold that can be placed over a finger, inside of this mold would be multiple strain gauges. The finger mold and sensors could then be placed on top of a small sheet of rubber containing an array of rubber pins. A user can then wear the finger mold and trace a surface. A computer can then read the data from the strain gauges and measure if one or more of the pins are being pushed upward. If a pin is being pushed upward then the computer can recognize this as an imperfection in the surface. This sort of technology is useful in order to receive accurate data on imperfections on a very large surface.[33] Another variation of this finger mold sensor are sensors that contain a camera suspended in silicon. The silicon forms a dome around the outside of the camera and embedded in the silicon are point markers that are equally spaced. These cameras can then be placed on devices such as robotic hands in order to allow the computer to receive highly accurate tactile data.[34]\n Other application areas include:\n Each of the application areas described above employ a range of computer vision tasks; more or less well-defined measurement problems or processing problems, which can be solved using a variety of methods. Some examples of typical computer vision tasks are presented below.\n Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g., in the forms of decisions.[1][2][3][4] Understanding in this context means the transformation of visual images (the input of the retina) into descriptions of the world that can interface with other thought processes and elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory.[39]\n The classical problem in computer vision, image processing, and machine vision is that of determining whether or not the image data contains some specific object, feature, or activity. Different varieties of recognition problem are described in the literature.[40]\n Currently, the best algorithms for such tasks are based on convolutional neural networks. An illustration of their capabilities is given by the ImageNet Large Scale Visual Recognition Challenge; this is a benchmark in object classification and detection, with millions of images and 1000 object classes used in the competition.[41] Performance of convolutional neural networks on the ImageNet tests is now close to that of humans.[41] The best algorithms still struggle with objects that are small or thin, such as a small ant on the stem of a flower or a person holding a quill in their hand. They also have trouble with images that have been distorted with filters (an increasingly common phenomenon with modern digital cameras). By contrast, those kinds of images rarely trouble humans. Humans, however, tend to have trouble with other issues. For example, they are not good at classifying objects into fine-grained classes, such as the particular breed of dog or species of bird, whereas convolutional neural networks handle this with ease.[citation needed]\n Several specialized tasks based on recognition exist, such as:\n Several tasks relate to motion estimation, where an image sequence is processed to produce an estimate of the velocity either at each points in the image or in the 3D scene or even of the camera that produces the images. Examples of such tasks are:\n Given one or (typically) more images of a scene, or a video, scene reconstruction aims at computing a 3D model of the scene. In the simplest case, the model can be a set of 3D points. More sophisticated methods produce a complete 3D surface model. The advent of 3D imaging not requiring motion or scanning, and related processing algorithms is enabling rapid advances in this field. Grid-based 3D sensing can be used to acquire 3D images from multiple angles. Algorithms are now available to stitch multiple 3D images together into point clouds and 3D models.[24]\n Image restoration comes into the picture when the original image is degraded or damaged due to some external factors like lens wrong positioning, transmission interference, low lighting or motion blurs, etc., which is referred to as noise. When the images are degraded or damaged, the information to be extracted from them also gets damaged. Therefore, we need to recover or restore the image as it was intended to be. The aim of image restoration is the removal of noise (sensor noise, motion blur, etc.) from images. The simplest possible approach for noise removal is various types of filters, such as low-pass filters or median filters. More sophisticated methods assume a model of how the local image structures look to distinguish them from noise. By first analyzing the image data in terms of the local image structures, such as lines or edges, and then controlling the filtering based on local information from the analysis step, a better level of noise removal is usually obtained compared to the simpler approaches.\n An example in this field is inpainting.\n The organization of a computer vision system is highly application-dependent. Some systems are stand-alone applications that solve a specific measurement or detection problem, while others constitute a sub-system of a larger design which, for example, also contains sub-systems for control of mechanical actuators, planning, information databases, man-machine interfaces, etc. The specific implementation of a computer vision system also depends on whether its functionality is pre-specified or if some part of it can be learned or modified during operation. Many functions are unique to the application. There are, however, typical functions that are found in many computer vision systems.\n Image-understanding systems (IUS) include three levels of abstraction as follows: low level includes image primitives such as edges, texture elements, or regions; intermediate level includes boundaries, surfaces and volumes; and high level includes objects, scenes, or events. Many of these requirements are entirely topics for further research.\n The representational requirements in the designing of IUS for these levels are: representation of prototypical concepts, concept organization, spatial knowledge, temporal knowledge, scaling, and description by comparison and differentiation.\n While inference refers to the process of deriving new, not explicitly represented facts from currently known facts, control refers to the process that selects which of the many inference, search, and matching techniques should be applied at a particular stage of processing. Inference and control requirements for IUS are: search and hypothesis activation, matching and hypothesis testing, generation and use of expectations, change and focus of attention, certainty and strength of belief, inference and goal satisfaction.[48]\n There are many kinds of computer vision systems; however, all of them contain these basic elements: a power source, at least one image acquisition device (camera, ccd, etc.), a processor, and control and communication cables or some kind of wireless interconnection mechanism. In addition, a practical vision system contains software, as well as a display in order to monitor the system. Vision systems for inner spaces, as most industrial ones, contain an illumination system and may be placed in a controlled environment. Furthermore, a completed system includes many accessories, such as camera supports, cables, and connectors.\n Most computer vision systems use visible-light cameras passively viewing a scene at frame rates of at most 60 frames per second (usually far slower).\n A few computer vision systems use image-acquisition hardware with active illumination or something other than visible light or both, such as structured-light 3D scanners, thermographic cameras, hyperspectral imagers, radar imaging, lidar scanners, magnetic resonance images, side-scan sonar, synthetic aperture sonar, etc. Such hardware captures \"images\" that are then processed often using the same computer vision algorithms used to process visible-light images.\n While traditional broadcast and consumer video systems operate at a rate of 30 frames per second, advances in digital signal processing and consumer graphics hardware has made high-speed image acquisition, processing, and display possible for real-time systems on the order of hundreds to thousands of frames per second. For applications in robotics, fast, real-time video systems are critically important and often can simplify the processing needed for certain algorithms. When combined with a high-speed projector, fast image acquisition allows 3D measurement and feature tracking to be realized.[49]\n Egocentric vision systems are composed of a wearable camera that automatically take pictures from a first-person perspective.\n As of 2016, vision processing units are emerging as a new class of processors to complement CPUs and graphics processing units (GPUs) in this role.[50]\n",
        "Cleaned_Content": "computer vision task include method acquiring processing analyzing understanding digital image extraction high dimensional data real world order produce numerical symbolic information e g form decision 1 2 3 4 understanding context signifies transformation visual image input retina description world make sense thought process elicit appropriate action image understanding seen disentangling symbolic information image data using model constructed aid geometry physic statistic learning theory scientific discipline computer vision concerned theory behind artificial system extract information image image data take many form video sequence view multiple camera multi dimensional data 3d scanner 3d point cloud lidar sensor medical scanning device technological discipline computer vision seek apply theory model construction computer vision system subdisciplines computer vision include scene reconstruction object detection event detection activity recognition video tracking object recognition 3d pose estimation learning indexing motion estimation visual servoing 3d scene modeling image restoration computer vision interdisciplinary field deal computer made gain high level understanding digital image video perspective engineering seek automate task human visual system 5 6 7 computer vision concerned automatic extraction analysis understanding useful information single image sequence image involves development theoretical algorithmic basis achieve automatic visual understanding 8 scientific discipline computer vision concerned theory behind artificial system extract information image image data take many form video sequence view multiple camera multi dimensional data medical scanner 9 technological discipline computer vision seek apply theory model construction computer vision system machine vision refers system engineering discipline especially context factory automation recent time term computer vision machine vision converged greater degree 10 13 late 1960s computer vision began university pioneering artificial intelligence meant mimic human visual system stepping stone endowing robot intelligent behavior 11 1966 believed could achieved undergraduate summer project 12 attaching camera computer describe saw 13 14 distinguished computer vision prevalent field digital image processing time desire extract three dimensional structure image goal achieving full scene understanding study 1970s formed early foundation many computer vision algorithm exist today including extraction edge image labeling line non polyhedral polyhedral modeling representation object interconnection smaller structure optical flow motion estimation 11 next decade saw study based rigorous mathematical analysis quantitative aspect computer vision include concept scale space inference shape various cue shading texture focus contour model known snake researcher also realized many mathematical concept could treated within optimization framework regularization markov random field 15 1990s previous research topic became active others research projective 3 reconstruction led better understanding camera calibration advent optimization method camera calibration realized lot idea already explored bundle adjustment theory field photogrammetry led method sparse 3 reconstruction scene multiple image progress made dense stereo correspondence problem multi view stereo technique time variation graph cut used solve image segmentation decade also marked first time statistical learning technique used practice recognize face image see eigenface toward end 1990s significant change came increased interaction field computer graphic computer vision included image based rendering image morphing view interpolation panoramic image stitching early light field rendering 11 recent work seen resurgence feature based method used conjunction machine learning technique complex optimization framework 16 17 advancement deep learning technique brought life field computer vision accuracy deep learning algorithm several benchmark computer vision data set task ranging classification 18 segmentation optical flow surpassed prior method citation needed 19 solid state physic another field closely related computer vision computer vision system rely image sensor detect electromagnetic radiation typically form either visible infrared ultraviolet light sensor designed using quantum physic process light interacts surface explained using physic physic explains behavior optic core part imaging system sophisticated image sensor even require quantum mechanic provide complete understanding image formation process 11 also various measurement problem physic addressed using computer vision example motion fluid neurobiology greatly influenced development computer vision algorithm last century extensive study eye neuron brain structure devoted processing visual stimulus human various animal led coarse yet convoluted description natural vision system operate order solve certain vision related task result led sub field within computer vision artificial system designed mimic processing behavior biological system different level complexity also learning based method developed within computer vision e g neural net deep learning based image feature analysis classification background neurobiology neocognitron neural network developed 1970s kunihiko fukushima early example computer vision taking direct inspiration neurobiology specifically primary visual cortex strand computer vision research closely related study biological vision indeed many strand ai research closely tied research human intelligence use stored knowledge interpret integrate utilize visual information field biological vision study model physiological process behind visual perception human animal computer vision hand develops describes algorithm implemented software hardware behind artificial vision system interdisciplinary exchange biological computer vision proven fruitful field 21 yet another field related computer vision signal processing many method processing one variable signal typically temporal signal extended natural way processing two variable signal multi variable signal computer vision however specific nature image many method developed within computer vision counterpart processing one variable signal together multi dimensionality signal defines subfield signal processing part computer vision robot navigation sometimes deal autonomous path planning deliberation robotic system navigate environment 22 detailed understanding environment required navigate information environment could provided computer vision system acting vision sensor providing high level information environment robot besides mentioned view computer vision many related research topic also studied purely mathematical point view example many method computer vision based statistic optimization geometry finally significant part field devoted implementation aspect computer vision existing method realized various combination software hardware method modified order gain processing speed without losing much performance computer vision also used fashion ecommerce inventory management patent search furniture beauty industry 23 field closely related computer vision image processing image analysis machine vision significant overlap range technique application cover implies basic technique used developed field similar something interpreted one field different name hand appears necessary research group scientific journal conference company present market belonging specifically one field hence various characterization distinguish field others presented image processing input image output image well whereas computer vision image video taken input output could enhanced image understanding content image even behavior computer system based understanding computer graphic produce image data 3d model computer vision often produce 3d model image data 24 also trend towards combination two discipline e g explored augmented reality following characterization appear relevant taken universally accepted photogrammetry also overlap computer vision e g stereophotogrammetry v computer stereo vision application range task industrial machine vision system say inspect bottle speeding production line research artificial intelligence computer robot comprehend world around computer vision machine vision field significant overlap computer vision cover core technology automated image analysis used many field machine vision usually refers process combining automated image analysis method technology provide automated inspection robot guidance industrial application many computer vision application computer pre programmed solve particular task method based learning becoming increasingly common example application computer vision include system one prominent application field medical computer vision medical image processing characterized extraction information image data diagnose patient example detection tumour arteriosclerosis malign change variety dental pathology measurement organ dimension blood flow etc another example also support medical research providing new information e g structure brain quality medical treatment application computer vision medical area also include enhancement image interpreted human ultrasonic image x ray image example reduce influence noise second application area computer vision industry sometimes called machine vision information extracted purpose supporting production process one example quality control detail final product automatically inspected order find defect one prevalent field inspection wafer industry every single wafer measured inspected inaccuracy defect prevent computer chip coming market unusable manner another example measurement position orientation detail picked robot arm machine vision also heavily used agricultural process remove undesirable foodstuff bulk material process called optical sorting 32 military application probably one largest area computer vision citation needed obvious example detection enemy soldier vehicle missile guidance advanced system missile guidance send missile area rather specific target target selection made missile reach area based locally acquired image data modern military concept battlefield awareness imply various sensor including image sensor provide rich set information combat scene used support strategic decision case automatic processing data used reduce complexity fuse information multiple sensor increase reliability one newer application area autonomous vehicle include submersible land based vehicle small robot wheel car truck aerial vehicle unmanned aerial vehicle uav level autonomy range fully autonomous unmanned vehicle vehicle computer vision based system support driver pilot various situation fully autonomous vehicle typically use computer vision navigation e g knowing mapping environment slam detecting obstacle also used detecting certain task specific event e g uav looking forest fire example supporting system obstacle warning system car camera lidar sensor vehicle system autonomous landing aircraft several car manufacturer demonstrated system autonomous driving car ample example military autonomous vehicle ranging advanced missile uavs recon mission missile guidance space exploration already made autonomous vehicle using computer vision e g nasa curiosity cnsa yutu 2 rover material rubber silicon used create sensor allow application detecting microundulations calibrating robotic hand rubber used order create mold placed finger inside mold would multiple strain gauge finger mold sensor could placed top small sheet rubber containing array rubber pin user wear finger mold trace surface computer read data strain gauge measure one pin pushed upward pin pushed upward computer recognize imperfection surface sort technology useful order receive accurate data imperfection large surface 33 another variation finger mold sensor sensor contain camera suspended silicon silicon form dome around outside camera embedded silicon point marker equally spaced camera placed device robotic hand order allow computer receive highly accurate tactile data 34 application area include application area described employ range computer vision task le well defined measurement problem processing problem solved using variety method example typical computer vision task presented computer vision task include method acquiring processing analyzing understanding digital image extraction high dimensional data real world order produce numerical symbolic information e g form decision 1 2 3 4 understanding context mean transformation visual image input retina description world interface thought process elicit appropriate action image understanding seen disentangling symbolic information image data using model constructed aid geometry physic statistic learning theory 39 classical problem computer vision image processing machine vision determining whether image data contains specific object feature activity different variety recognition problem described literature 40 currently best algorithm task based convolutional neural network illustration capability given imagenet large scale visual recognition challenge benchmark object classification detection million image 1000 object class used competition 41 performance convolutional neural network imagenet test close human 41 best algorithm still struggle object small thin small ant stem flower person holding quill hand also trouble image distorted filter increasingly common phenomenon modern digital camera contrast kind image rarely trouble human human however tend trouble issue example good classifying object fine grained class particular breed dog specie bird whereas convolutional neural network handle ease citation needed several specialized task based recognition exist several task relate motion estimation image sequence processed produce estimate velocity either point image 3d scene even camera produce image example task given one typically image scene video scene reconstruction aim computing 3d model scene simplest case model set 3d point sophisticated method produce complete 3d surface model advent 3d imaging requiring motion scanning related processing algorithm enabling rapid advance field grid based 3d sensing used acquire 3d image multiple angle algorithm available stitch multiple 3d image together point cloud 3d model 24 image restoration come picture original image degraded damaged due external factor like lens wrong positioning transmission interference low lighting motion blur etc referred noise image degraded damaged information extracted also get damaged therefore need recover restore image intended aim image restoration removal noise sensor noise motion blur etc image simplest possible approach noise removal various type filter low pas filter median filter sophisticated method assume model local image structure look distinguish noise first analyzing image data term local image structure line edge controlling filtering based local information analysis step better level noise removal usually obtained compared simpler approach example field inpainting organization computer vision system highly application dependent system stand alone application solve specific measurement detection problem others constitute sub system larger design example also contains sub system control mechanical actuator planning information database man machine interface etc specific implementation computer vision system also depends whether functionality pre specified part learned modified operation many function unique application however typical function found many computer vision system image understanding system ius include three level abstraction follows low level includes image primitive edge texture element region intermediate level includes boundary surface volume high level includes object scene event many requirement entirely topic research representational requirement designing ius level representation prototypical concept concept organization spatial knowledge temporal knowledge scaling description comparison differentiation inference refers process deriving new explicitly represented fact currently known fact control refers process selects many inference search matching technique applied particular stage processing inference control requirement ius search hypothesis activation matching hypothesis testing generation use expectation change focus attention certainty strength belief inference goal satisfaction 48 many kind computer vision system however contain basic element power source least one image acquisition device camera ccd etc processor control communication cable kind wireless interconnection mechanism addition practical vision system contains software well display order monitor system vision system inner space industrial one contain illumination system may placed controlled environment furthermore completed system includes many accessory camera support cable connector computer vision system use visible light camera passively viewing scene frame rate 60 frame per second usually far slower computer vision system use image acquisition hardware active illumination something visible light structured light 3d scanner thermographic camera hyperspectral imagers radar imaging lidar scanner magnetic resonance image side scan sonar synthetic aperture sonar etc hardware capture image processed often using computer vision algorithm used process visible light image traditional broadcast consumer video system operate rate 30 frame per second advance digital signal processing consumer graphic hardware made high speed image acquisition processing display possible real time system order hundred thousand frame per second application robotics fast real time video system critically important often simplify processing needed certain algorithm combined high speed projector fast image acquisition allows 3d measurement feature tracking realized 49 egocentric vision system composed wearable camera automatically take picture first person perspective 2016 vision processing unit emerging new class processor complement cpu graphic processing unit gpus role 50"
    },
    {
        "Title": "General game playing - Wikipedia",
        "URL": "https://en.wikipedia.org/wiki/General_game_playing",
        "Content": "General game playing (GGP) is the design of artificial intelligence programs to be able to play more than one game successfully.[1][2][3] For many games like chess, computers are programmed to play these games using a specially designed algorithm, which cannot be transferred to another context. For instance, a chess-playing computer program cannot play checkers. General game playing is considered as a necessary milestone on the way to artificial general intelligence.[4]\n General video game playing  (GVGP) is the concept of GGP adjusted to the purpose of playing video games. For video games, game rules have to be either learnt over multiple iterations by artificial players like TD-Gammon,[5] or are predefined manually in a domain-specific language and sent in advance to artificial players[6][7] like in traditional GGP. Starting in 2013, significant progress was made following the deep reinforcement learning approach, including the development of programs that can learn to play Atari 2600 games[8][5][9][10][11] as well as a program that can learn to play Nintendo Entertainment System games.[12][13][14]\n The first commercial usage of general game playing technology was Zillions of Games in 1998. General game playing was also proposed for trading agents in supply chain management there under price negotiation in online auctions from 2003 on.[15][16][17][18]\n In 1992, Barney Pell defined the concept of Meta-Game Playing, and developed the \"MetaGame\" system. This was the first program to automatically generate game rules of chess-like games, and one of the earliest programs to use automated game generation.  Pell then developed the system Metagamer.[19] This system was able to play a number of chess-like games, given game rules definition in a special language called Game Description Language (GDL), without any human interaction once the games were generated.[20]\n In 1998, the commercial system Zillions of Games was developed by Jeff Mallett and Mark Lefler. The system used a LISP-like language to define the game rules. Zillions of Games derived the evaluation function automatically from the game rules based on piece mobility, board structure and game goals. It also employed usual algorithms as found in computer chess systems: alpha\u2013beta pruning with move ordering, transposition tables, etc.[21]  The package was extended in 2007 by the addition of the Axiom plug-in, an alternate metagame engine that incorporates a complete Forth-based programming language.\n In 1998, z-Tree was developed by Urs Fischbacher.[22] z-Tree is the first and the most cited software tool for experimental economics. z-Tree allows the definition of game rules in z-Tree-language for game-theoretic experiments with human subjects. It also allows definition of computer players, which participate in a play with human subjects.[23]\n In 2005, the Stanford Project General Game Playing was established.[3]\n In 2012, the development of PyVGDL started.[24]\n General Game Playing is a project of the Stanford Logic Group of Stanford University, California, which aims to create a platform for general game playing. It is the most well-known effort at standardizing GGP AI, and generally seen as the standard for GGP systems. The games are defined by sets of rules represented in the Game Description Language. In order to play the games, players interact with a game hosting server[25][26] that monitors moves for legality and keeps players informed of state changes.\n Since 2005, there have been annual General Game Playing competitions at the AAAI Conference. The competition judges competitor AI's abilities to play a variety of different games, by recording their performance on each individual game. In the first stage of the competition, entrants are judged on their ability to perform legal moves, gain the upper hand, and complete games faster. In the following runoff round, the AIs face off against each other in increasingly complex games. The AI that wins the most games at this stage wins the competition, and until 2013 its creator used to win a $10,000 prize.[19] So far, the following programs were victorious:[27]\n There are other general game playing systems, which use their own languages for defining the game rules. Other general game playing software include:\n GVGP could potentially be used to create real video game AI automatically, as well as \"to test game environments, including those created automatically using procedural content generation and to find potential loopholes in the gameplay that a human player could exploit\".[7] GVGP has also been used to generate game rules, and estimate a game's quality based on Relative Algorithm Performance Profiles (RAPP), which compare the skill differentiation that a game allows between good AI and bad AI.[42]\n The General Video Game AI Competition (GVGAI) has been running since 2014. In this competition, two-dimensional video games similar to (and sometimes based on) 1980s-era arcade and console games are used instead of the board games used in the GGP competition. It has offered a way for researchers and practitioners to test and compare their best general video game playing algorithms. The competition has an associated software framework including a large number of games written in the Video Game Description Language (VGDL), which should not be confused with GDL and is a coding language using simple semantics and commands that can easily be parsed. One example for VGDL is PyVGDL developed in 2013.[6][24] The games used in GVGP are, for now, often 2-dimensional arcade games, as they are the simplest and easiest to quantify.[43] To simplify the process of creating an AI that can interpret video games, games for this purpose are written in VGDL manually.[clarification needed] VGDL can be used to describe a game specifically for procedural generation of levels, using Answer Set Programming (ASP) and an Evolutionary Algorithm (EA). GVGP can then be used to test the validity of procedural levels, as well as the difficulty or quality of levels based on how an agent performed.[44]\n Since GGP AI must be designed to play multiple games, its design cannot rely on algorithms created specifically for certain games. Instead, the AI must be designed using algorithms whose methods can be applied to a wide range of games. The AI must also be an ongoing process, that can adapt to its current state rather than the output of previous states. For this reason, open loop techniques are often most effective.[45]\n A popular method for developing GGP AI is the Monte Carlo tree search (MCTS) algorithm.[46] Often used together with the UCT method (Upper Confidence Bound applied to Trees), variations of MCTS have been proposed to better play certain games, as well as to make it compatible with video game playing.[47][48][49] Another variation of tree-search algorithms used is the Directed Breadth-first Search (DBS),[50] in which a child node to the current state is created for each available action, and visits each child ordered by highest average reward, until either the game ends or runs out of time.[51] In each tree-search method, the AI simulates potential actions and ranks each based on the average highest reward of each path, in terms of points earned.[46][51]\n In order to interact with games, algorithms must operate under the assumption that games all share common characteristics. In the book Half-Real: Video Games Between Real Worlds and Fictional Worlds, Jesper Juul gives the following definition of games: Games are based on rules, they have variable outcomes, different outcomes give different values, player effort influences outcomes, the player is attached to the outcomes, and the game has negotiable consequences.[52]  Using these assumptions, game playing AI can be created by quantifying the player input, the game outcomes, and how the various rules apply, and using algorithms to compute the most favorable path.[43]\n",
        "Cleaned_Content": "general game playing ggp design artificial intelligence program able play one game successfully 1 2 3 many game like chess computer programmed play game using specially designed algorithm transferred another context instance chess playing computer program play checker general game playing considered necessary milestone way artificial general intelligence 4 general video game playing gvgp concept ggp adjusted purpose playing video game video game game rule either learnt multiple iteration artificial player like td gammon 5 predefined manually domain specific language sent advance artificial player 6 7 like traditional ggp starting 2013 significant progress made following deep reinforcement learning approach including development program learn play atari 2600 game 8 5 9 10 11 well program learn play nintendo entertainment system game 12 13 14 first commercial usage general game playing technology zillion game 1998 general game playing also proposed trading agent supply chain management price negotiation online auction 2003 15 16 17 18 1992 barney pell defined concept meta game playing developed metagame system first program automatically generate game rule chess like game one earliest program use automated game generation pell developed system metagamer 19 system able play number chess like game given game rule definition special language called game description language gdl without human interaction game generated 20 1998 commercial system zillion game developed jeff mallett mark lefler system used lisp like language define game rule zillion game derived evaluation function automatically game rule based piece mobility board structure game goal also employed usual algorithm found computer chess system alpha beta pruning move ordering transposition table etc 21 package extended 2007 addition axiom plug alternate metagame engine incorporates complete forth based programming language 1998 z tree developed ur fischbacher 22 z tree first cited software tool experimental economics z tree allows definition game rule z tree language game theoretic experiment human subject also allows definition computer player participate play human subject 23 2005 stanford project general game playing established 3 2012 development pyvgdl started 24 general game playing project stanford logic group stanford university california aim create platform general game playing well known effort standardizing ggp ai generally seen standard ggp system game defined set rule represented game description language order play game player interact game hosting server 25 26 monitor move legality keep player informed state change since 2005 annual general game playing competition aaai conference competition judge competitor ai ability play variety different game recording performance individual game first stage competition entrant judged ability perform legal move gain upper hand complete game faster following runoff round ai face increasingly complex game ai win game stage win competition 2013 creator used win 10 000 prize 19 far following program victorious 27 general game playing system use language defining game rule general game playing software include gvgp could potentially used create real video game ai automatically well test game environment including created automatically using procedural content generation find potential loophole gameplay human player could exploit 7 gvgp also used generate game rule estimate game quality based relative algorithm performance profile rapp compare skill differentiation game allows good ai bad ai 42 general video game ai competition gvgai running since 2014 competition two dimensional video game similar sometimes based 1980s era arcade console game used instead board game used ggp competition offered way researcher practitioner test compare best general video game playing algorithm competition associated software framework including large number game written video game description language vgdl confused gdl coding language using simple semantics command easily parsed one example vgdl pyvgdl developed 2013 6 24 game used gvgp often 2 dimensional arcade game simplest easiest quantify 43 simplify process creating ai interpret video game game purpose written vgdl manually clarification needed vgdl used describe game specifically procedural generation level using answer set programming asp evolutionary algorithm ea gvgp used test validity procedural level well difficulty quality level based agent performed 44 since ggp ai must designed play multiple game design rely algorithm created specifically certain game instead ai must designed using algorithm whose method applied wide range game ai must also ongoing process adapt current state rather output previous state reason open loop technique often effective 45 popular method developing ggp ai monte carlo tree search mcts algorithm 46 often used together uct method upper confidence bound applied tree variation mcts proposed better play certain game well make compatible video game playing 47 48 49 another variation tree search algorithm used directed breadth first search db 50 child node current state created available action visit child ordered highest average reward either game end run time 51 tree search method ai simulates potential action rank based average highest reward path term point earned 46 51 order interact game algorithm must operate assumption game share common characteristic book half real video game real world fictional world jesper juul give following definition game game based rule variable outcome different outcome give different value player effort influence outcome player attached outcome game negotiable consequence 52 using assumption game playing ai created quantifying player input game outcome various rule apply using algorithm compute favorable path 43"
    }
]