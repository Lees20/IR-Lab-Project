{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "912704bc-ae11-49e4-b008-e8b6c76c343b",
   "metadata": {},
   "source": [
    "# ΕΡΓΑΣΙΑ ΑΝΑΚΤΗΣΗΣ ΠΛΗΡΟΦΟΡΙΑΣ\n",
    "\n",
    "Πριν αρχίσουμε, κατεβάζουμε ολα τα απαραίτητα πακέτα για να τρέξει το πρόγραμμα μας\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57039fd7-2ad8-4d51-9aeb-4772499e2c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/Cellar/jupyterlab/4.3.4_1/libexec/lib/python3.13/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /usr/local/Cellar/jupyterlab/4.3.4_1/libexec/lib/python3.13/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/Cellar/jupyterlab/4.3.4_1/libexec/lib/python3.13/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/Cellar/jupyterlab/4.3.4_1/libexec/lib/python3.13/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/Cellar/jupyterlab/4.3.4_1/libexec/lib/python3.13/site-packages (from nltk) (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0276b5d-e379-4fda-a2d9-b926c2fc999e",
   "metadata": {},
   "source": [
    "# Αρχικοποίηση προγράμματος\n",
    "Το παρακάτω τμήμα κώδικα εισάγει απαραίτητες βιβλιοθήκες για την επεξεργασία δεδομένων και φυσικής γλώσσας, όπως το requests για HTTP αιτήματα, το BeautifulSoup για ανάλυση HTML, και το nltk για λεματοποίηση, διαχωρισμό λέξεων και απομάκρυνση κοινών λέξεων (stopwords). Ρυθμίζει τη διαδρομή αποθήκευσης των δεδομένων της βιβλιοθήκης nltk και κατεβάζει τα εργαλεία punkt, stopwords και wordnet. Επιπλέον, αρχικοποιεί εργαλεία επεξεργασίας κειμένου, όπως τα stop_words, lemmatizer και stemmer, για την προετοιμασία κειμένων προς ανάλυση."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb67a3a-9b24-490e-8bca-5a8ebb3d83b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/panteliskarabetsos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/panteliskarabetsos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/panteliskarabetsos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Διαδρομή NLTK\n",
    "nltk.data.path.append('/Users/panteliskarabetsos/nltk_data')\n",
    "\n",
    "# Κατέβασμα απαραίτητων δεδομένων NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Αρχικοποίηση εργαλείων\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c1543f-defc-4a5a-bada-c656998a58ac",
   "metadata": {},
   "source": [
    "\n",
    "Το παρακάτω τμήμα του κώδικα περιλαμβάνει την αρχικοποίηση μεταβλητών και τη δημιουργία μιας συνάρτησης για την προεπεξεργασία κειμένου. Οι μεταβλητές visited_urls (σύνολο για αποθήκευση επισκεπτόμενων URLs), articles (λίστα άρθρων), και inverted_index (αντεστραμμένο ευρετήριο) προετοιμάζουν την αποθήκευση δεδομένων του προγράμματος. Η συνάρτηση preprocess_text καθαρίζει και προετοιμάζει το κείμενο προς ανάλυση: μετατρέπει τα γράμματα σε πεζά, αφαιρεί μη αλφαριθμητικούς χαρακτήρες και περιττά κενά, διαχωρίζει το κείμενο σε λέξεις (tokens), απομακρύνει τις stopwords, και εφαρμόζει λεματοποίηση για τη μείωση των λέξεων στη βασική τους μορφή. Επιστρέφει μια λίστα με τις επεξεργασμένες λέξεις."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28ba2ce-eb63-43ed-b65a-811e82e6139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Μεταβλητές\n",
    "visited_urls = set()\n",
    "articles = []\n",
    "inverted_index = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b79638-2310-4151-bd7a-03afc41a56a3",
   "metadata": {},
   "source": [
    "# Βήμα 1ο: Συλλογή Δεδομένων\n",
    "Η συνάρτηση crawl_wikipedia υλοποιεί έναν web crawler που συλλέγει άρθρα από τη Wikipedia, ανιχνεύει σελίδες στη Wikipedia ξεκινώντας από ένα URL και συλλέγει έως max_articles άρθρα. Επισκέπτεται κάθε σελίδα, εξάγει τον τίτλο, το κείμενο και τους συνδέσμους της, και αποθηκεύει τα δεδομένα στη λίστα articles. Ελέγχει για διπλότυπα URLs, προσθέτει νέους συνδέσμους στην ουρά ανίχνευσης, και καθυστερεί κάθε αίτημα για να προστατεύσει τον διακομιστή.\n",
    "### Ορόσημο: Τα συλλεγμένα άρθρα είναι διαθέσιμα στη λίστα articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df539af0-f3f3-4d5b-8273-7026c78d9653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Crawling\n",
    "def crawl_wikipedia(url, max_articles=10):\n",
    "    queue = [url]\n",
    "    while queue and len(articles) < max_articles:\n",
    "        current_url = queue.pop(0)\n",
    "        if current_url in visited_urls:\n",
    "            continue\n",
    "        try:\n",
    "            response = requests.get(current_url)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Απόκτηση τίτλου και περιεχομένου\n",
    "            title = soup.title.string if soup.title else 'No Title'\n",
    "            paragraphs = soup.find_all('p')\n",
    "            content = ' '.join([para.get_text() for para in paragraphs])\n",
    "            cleaned_content = ' '.join(preprocess_text(content))\n",
    "\n",
    "            # Αποθήκευση δεδομένων άρθρου\n",
    "            articles.append({\n",
    "                'Title': title,\n",
    "                'URL': current_url,\n",
    "                'Content': content,\n",
    "                'Cleaned_Content': cleaned_content\n",
    "            })\n",
    "            print(f'Collected and processed article: {title} from {current_url}')\n",
    "\n",
    "            visited_urls.add(current_url)\n",
    "\n",
    "            # Εύρεση συνδέσμων\n",
    "            for link in soup.find_all('a', href=True):\n",
    "                href = link['href']\n",
    "                if href.startswith('/wiki/') and ':' not in href:\n",
    "                    full_url = urljoin(base_url, href)\n",
    "                    if full_url not in visited_urls:\n",
    "                        queue.append(full_url)\n",
    "\n",
    "            time.sleep(1)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to retrieve {current_url}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34056b9f-213e-4aa8-8c55-87360a4d5607",
   "metadata": {},
   "source": [
    "# Βήμα 2: Προεπεξεργασία κειμένου\n",
    "Η συνάρτηση preprocess_text πραγματοποιεί:\n",
    "* Tokenization: Διαχωρισμός κειμένου σε λέξεις.\n",
    "* Stemming/Lemmatization: Εφαρμογή της μεθόδου lemmatizer.lemmatize.\n",
    "* Αφαίρεση stopwords και ειδικών χαρακτήρων: Χρησιμοποιούνται οι stop_words και οι κανονικές εκφράσεις.\n",
    "### Ορόσημο: Τα «καθαρισμένα» δεδομένα αποθηκεύονται στο πεδίο Cleaned_Content κάθε άρθρου στη λίστα articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58075b87-4859-4390-bdb3-83f42f05ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Προεπεξεργασία Κειμένου\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W', ' ', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa79c73d-7349-493d-8591-e72eca6a2fa5",
   "metadata": {},
   "source": [
    "# ΒΗΜΑ 3: Ευρετήριο\n",
    "Η συνάρτηση build_inverted_index δημιουργεί ένα αντεστραμμένο ευρετήριο από τα άρθρα που έχουν συλλεχθεί. Για κάθε άρθρο, εξάγει τις λέξεις από το πεδίο Cleaned_Content, εφαρμόζει stemming σε κάθε λέξη και καταχωρεί την ταυτότητα του άρθρου (index) στο ευρετήριο για κάθε λέξη. Έτσι, δημιουργείται μια δομή που συνδέει κάθε λέξη με τα άρθρα στα οποία εμφανίζεται, διευκολύνοντας την αναζήτηση.\n",
    "### Ορόσημο: Το αντεστραμμένο ευρετήριο είναι διαθέσιμο στο inverted_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b40c1c35-a2d4-4913-b9cf-4d5885026af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Δημιουργία Ευρετηρίου\n",
    "def build_inverted_index():\n",
    "    global inverted_index\n",
    "    for idx, article in enumerate(articles):\n",
    "        tokens = preprocess_text(article['Cleaned_Content'])\n",
    "        for token in tokens:\n",
    "            stemmed_token = stemmer.stem(token)\n",
    "            if stemmed_token not in inverted_index:\n",
    "                inverted_index[stemmed_token] = set()\n",
    "            inverted_index[stemmed_token].add(idx)\n",
    "   # print(\"Inverted Index Built:\", inverted_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5096f3f3-ed39-4d28-ad09-ed2749ce349a",
   "metadata": {},
   "source": [
    "# Βήμα 4: Μηχανή αναζήτησης\n",
    "\n",
    "Η συνάρτηση infix_to_postfix μετατρέπει ένα λογικό ερώτημα από τη μορφή infix (π.χ., A AND B) σε postfix (π.χ., A B AND) χρησιμοποιώντας τους κανόνες προτεραιότητας των τελεστών. Χρησιμοποιεί μια στοίβα (operators) για την αποθήκευση τελεστών και μια λίστα (output) για την κατασκευή της postfix έκφρασης. Οι τελεστές NOT, AND, OR έχουν συγκεκριμένη προτεραιότητα, ενώ οι παρενθέσεις εξασφαλίζουν τη σωστή σειρά εκτέλεσης. Τέλος, προσθέτει στη λίστα output ό,τι έχει απομείνει στη στοίβα.\n",
    "## i) Επεξεργασία Ερωτήματος"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6abd020f-6bea-440c-90ac-8f938e4cc13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Boolean Query Processing\n",
    "def infix_to_postfix(query):\n",
    "    precedence = {'NOT': 3, 'AND': 2, 'OR': 1}\n",
    "    output = []\n",
    "    operators = []\n",
    "    tokens = re.findall(r'\\(|\\)|\\w+|AND|OR|NOT', query)\n",
    "\n",
    "    for token in tokens:\n",
    "        token = token.upper()\n",
    "        if token in precedence:\n",
    "            while operators and operators[-1] != '(' and precedence[operators[-1]] >= precedence[token]:\n",
    "                output.append(operators.pop())\n",
    "            operators.append(token)\n",
    "        elif token == '(':\n",
    "            operators.append(token)\n",
    "        elif token == ')':\n",
    "            while operators and operators[-1] != '(':\n",
    "                output.append(operators.pop())\n",
    "            operators.pop()\n",
    "        else:\n",
    "            output.append(token)\n",
    "\n",
    "    while operators:\n",
    "        output.append(operators.pop())\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4dfb0f-5281-485a-9409-577b327f1bfc",
   "metadata": {},
   "source": [
    "Η συνάρτηση evaluate_postfix εκτελεί ένα λογικό ερώτημα σε μορφή postfix. Για κάθε λέξη, βρίσκει τα άρθρα όπου εμφανίζεται χρησιμοποιώντας το αντεστραμμένο ευρετήριο και τα αποθηκεύει στη στοίβα. Για τους τελεστές (AND, OR, NOT), συνδυάζει τα σύνολα εγγράφων από τη στοίβα: το AND κρατά τα κοινά έγγραφα, το OR ενώνει τα σύνολα, και το NOT αφαιρεί τα έγγραφα ενός συνόλου από το σύνολο όλων των εγγράφων. Τελικά, επιστρέφει το σύνολο των εγγράφων που ικανοποιούν το ερώτημα.\n",
    "### Ορόσημο: Λειτουργική μηχανή αναζήτησης με επιλογή αλγορίθμου κατάταξης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b95e7c5-49ce-400f-b98d-336edddbbb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_postfix(postfix):\n",
    "    \"\"\"Αξιολογεί ένα Boolean query σε postfix μορφή.\"\"\"\n",
    "    stack = []\n",
    "    all_docs = set(range(len(articles))) \n",
    "\n",
    "    for token in postfix:\n",
    "        print(f\"Processing token: {token}\") \n",
    "        if token in {\"AND\", \"OR\", \"NOT\"}: \n",
    "            if token == \"AND\":\n",
    "                if len(stack) < 2:\n",
    "                    print(\"Error: Not enough operands for AND.\")\n",
    "                    return set()\n",
    "                set2 = stack.pop()\n",
    "                set1 = stack.pop()\n",
    "                stack.append(set1.intersection(set2))\n",
    "            elif token == \"OR\":\n",
    "                if len(stack) < 2:\n",
    "                    print(\"Error: Not enough operands for OR.\")\n",
    "                    return set()\n",
    "                set2 = stack.pop()\n",
    "                set1 = stack.pop()\n",
    "                stack.append(set1.union(set2))\n",
    "            elif token == \"NOT\":\n",
    "                if not stack:\n",
    "                    print(\"Error: Not enough operands for NOT.\")\n",
    "                    return set()\n",
    "                set1 = stack.pop()\n",
    "                # Αφαιρούμε τα έγγραφα του set1 από το σύνολο όλων των εγγράφων\n",
    "                negated_set = all_docs.difference(set1)\n",
    "                print(f\"NOT operation negates documents: {set1}\")\n",
    "                stack.append(negated_set)\n",
    "        else:  # Αν είναι όρος\n",
    "            stemmed_token = stemmer.stem(token.lower())\n",
    "            result_set = inverted_index.get(stemmed_token, set())\n",
    "            print(f\"Token '{token}' maps to documents: {result_set}\") \n",
    "            stack.append(result_set)\n",
    "\n",
    "    result = stack.pop() if stack else set()\n",
    "    print(f\"Final result: {result}\")  \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1da26f-bf18-43bf-be35-abfba6278252",
   "metadata": {},
   "source": [
    "## ii) Κατάταξη αποτελεσμάτων:\n",
    "Η συνάρτηση compute_tfidf υπολογίζει το TF-IDF σκορ για κάθε έγγραφο του corpus με βάση τους όρους του ερωτήματος. Αρχικά, υπολογίζει το IDF (αντίστροφη συχνότητα εγγράφων) κάθε όρου, που δείχνει πόσο μοναδικός είναι σε σχέση με το σύνολο των εγγράφων. Στη συνέχεια, για κάθε έγγραφο, υπολογίζει τη συχνότητα του όρου (TF) και πολλαπλασιάζει με το αντίστοιχο IDF για να υπολογίσει το συνολικό σκορ. Επιστρέφει τα έγγραφα ταξινομημένα κατά TF-IDF σκορ από το υψηλότερο στο χαμηλότερο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54a53fca-195a-461d-92b2-187016231cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Κατάταξη \n",
    "def compute_tfidf(query_terms, corpus):\n",
    "    \"\"\"Υπολογίζει το TF-IDF σκορ κάθε εγγράφου για τους όρους του ερωτήματος.\"\"\"\n",
    "    tfidf_scores = []\n",
    "    num_docs = len(corpus)\n",
    "\n",
    "    # Υπολογισμός IDF με ελάχιστο όριο\n",
    "    idf = {}\n",
    "    for term in query_terms:\n",
    "        doc_count = sum(1 for doc in corpus if term in doc)\n",
    "        idf[term] = max(math.log((num_docs + 1) / (doc_count + 1)), 0.1)  \n",
    "\n",
    "    # Υπολογισμός TF-IDF για κάθε έγγραφο\n",
    "    for doc in corpus:\n",
    "        score = 0\n",
    "        for term in query_terms:\n",
    "            tf = doc.count(term) / len(doc) if len(doc) > 0 else 0\n",
    "            score += tf * idf.get(term, 0)\n",
    "        tfidf_scores.append(score)\n",
    "\n",
    "    ranked_indices = np.argsort(tfidf_scores)[::-1]\n",
    "    return ranked_indices, tfidf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118013c4-a4ef-4ac8-b187-d70ccf1004af",
   "metadata": {},
   "source": [
    "Η συνάρτηση compute_bm25 υπολογίζει το BM25 σκορ κάθε εγγράφου για τους όρους του ερωτήματος, το οποίο χρησιμοποιείται για την κατάταξη εγγράφων με βάση τη συνάφεια. Αρχικά, υπολογίζει το IDF (αντίστροφη συχνότητα εγγράφων) κάθε όρου για να μετρήσει πόσο σημαντικός είναι. Στη συνέχεια, για κάθε έγγραφο, υπολογίζει το BM25 σκορ, λαμβάνοντας υπόψη τη συχνότητα των όρων, το μήκος του εγγράφου, και τον μέσο όρο μήκους των εγγράφων. Τελικά, ταξινομεί τα έγγραφα με βάση το σκορ τους από το υψηλότερο στο χαμηλότερο και επιστρέφει τα ταξινομημένα ευρετήρια και τα αντίστοιχα σκορ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43802cdc-e7d8-4b9d-92b5-df335e74dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_bm25(query_terms, corpus, k1=1.5, b=0.75):\n",
    "    \"\"\"Υπολογίζει το BM25 σκορ κάθε εγγράφου για τους όρους του ερωτήματος.\"\"\"\n",
    "    bm25_scores = []\n",
    "    num_docs = len(corpus)\n",
    "    avg_doc_len = np.mean([len(doc) for doc in corpus]) \n",
    "\n",
    "    # Υπολογισμός IDF για κάθε όρο\n",
    "    idf = {}\n",
    "    for term in query_terms:\n",
    "        doc_count = sum(1 for doc in corpus if term in doc)\n",
    "        idf[term] = math.log((num_docs - doc_count + 0.5) / (doc_count + 0.5) + 1)  \n",
    "\n",
    "    # Υπολογισμός BM25 για κάθε έγγραφο\n",
    "    for doc in corpus:\n",
    "        doc_len = len(doc)\n",
    "        score = 0\n",
    "        for term in query_terms:\n",
    "            freq = doc.count(term)\n",
    "            numerator = freq * (k1 + 1)\n",
    "            denominator = freq + k1 * (1 - b + b * (doc_len / avg_doc_len))\n",
    "            score += idf.get(term, 0) * (numerator / denominator)\n",
    "        bm25_scores.append(score)\n",
    "\n",
    "    ranked_indices = np.argsort(bm25_scores)[::-1]\n",
    "    return ranked_indices, bm25_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0231ce3-9356-4355-a563-5dec0a7862c8",
   "metadata": {},
   "source": [
    "Η συνάρτηση compute_vsm υπολογίζει τη συνημιτονοειδή ομοιότητα (cosine similarity) κάθε εγγράφου με το ερώτημα. Πρώτα, υπολογίζει το IDF (αντίστροφη συχνότητα εγγράφων) για κάθε όρο, ώστε να μετρήσει τη σημασία του. Στη συνέχεια, δημιουργεί διανύσματα για το ερώτημα και τα έγγραφα, όπου κάθε όρος σταθμίζεται με βάση το IDF. Υπολογίζει τη συνημιτονοειδή ομοιότητα ως το εσωτερικό γινόμενο των διανυσμάτων διαιρεμένο με το γινόμενο των μηκών τους. Τα αποτελέσματα ταξινομούνται με βάση τη συνάφεια από το υψηλότερο στο χαμηλότερο και επιστρέφονται οι δείκτες των εγγράφων μαζί με τα αντίστοιχα σκορ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd728af4-759e-4078-aae4-c4733740179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_vsm(query_terms, corpus, debug=False):\n",
    "    \"\"\"Υπολογίζει τη συνημιτονοειδή ομοιότητα (cosine similarity) για κάθε έγγραφο.\"\"\"\n",
    "    from collections import defaultdict\n",
    "    from math import log, sqrt\n",
    "\n",
    "    # Υπολογισμός IDF\n",
    "    term_idf = {}\n",
    "    num_docs = len(corpus)\n",
    "    for doc in corpus:\n",
    "        for term in set(doc):\n",
    "            if term not in term_idf:\n",
    "                doc_count = sum(1 for d in corpus if term in d)\n",
    "                term_idf[term] = max(log((num_docs + 1) / (1 + doc_count)), 0.1)  # Κατώτατο όριο IDF\n",
    "\n",
    "    if debug:\n",
    "        print(f\"IDF Values: {term_idf}\")\n",
    "\n",
    "    # Δημιουργία διανύσματος ερωτήματος\n",
    "    query_vector = defaultdict(float)\n",
    "    for term in query_terms:\n",
    "        term = term.lower()\n",
    "        if term in term_idf:\n",
    "            query_vector[term] = query_terms.count(term) * term_idf[term]\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Query Vector: {dict(query_vector)}\")\n",
    "\n",
    "    # Υπολογισμός διανυσμάτων εγγράφων και cosine similarity\n",
    "    scores = []\n",
    "    for idx, doc in enumerate(corpus):\n",
    "        doc_vector = defaultdict(float)\n",
    "        for term in doc:\n",
    "            if term in term_idf:\n",
    "                doc_vector[term] = doc.count(term) * term_idf[term]\n",
    "\n",
    "        # Υπολογισμός cosine similarity\n",
    "        numerator = sum(query_vector[term] * doc_vector[term] for term in query_vector)\n",
    "        query_norm = sqrt(sum(v**2 for v in query_vector.values()))\n",
    "        doc_norm = sqrt(sum(v**2 for v in doc_vector.values()))\n",
    "        denominator = query_norm * doc_norm\n",
    "\n",
    "        if denominator == 0:\n",
    "            scores.append(0)\n",
    "        else:\n",
    "            scores.append(numerator / denominator)\n",
    "\n",
    "        if debug:\n",
    "            print(f\"Doc {idx} Vector: {dict(doc_vector)}, Score: {scores[-1]}\")\n",
    "\n",
    "    \n",
    "    ranked_indices = np.argsort(scores)[::-1]\n",
    "    return ranked_indices, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a56af-c141-4297-91ac-7a46a63c7c07",
   "metadata": {},
   "source": [
    "Η συνάρτηση search_with_ranking εκτελεί αναζήτηση με βάση ένα ερώτημα και ταξινομεί τα αποτελέσματα χρησιμοποιώντας τον επιλεγμένο αλγόριθμο κατάταξης (tfidf, bm25, ή vsm). Μετατρέπει το ερώτημα σε postfix μορφή, φιλτράρει τα σχετικά έγγραφα μέσω της συνάρτησης evaluate_postfix, και εξάγει τους όρους του ερωτήματος. Ανάλογα με τη μέθοδο κατάταξης, υπολογίζει τα σκορ συνάφειας για τα σχετικά έγγραφα και ταξινομεί τα αποτελέσματα. Επιστρέφει μόνο τα έγγραφα με θετικά σκορ, τα οποία εκτυπώνονται μαζί με τους τίτλους και τα URLs τους, επιτρέποντας την επιλογή κατάλληλου αλγορίθμου για καλύτερα αποτελέσματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2360293f-3c8a-4100-83b4-41370d3afa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_with_ranking(query, corpus, ranking_method=\"tfidf\"):\n",
    "    \"\"\"Αναζήτηση και κατάταξη με βάση τον επιλεγμένο αλγόριθμο.\"\"\"\n",
    "    postfix_query = infix_to_postfix(query)\n",
    "    filtered_indices = evaluate_postfix(postfix_query)\n",
    "\n",
    "    if not filtered_indices:\n",
    "        print(\"No results found.\")\n",
    "        return None, None  \n",
    "\n",
    "    filtered_indices = list(filtered_indices)\n",
    "    filtered_corpus = [corpus[idx] for idx in filtered_indices]\n",
    "    query_terms = [term for term in query.lower().split() if term not in {\"AND\", \"OR\", \"NOT\"}]\n",
    "\n",
    "    if ranking_method == \"tfidf\":\n",
    "        ranked_indices, scores = compute_tfidf(query_terms, filtered_corpus)\n",
    "    elif ranking_method == \"bm25\":\n",
    "        ranked_indices, scores = compute_bm25(query_terms, filtered_corpus)\n",
    "    elif ranking_method == \"vsm\":\n",
    "        ranked_indices, scores = compute_vsm(query_terms, filtered_corpus)\n",
    "    else:\n",
    "        print(\"Invalid ranking method.\")\n",
    "        return None, None  \n",
    "\n",
    "    # Φιλτράρισμα έγγραφων με σκορ > 0\n",
    "    valid_results = [\n",
    "        (filtered_indices[idx], scores[idx])\n",
    "        for idx in ranked_indices if scores[idx] > 0\n",
    "    ]\n",
    "\n",
    "    if not valid_results:\n",
    "        print(\"No valid results found.\")\n",
    "        return None, None \n",
    "\n",
    "    print(f\"Results ranked by {ranking_method.upper()}:\")\n",
    "    for rank, (doc_idx, score) in enumerate(valid_results):\n",
    "        print(f\"- {articles[doc_idx]['Title']} (Score: {score:.4f}) - URL: {articles[doc_idx]['URL']}\")\n",
    "\n",
    "    return [doc_idx for doc_idx, _ in valid_results], [score for _, score in valid_results]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028a8004-3fc8-42d7-82e5-a10e580f14fd",
   "metadata": {},
   "source": [
    "## Διεπαφή χρήστη\n",
    "Η συνάρτηση search_interface παρέχει έναν διαδραστικό τρόπο για αναζήτηση χρησιμοποιώντας λογικά ερωτήματα (Boolean queries). Ο χρήστης εισάγει το ερώτημά του και επιλέγει τον αλγόριθμο κατάταξης (TF-IDF, BM25, ή VSM). Η συνάρτηση καλεί τη μέθοδο search_with_ranking για την εκτέλεση της αναζήτησης και την εμφάνιση των αποτελεσμάτων. Ο χρήστης μπορεί να συνεχίσει να εισάγει ερωτήματα ή να τερματίσει τη διεπαφή πληκτρολογώντας exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e72a26d-7a44-49b8-bcf3-f664b92f676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Διεπαφή Αναζήτησης\n",
    "def search_interface():\n",
    "    \"\"\"Διεπαφή αναζήτησης για Boolean queries.\"\"\"\n",
    "    print(\"Welcome to the Search Engine with Ranking Options! Enter your query (type 'exit' to quit):\")\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"Query: \")\n",
    "        if query.lower() == 'exit':\n",
    "            break\n",
    "        \n",
    "        print(\"Choose ranking method: (1) TF-IDF, (2) BM25, (3) VSM\")\n",
    "        choice = input(\"Enter 1, 2, or 3: \")\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            search_with_ranking(query, [doc[\"Cleaned_Content\"].split() for doc in articles], ranking_method=\"tfidf\")\n",
    "        elif choice == \"2\":\n",
    "            search_with_ranking(query, [doc[\"Cleaned_Content\"].split() for doc in articles], ranking_method=\"bm25\")\n",
    "        elif choice == \"3\":\n",
    "            search_with_ranking(query, [doc[\"Cleaned_Content\"].split() for doc in articles], ranking_method=\"vsm\")\n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter 1, 2, or 3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d6109-a8b9-4266-bda0-18ced6776427",
   "metadata": {},
   "source": [
    "# Βήμα 5: Αξιολόγηση συστήματος\n",
    "Η συνάρτηση evaluate_search_engine αξιολογεί την απόδοση της μηχανής αναζήτησης χρησιμοποιώντας διάφορες μεθόδους κατάταξης (TF-IDF, BM25, VSM). Ο χρήστης επιλέγει τον αλγόριθμο, και για κάθε ερώτημα υπολογίζονται μετρικές όπως Precision, Recall, F1-Score και Μέση Ακρίβεια (MAP). Συγκρίνονται τα έγγραφα που επιστρέφονται από την αναζήτηση με τα σχετικά έγγραφα για κάθε ερώτημα, ενώ τα αποτελέσματα συνοψίζονται σε επίπεδο ερωτήματος και συνολικά.\n",
    "### Ορόσημο: Αναφορά αξιολόγησης με αποτελέσματα των μετρικών για κάθε ερώτημα και συνολικά."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c06257a7-ba55-4aaf-ba15-0378a74f1485",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_search_engine(test_queries, corpus):\n",
    "    while True:\n",
    "        print(\"\\nChoose ranking method for evaluation: (1) TF-IDF, (2) BM25, (3) VSM, (4) Exit\")\n",
    "        choice = input(\"Enter 1, 2, 3, or 4: \")\n",
    "\n",
    "        if choice == \"1\":\n",
    "            ranking_method = \"tfidf\"\n",
    "        elif choice == \"2\":\n",
    "            ranking_method = \"bm25\"\n",
    "        elif choice == \"3\":\n",
    "            ranking_method = \"vsm\"\n",
    "        elif choice == \"4\":\n",
    "            print(\"Exiting evaluation.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter 1, 2, 3, or 4.\")\n",
    "            continue\n",
    "\n",
    "        results = []\n",
    "        all_precisions = []\n",
    "\n",
    "        for query, relevant_docs in test_queries.items():\n",
    "            print(f\"\\nEvaluating query: {query}\")\n",
    "            ranked_indices, scores = search_with_ranking(query, [doc[\"Cleaned_Content\"].split() for doc in corpus], ranking_method)\n",
    "\n",
    "            if ranked_indices is None or scores is None:  # Handle case where no results are found\n",
    "                print(f\"No results for query: {query}\")\n",
    "                continue\n",
    "\n",
    "            # Υπολογισμός Precision, Recall, F1\n",
    "            retrieved_docs = ranked_indices[:len(relevant_docs)]  \n",
    "            true_positive = len(set(retrieved_docs) & set(relevant_docs))\n",
    "            precision = true_positive / len(retrieved_docs) if retrieved_docs else 0\n",
    "            recall = true_positive / len(relevant_docs) if relevant_docs else 0\n",
    "            f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) else 0\n",
    "\n",
    "            # Υπολογισμός Average Precision \n",
    "            precisions = []\n",
    "            retrieved_set = set()\n",
    "            for rank, idx in enumerate(ranked_indices):\n",
    "                if idx in relevant_docs:\n",
    "                    retrieved_set.add(idx)\n",
    "                    precision_at_k = len(retrieved_set) / (rank + 1)\n",
    "                    precisions.append(precision_at_k)\n",
    "            average_precision = sum(precisions) / len(relevant_docs) if precisions else 0\n",
    "            all_precisions.append(average_precision)\n",
    "\n",
    "            results.append({\n",
    "                \"Query\": query,\n",
    "                \"Precision\": precision,\n",
    "                \"Recall\": recall,\n",
    "                \"F1-Score\": f1,\n",
    "                \"Average Precision\": average_precision,\n",
    "            })\n",
    "\n",
    "        # Υπολογισμός Συνολικών Μετρικών\n",
    "        mean_average_precision = sum(all_precisions) / len(all_precisions) if all_precisions else 0\n",
    "        avg_precision = sum(res[\"Precision\"] for res in results) / len(results) if results else 0\n",
    "        avg_recall = sum(res[\"Recall\"] for res in results) / len(results) if results else 0\n",
    "        avg_f1 = sum(res[\"F1-Score\"] for res in results) / len(results) if results else 0\n",
    "\n",
    "        print(\"\\nΑποτελέσματα ανά Ερώτημα:\")\n",
    "        for res in results:\n",
    "            print(f\"- Query: {res['Query']}, Precision: {res['Precision']:.2f}, Recall: {res['Recall']:.2f}, \"\n",
    "                  f\"F1: {res['F1-Score']:.2f}, Average Precision: {res['Average Precision']:.2f}\")\n",
    "\n",
    "        print(\"\\nΣυνολικά Αποτελέσματα:\")\n",
    "        print(f\"Μέση Ακρίβεια (MAP): {mean_average_precision:.2f}\")\n",
    "        print(f\"Μέση Precision: {avg_precision:.2f}\")\n",
    "        print(f\"Μέση Recall: {avg_recall:.2f}\")\n",
    "        print(f\"Μέσο F1-Score: {avg_f1:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8a5450-77b1-455c-81d7-334b56aa45aa",
   "metadata": {},
   "source": [
    "Το τμήμα if __name__ == \"__main__\": είναι το σημείο εκκίνησης του προγράμματος. Ξεκινά ανιχνεύοντας τη Wikipedia από τη σελίδα της Τεχνητής Νοημοσύνης, συλλέγοντας έως 10 άρθρα μέσω της συνάρτησης crawl_wikipedia. Στη συνέχεια, δημιουργεί ένα αντεστραμμένο ευρετήριο με τη συνάρτηση build_inverted_index για γρήγορη αναζήτηση. Παρέχεται διεπαφή για αναζήτηση (search_interface), όπου ο χρήστης μπορεί να εκτελεί λογικά ερωτήματα. Τέλος, η συνάρτηση evaluate_search_engine αξιολογεί την ακρίβεια της μηχανής αναζήτησης σε συγκεκριμένα ερωτήματα δοκιμής. Αυτό το τμήμα συνδυάζει όλες τις κύριες λειτουργίες του προγράμματος για να εκτελεστούν διαδοχικά."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a78a1-53ba-4d4f-bc84-b90b9dfef214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected and processed article: Artificial intelligence - Wikipedia from https://en.wikipedia.org/wiki/Artificial_intelligence\n",
      "Collected and processed article: Wikipedia, the free encyclopedia from https://en.wikipedia.org/wiki/Main_Page\n",
      "Collected and processed article: Ai - Wikipedia from https://en.wikipedia.org/wiki/AI_(disambiguation)\n",
      "Collected and processed article: Artificial intelligence (disambiguation) - Wikipedia from https://en.wikipedia.org/wiki/Artificial_intelligence_(disambiguation)\n",
      "Collected and processed article: Artificial general intelligence - Wikipedia from https://en.wikipedia.org/wiki/Artificial_general_intelligence\n",
      "Collected and processed article: Intelligent agent - Wikipedia from https://en.wikipedia.org/wiki/Intelligent_agent\n",
      "Collected and processed article: Recursive self-improvement - Wikipedia from https://en.wikipedia.org/wiki/Recursive_self-improvement\n",
      "Collected and processed article: Automated planning and scheduling - Wikipedia from https://en.wikipedia.org/wiki/Automated_planning_and_scheduling\n",
      "Collected and processed article: Computer vision - Wikipedia from https://en.wikipedia.org/wiki/Computer_vision\n",
      "Collected and processed article: General game playing - Wikipedia from https://en.wikipedia.org/wiki/General_game_playing\n",
      "Welcome to the Search Engine with Ranking Options! Enter your query (type 'exit' to quit):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ΕΚΤΕΛΕΣΗ\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"https://en.wikipedia.org\"\n",
    "    start_url = f\"{base_url}/wiki/Artificial_intelligence\"\n",
    "\n",
    "    crawl_wikipedia(start_url, max_articles=10)\n",
    "    build_inverted_index()\n",
    "    search_interface()\n",
    "\n",
    "    #Eρωτήματα δοκιμής\n",
    "    test_queries = {\n",
    "        \"ai\": [0, 2, 4],\n",
    "        \"machine learning\": [1, 3],\n",
    "        \"deep learning\": [5, 6, 7],\n",
    "    }\n",
    "    evaluate_search_engine(test_queries, articles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
